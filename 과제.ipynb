{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using plaidml.keras.backend backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.datasets import load_breast_cancer, load_digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## breast cancer 분류, best model save, early stopping, graph, 2진분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = bc.data\n",
    "y = bc.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(300, input_dim=30, activation='relu'),\n",
    "    Dense(120, activation='relu'),\n",
    "    Dense(60, activation='relu'),\n",
    "    Dense(30, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy',\n",
    "             optimizer='nadam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = '../model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = MODEL_DIR + 'cencer{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "checkpointer_cb = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "earlystopping_cb = EarlyStopping(monitor='val_loss', patience=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 455 samples, validate on 114 samples\n",
      "Epoch 1/3000\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 9.47065, saving model to ../model/cencer001-9.4706.hdf5\n",
      "455/455 - 1s - loss: 9.9294 - accuracy: 0.5341 - val_loss: 9.4706 - val_accuracy: 0.2281\n",
      "Epoch 2/3000\n",
      "\n",
      "Epoch 00002: val_loss improved from 9.47065 to 0.62987, saving model to ../model/cencer002-0.6299.hdf5\n",
      "455/455 - 0s - loss: 2.8397 - accuracy: 0.6681 - val_loss: 0.6299 - val_accuracy: 0.8596\n",
      "Epoch 3/3000\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.62987 to 0.25299, saving model to ../model/cencer003-0.2530.hdf5\n",
      "455/455 - 0s - loss: 4.6344 - accuracy: 0.5582 - val_loss: 0.2530 - val_accuracy: 0.8947\n",
      "Epoch 4/3000\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.25299\n",
      "455/455 - 0s - loss: 1.1068 - accuracy: 0.7758 - val_loss: 2.2021 - val_accuracy: 0.4386\n",
      "Epoch 5/3000\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.25299\n",
      "455/455 - 0s - loss: 1.6872 - accuracy: 0.6505 - val_loss: 0.9405 - val_accuracy: 0.8772\n",
      "Epoch 6/3000\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.25299\n",
      "455/455 - 0s - loss: 1.6293 - accuracy: 0.7187 - val_loss: 0.4121 - val_accuracy: 0.8684\n",
      "Epoch 7/3000\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.25299\n",
      "455/455 - 0s - loss: 0.3094 - accuracy: 0.8945 - val_loss: 0.2641 - val_accuracy: 0.8860\n",
      "Epoch 8/3000\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.25299 to 0.23876, saving model to ../model/cencer008-0.2388.hdf5\n",
      "455/455 - 0s - loss: 0.2468 - accuracy: 0.9121 - val_loss: 0.2388 - val_accuracy: 0.9035\n",
      "Epoch 9/3000\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.23876\n",
      "455/455 - 0s - loss: 0.1915 - accuracy: 0.9275 - val_loss: 0.8484 - val_accuracy: 0.6754\n",
      "Epoch 10/3000\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.23876\n",
      "455/455 - 0s - loss: 1.2264 - accuracy: 0.7407 - val_loss: 1.3229 - val_accuracy: 0.8509\n",
      "Epoch 11/3000\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.23876\n",
      "455/455 - 0s - loss: 1.2419 - accuracy: 0.7978 - val_loss: 0.3004 - val_accuracy: 0.8860\n",
      "Epoch 12/3000\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.23876\n",
      "455/455 - 0s - loss: 0.3154 - accuracy: 0.9099 - val_loss: 0.7854 - val_accuracy: 0.7719\n",
      "Epoch 13/3000\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.23876\n",
      "455/455 - 0s - loss: 0.3223 - accuracy: 0.9011 - val_loss: 0.4509 - val_accuracy: 0.8509\n",
      "Epoch 14/3000\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.23876\n",
      "455/455 - 0s - loss: 0.2787 - accuracy: 0.9099 - val_loss: 0.3802 - val_accuracy: 0.9386\n",
      "Epoch 15/3000\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.23876\n",
      "455/455 - 0s - loss: 0.5275 - accuracy: 0.8615 - val_loss: 0.3191 - val_accuracy: 0.8860\n",
      "Epoch 16/3000\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.23876\n",
      "455/455 - 0s - loss: 0.2420 - accuracy: 0.9187 - val_loss: 0.7252 - val_accuracy: 0.7544\n",
      "Epoch 17/3000\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.23876\n",
      "455/455 - 0s - loss: 0.2627 - accuracy: 0.9187 - val_loss: 0.9516 - val_accuracy: 0.7018\n",
      "Epoch 18/3000\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.23876\n",
      "455/455 - 0s - loss: 0.9378 - accuracy: 0.7626 - val_loss: 0.6887 - val_accuracy: 0.9211\n",
      "Epoch 19/3000\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.23876\n",
      "455/455 - 0s - loss: 1.2826 - accuracy: 0.7670 - val_loss: 0.3245 - val_accuracy: 0.9035\n",
      "Epoch 20/3000\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.23876\n",
      "455/455 - 0s - loss: 0.2319 - accuracy: 0.9275 - val_loss: 0.4653 - val_accuracy: 0.8509\n",
      "Epoch 21/3000\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.23876\n",
      "455/455 - 0s - loss: 0.2592 - accuracy: 0.9253 - val_loss: 0.5227 - val_accuracy: 0.8509\n",
      "Epoch 22/3000\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.23876\n",
      "455/455 - 0s - loss: 0.2810 - accuracy: 0.9165 - val_loss: 0.4357 - val_accuracy: 0.8509\n",
      "Epoch 23/3000\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.23876\n",
      "455/455 - 0s - loss: 0.1974 - accuracy: 0.9363 - val_loss: 0.3679 - val_accuracy: 0.8772\n",
      "Epoch 24/3000\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.23876\n",
      "455/455 - 0s - loss: 0.2289 - accuracy: 0.9275 - val_loss: 0.2651 - val_accuracy: 0.9035\n",
      "Epoch 25/3000\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.23876\n",
      "455/455 - 0s - loss: 0.2217 - accuracy: 0.9143 - val_loss: 0.3002 - val_accuracy: 0.9386\n",
      "Epoch 26/3000\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.23876\n",
      "455/455 - 0s - loss: 0.2125 - accuracy: 0.9231 - val_loss: 0.2566 - val_accuracy: 0.9123\n",
      "Epoch 27/3000\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.23876\n",
      "455/455 - 0s - loss: 0.1897 - accuracy: 0.9297 - val_loss: 0.2546 - val_accuracy: 0.9298\n",
      "Epoch 28/3000\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.23876\n",
      "455/455 - 0s - loss: 0.2631 - accuracy: 0.9121 - val_loss: 0.5777 - val_accuracy: 0.8246\n",
      "Epoch 29/3000\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.23876\n",
      "455/455 - 0s - loss: 0.2347 - accuracy: 0.9165 - val_loss: 0.2508 - val_accuracy: 0.9298\n",
      "Epoch 30/3000\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.23876\n",
      "455/455 - 0s - loss: 0.1860 - accuracy: 0.9275 - val_loss: 0.2403 - val_accuracy: 0.9298\n",
      "Epoch 31/3000\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.23876\n",
      "455/455 - 0s - loss: 0.4519 - accuracy: 0.8769 - val_loss: 2.0017 - val_accuracy: 0.5175\n",
      "Epoch 32/3000\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.23876\n",
      "455/455 - 0s - loss: 2.6562 - accuracy: 0.7099 - val_loss: 0.3600 - val_accuracy: 0.8860\n",
      "Epoch 33/3000\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.23876\n",
      "455/455 - 0s - loss: 0.3929 - accuracy: 0.8835 - val_loss: 0.3986 - val_accuracy: 0.9386\n",
      "Epoch 34/3000\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.23876\n",
      "455/455 - 0s - loss: 0.2817 - accuracy: 0.9231 - val_loss: 0.4929 - val_accuracy: 0.8509\n",
      "Epoch 35/3000\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.23876\n",
      "455/455 - 0s - loss: 0.2401 - accuracy: 0.9231 - val_loss: 0.3116 - val_accuracy: 0.9474\n",
      "Epoch 36/3000\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.23876\n",
      "455/455 - 0s - loss: 0.3239 - accuracy: 0.9033 - val_loss: 0.5927 - val_accuracy: 0.8158\n",
      "Epoch 37/3000\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.23876\n",
      "455/455 - 0s - loss: 0.2248 - accuracy: 0.9143 - val_loss: 0.3219 - val_accuracy: 0.8772\n",
      "Epoch 38/3000\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.23876\n",
      "455/455 - 0s - loss: 0.1979 - accuracy: 0.9253 - val_loss: 0.2509 - val_accuracy: 0.9123\n",
      "Epoch 39/3000\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.23876\n",
      "455/455 - 0s - loss: 0.1923 - accuracy: 0.9341 - val_loss: 0.4812 - val_accuracy: 0.8246\n",
      "Epoch 40/3000\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.23876 to 0.23632, saving model to ../model/cencer040-0.2363.hdf5\n",
      "455/455 - 0s - loss: 0.1872 - accuracy: 0.9231 - val_loss: 0.2363 - val_accuracy: 0.9298\n",
      "Epoch 41/3000\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.23632\n",
      "455/455 - 0s - loss: 0.9025 - accuracy: 0.7912 - val_loss: 9.2475 - val_accuracy: 0.2281\n",
      "Epoch 42/3000\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.23632\n",
      "455/455 - 0s - loss: 1.5818 - accuracy: 0.8132 - val_loss: 0.6520 - val_accuracy: 0.7719\n",
      "Epoch 43/3000\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.23632\n",
      "455/455 - 0s - loss: 0.2797 - accuracy: 0.9143 - val_loss: 0.4798 - val_accuracy: 0.8246\n",
      "Epoch 44/3000\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.23632\n",
      "455/455 - 0s - loss: 0.1747 - accuracy: 0.9319 - val_loss: 0.3819 - val_accuracy: 0.8596\n",
      "Epoch 45/3000\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.23632\n",
      "455/455 - 0s - loss: 0.1828 - accuracy: 0.9319 - val_loss: 0.2729 - val_accuracy: 0.9035\n",
      "Epoch 46/3000\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.23632\n",
      "455/455 - 0s - loss: 0.3172 - accuracy: 0.8725 - val_loss: 2.1159 - val_accuracy: 0.4825\n",
      "Epoch 47/3000\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.23632 to 0.22867, saving model to ../model/cencer047-0.2287.hdf5\n",
      "455/455 - 0s - loss: 0.4244 - accuracy: 0.8725 - val_loss: 0.2287 - val_accuracy: 0.9123\n",
      "Epoch 48/3000\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.22867\n",
      "455/455 - 0s - loss: 0.1724 - accuracy: 0.9297 - val_loss: 0.3483 - val_accuracy: 0.8684\n",
      "Epoch 49/3000\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.22867\n",
      "455/455 - 0s - loss: 0.2025 - accuracy: 0.9253 - val_loss: 0.2977 - val_accuracy: 0.8684\n",
      "Epoch 50/3000\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.22867 to 0.21387, saving model to ../model/cencer050-0.2139.hdf5\n",
      "455/455 - 0s - loss: 0.2246 - accuracy: 0.9099 - val_loss: 0.2139 - val_accuracy: 0.9298\n",
      "Epoch 51/3000\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.21387\n",
      "455/455 - 0s - loss: 0.1773 - accuracy: 0.9275 - val_loss: 0.2141 - val_accuracy: 0.9211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/3000\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.21387\n",
      "455/455 - 0s - loss: 0.1741 - accuracy: 0.9275 - val_loss: 0.2770 - val_accuracy: 0.8860\n",
      "Epoch 53/3000\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.21387\n",
      "455/455 - 0s - loss: 0.1635 - accuracy: 0.9363 - val_loss: 0.3884 - val_accuracy: 0.8421\n",
      "Epoch 54/3000\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.21387\n",
      "455/455 - 0s - loss: 0.3547 - accuracy: 0.8747 - val_loss: 0.3263 - val_accuracy: 0.8947\n",
      "Epoch 55/3000\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.21387\n",
      "455/455 - 0s - loss: 0.1892 - accuracy: 0.9319 - val_loss: 0.2598 - val_accuracy: 0.9035\n",
      "Epoch 56/3000\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.21387\n",
      "455/455 - 0s - loss: 0.1755 - accuracy: 0.9319 - val_loss: 0.2655 - val_accuracy: 0.9035\n",
      "Epoch 57/3000\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.21387\n",
      "455/455 - 0s - loss: 0.1751 - accuracy: 0.9253 - val_loss: 0.3309 - val_accuracy: 0.9298\n",
      "Epoch 58/3000\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.21387\n",
      "455/455 - 0s - loss: 0.3182 - accuracy: 0.9033 - val_loss: 0.2984 - val_accuracy: 0.8772\n",
      "Epoch 59/3000\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.21387\n",
      "455/455 - 0s - loss: 0.1807 - accuracy: 0.9319 - val_loss: 0.2374 - val_accuracy: 0.9035\n",
      "Epoch 60/3000\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.21387\n",
      "455/455 - 0s - loss: 0.1785 - accuracy: 0.9319 - val_loss: 0.4079 - val_accuracy: 0.8421\n",
      "Epoch 61/3000\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.21387\n",
      "455/455 - 0s - loss: 0.1588 - accuracy: 0.9385 - val_loss: 0.2600 - val_accuracy: 0.8947\n",
      "Epoch 62/3000\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.21387\n",
      "455/455 - 0s - loss: 0.1842 - accuracy: 0.9209 - val_loss: 0.2169 - val_accuracy: 0.9298\n",
      "Epoch 63/3000\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.21387\n",
      "455/455 - 0s - loss: 0.1839 - accuracy: 0.9385 - val_loss: 0.2169 - val_accuracy: 0.9211\n",
      "Epoch 64/3000\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.21387\n",
      "455/455 - 0s - loss: 0.1695 - accuracy: 0.9341 - val_loss: 0.2586 - val_accuracy: 0.8860\n",
      "Epoch 65/3000\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.21387\n",
      "455/455 - 0s - loss: 0.1653 - accuracy: 0.9319 - val_loss: 0.4180 - val_accuracy: 0.8333\n",
      "Epoch 66/3000\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.21387\n",
      "455/455 - 0s - loss: 0.2740 - accuracy: 0.9055 - val_loss: 0.4405 - val_accuracy: 0.9211\n",
      "Epoch 67/3000\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.21387\n",
      "455/455 - 0s - loss: 0.7481 - accuracy: 0.7978 - val_loss: 2.0505 - val_accuracy: 0.5175\n",
      "Epoch 68/3000\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.21387\n",
      "455/455 - 0s - loss: 1.8507 - accuracy: 0.6264 - val_loss: 0.2822 - val_accuracy: 0.9386\n",
      "Epoch 69/3000\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.21387\n",
      "455/455 - 0s - loss: 0.1962 - accuracy: 0.9209 - val_loss: 0.2522 - val_accuracy: 0.9035\n",
      "Epoch 70/3000\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.21387 to 0.21310, saving model to ../model/cencer070-0.2131.hdf5\n",
      "455/455 - 0s - loss: 0.1930 - accuracy: 0.9275 - val_loss: 0.2131 - val_accuracy: 0.9386\n",
      "Epoch 71/3000\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.21310\n",
      "455/455 - 0s - loss: 0.2618 - accuracy: 0.8967 - val_loss: 0.5908 - val_accuracy: 0.7719\n",
      "Epoch 72/3000\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.21310\n",
      "455/455 - 0s - loss: 0.2956 - accuracy: 0.8989 - val_loss: 0.3430 - val_accuracy: 0.8860\n",
      "Epoch 73/3000\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.21310\n",
      "455/455 - 0s - loss: 0.2046 - accuracy: 0.9319 - val_loss: 0.2216 - val_accuracy: 0.9211\n",
      "Epoch 74/3000\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.21310\n",
      "455/455 - 0s - loss: 0.2952 - accuracy: 0.9121 - val_loss: 0.2785 - val_accuracy: 0.9035\n",
      "Epoch 75/3000\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.21310\n",
      "455/455 - 0s - loss: 0.1905 - accuracy: 0.9297 - val_loss: 0.2837 - val_accuracy: 0.9035\n",
      "Epoch 76/3000\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.21310\n",
      "455/455 - 0s - loss: 0.1919 - accuracy: 0.9319 - val_loss: 0.2183 - val_accuracy: 0.9123\n",
      "Epoch 77/3000\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.21310\n",
      "455/455 - 0s - loss: 0.2091 - accuracy: 0.9319 - val_loss: 0.2160 - val_accuracy: 0.9211\n",
      "Epoch 78/3000\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.21310\n",
      "455/455 - 0s - loss: 0.1801 - accuracy: 0.9319 - val_loss: 0.2231 - val_accuracy: 0.9298\n",
      "Epoch 79/3000\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.21310\n",
      "455/455 - 0s - loss: 0.2681 - accuracy: 0.9099 - val_loss: 0.2322 - val_accuracy: 0.9298\n",
      "Epoch 80/3000\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.21310\n",
      "455/455 - 0s - loss: 0.2079 - accuracy: 0.9231 - val_loss: 0.3200 - val_accuracy: 0.8947\n",
      "Epoch 81/3000\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.21310\n",
      "455/455 - 0s - loss: 0.1845 - accuracy: 0.9275 - val_loss: 0.2175 - val_accuracy: 0.9298\n",
      "Epoch 82/3000\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.21310\n",
      "455/455 - 0s - loss: 0.2785 - accuracy: 0.9077 - val_loss: 0.2532 - val_accuracy: 0.9386\n",
      "Epoch 83/3000\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.21310\n",
      "455/455 - 0s - loss: 0.1936 - accuracy: 0.9275 - val_loss: 0.2507 - val_accuracy: 0.9035\n",
      "Epoch 84/3000\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.21310\n",
      "455/455 - 0s - loss: 0.1677 - accuracy: 0.9341 - val_loss: 0.3196 - val_accuracy: 0.8860\n",
      "Epoch 85/3000\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.21310\n",
      "455/455 - 0s - loss: 0.2546 - accuracy: 0.9143 - val_loss: 0.3426 - val_accuracy: 0.8772\n",
      "Epoch 86/3000\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.21310\n",
      "455/455 - 0s - loss: 0.1728 - accuracy: 0.9341 - val_loss: 0.2203 - val_accuracy: 0.9123\n",
      "Epoch 87/3000\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.21310\n",
      "455/455 - 0s - loss: 0.1798 - accuracy: 0.9297 - val_loss: 0.3599 - val_accuracy: 0.8772\n",
      "Epoch 88/3000\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.21310 to 0.20829, saving model to ../model/cencer088-0.2083.hdf5\n",
      "455/455 - 0s - loss: 0.1986 - accuracy: 0.9319 - val_loss: 0.2083 - val_accuracy: 0.9123\n",
      "Epoch 89/3000\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.20829\n",
      "455/455 - 0s - loss: 0.1757 - accuracy: 0.9297 - val_loss: 0.2178 - val_accuracy: 0.9123\n",
      "Epoch 90/3000\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.20829\n",
      "455/455 - 0s - loss: 0.1816 - accuracy: 0.9297 - val_loss: 0.2185 - val_accuracy: 0.9123\n",
      "Epoch 91/3000\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.20829\n",
      "455/455 - 0s - loss: 0.1627 - accuracy: 0.9319 - val_loss: 0.2148 - val_accuracy: 0.9123\n",
      "Epoch 92/3000\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.20829\n",
      "455/455 - 0s - loss: 0.2002 - accuracy: 0.9231 - val_loss: 0.3660 - val_accuracy: 0.9298\n",
      "Epoch 93/3000\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.20829\n",
      "455/455 - 0s - loss: 0.3508 - accuracy: 0.8791 - val_loss: 0.2219 - val_accuracy: 0.9123\n",
      "Epoch 94/3000\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.20829\n",
      "455/455 - 0s - loss: 0.1771 - accuracy: 0.9319 - val_loss: 0.3426 - val_accuracy: 0.9298\n",
      "Epoch 95/3000\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.20829\n",
      "455/455 - 0s - loss: 0.2400 - accuracy: 0.9165 - val_loss: 0.4850 - val_accuracy: 0.8246\n",
      "Epoch 96/3000\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.20829\n",
      "455/455 - 0s - loss: 0.2682 - accuracy: 0.8989 - val_loss: 0.2462 - val_accuracy: 0.9386\n",
      "Epoch 97/3000\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.20829\n",
      "455/455 - 0s - loss: 0.1931 - accuracy: 0.9297 - val_loss: 0.2160 - val_accuracy: 0.9298\n",
      "Epoch 98/3000\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.20829\n",
      "455/455 - 0s - loss: 0.2098 - accuracy: 0.9231 - val_loss: 0.2915 - val_accuracy: 0.8860\n",
      "Epoch 99/3000\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.20829\n",
      "455/455 - 0s - loss: 0.1707 - accuracy: 0.9319 - val_loss: 0.2096 - val_accuracy: 0.9298\n",
      "Epoch 100/3000\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.20829\n",
      "455/455 - 0s - loss: 0.3444 - accuracy: 0.8791 - val_loss: 0.2119 - val_accuracy: 0.9123\n",
      "Epoch 101/3000\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.20829\n",
      "455/455 - 0s - loss: 0.1569 - accuracy: 0.9341 - val_loss: 0.5198 - val_accuracy: 0.7719\n",
      "Epoch 102/3000\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.20829\n",
      "455/455 - 0s - loss: 0.1830 - accuracy: 0.9231 - val_loss: 0.3457 - val_accuracy: 0.8421\n",
      "Epoch 103/3000\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.20829\n",
      "455/455 - 0s - loss: 0.1816 - accuracy: 0.9209 - val_loss: 0.2454 - val_accuracy: 0.8947\n",
      "Epoch 104/3000\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.20829\n",
      "455/455 - 0s - loss: 0.1621 - accuracy: 0.9363 - val_loss: 0.2351 - val_accuracy: 0.8947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/3000\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.20829 to 0.20764, saving model to ../model/cencer105-0.2076.hdf5\n",
      "455/455 - 0s - loss: 0.1910 - accuracy: 0.9209 - val_loss: 0.2076 - val_accuracy: 0.9123\n",
      "Epoch 106/3000\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.20764\n",
      "455/455 - 0s - loss: 0.1661 - accuracy: 0.9231 - val_loss: 0.2145 - val_accuracy: 0.9123\n",
      "Epoch 107/3000\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.20764\n",
      "455/455 - 0s - loss: 0.1585 - accuracy: 0.9385 - val_loss: 0.2611 - val_accuracy: 0.8947\n",
      "Epoch 108/3000\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.20764\n",
      "455/455 - 0s - loss: 0.3025 - accuracy: 0.8769 - val_loss: 0.3974 - val_accuracy: 0.8421\n",
      "Epoch 109/3000\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.20764 to 0.20439, saving model to ../model/cencer109-0.2044.hdf5\n",
      "455/455 - 0s - loss: 0.1714 - accuracy: 0.9363 - val_loss: 0.2044 - val_accuracy: 0.9298\n",
      "Epoch 110/3000\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.20439\n",
      "455/455 - 0s - loss: 0.1751 - accuracy: 0.9385 - val_loss: 0.6251 - val_accuracy: 0.7368\n",
      "Epoch 111/3000\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.20439\n",
      "455/455 - 0s - loss: 0.2029 - accuracy: 0.9253 - val_loss: 0.2998 - val_accuracy: 0.8860\n",
      "Epoch 112/3000\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.20439 to 0.19488, saving model to ../model/cencer112-0.1949.hdf5\n",
      "455/455 - 0s - loss: 0.1706 - accuracy: 0.9319 - val_loss: 0.1949 - val_accuracy: 0.9298\n",
      "Epoch 113/3000\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.19488\n",
      "455/455 - 0s - loss: 0.1589 - accuracy: 0.9363 - val_loss: 0.2399 - val_accuracy: 0.8860\n",
      "Epoch 114/3000\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.19488\n",
      "455/455 - 0s - loss: 0.1791 - accuracy: 0.9319 - val_loss: 0.3735 - val_accuracy: 0.8421\n",
      "Epoch 115/3000\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.19488\n",
      "455/455 - 0s - loss: 0.1644 - accuracy: 0.9451 - val_loss: 0.1960 - val_accuracy: 0.9123\n",
      "Epoch 116/3000\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.19488 to 0.19177, saving model to ../model/cencer116-0.1918.hdf5\n",
      "455/455 - 0s - loss: 0.1461 - accuracy: 0.9341 - val_loss: 0.1918 - val_accuracy: 0.9211\n",
      "Epoch 117/3000\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.19177\n",
      "455/455 - 0s - loss: 0.1682 - accuracy: 0.9363 - val_loss: 0.2015 - val_accuracy: 0.9123\n",
      "Epoch 118/3000\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.19177\n",
      "455/455 - 0s - loss: 0.1490 - accuracy: 0.9385 - val_loss: 0.3423 - val_accuracy: 0.8421\n",
      "Epoch 119/3000\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.19177\n",
      "455/455 - 0s - loss: 0.2680 - accuracy: 0.8945 - val_loss: 0.2186 - val_accuracy: 0.9035\n",
      "Epoch 120/3000\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.19177\n",
      "455/455 - 0s - loss: 0.1517 - accuracy: 0.9275 - val_loss: 0.1938 - val_accuracy: 0.9123\n",
      "Epoch 121/3000\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.19177\n",
      "455/455 - 0s - loss: 0.1610 - accuracy: 0.9429 - val_loss: 0.1935 - val_accuracy: 0.9211\n",
      "Epoch 122/3000\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.19177\n",
      "455/455 - 0s - loss: 0.1529 - accuracy: 0.9385 - val_loss: 0.2410 - val_accuracy: 0.8860\n",
      "Epoch 123/3000\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.19177\n",
      "455/455 - 0s - loss: 0.1642 - accuracy: 0.9341 - val_loss: 0.1940 - val_accuracy: 0.9123\n",
      "Epoch 124/3000\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.19177\n",
      "455/455 - 0s - loss: 0.1506 - accuracy: 0.9341 - val_loss: 0.2873 - val_accuracy: 0.8947\n",
      "Epoch 125/3000\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.19177\n",
      "455/455 - 0s - loss: 0.1699 - accuracy: 0.9407 - val_loss: 0.2147 - val_accuracy: 0.9123\n",
      "Epoch 126/3000\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.19177 to 0.18782, saving model to ../model/cencer126-0.1878.hdf5\n",
      "455/455 - 0s - loss: 0.2989 - accuracy: 0.8879 - val_loss: 0.1878 - val_accuracy: 0.9298\n",
      "Epoch 127/3000\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.18782\n",
      "455/455 - 0s - loss: 0.1509 - accuracy: 0.9319 - val_loss: 0.2839 - val_accuracy: 0.8860\n",
      "Epoch 128/3000\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.18782 to 0.18020, saving model to ../model/cencer128-0.1802.hdf5\n",
      "455/455 - 0s - loss: 0.1548 - accuracy: 0.9385 - val_loss: 0.1802 - val_accuracy: 0.9298\n",
      "Epoch 129/3000\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.18020\n",
      "455/455 - 0s - loss: 0.1921 - accuracy: 0.9319 - val_loss: 0.1917 - val_accuracy: 0.9211\n",
      "Epoch 130/3000\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.18020\n",
      "455/455 - 0s - loss: 0.1585 - accuracy: 0.9407 - val_loss: 0.3493 - val_accuracy: 0.8509\n",
      "Epoch 131/3000\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.18020\n",
      "455/455 - 0s - loss: 0.1562 - accuracy: 0.9341 - val_loss: 0.3398 - val_accuracy: 0.8333\n",
      "Epoch 132/3000\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.18020\n",
      "455/455 - 0s - loss: 0.1741 - accuracy: 0.9385 - val_loss: 0.3250 - val_accuracy: 0.8772\n",
      "Epoch 133/3000\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.18020\n",
      "455/455 - 0s - loss: 0.1574 - accuracy: 0.9363 - val_loss: 0.1851 - val_accuracy: 0.9298\n",
      "Epoch 134/3000\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.18020\n",
      "455/455 - 0s - loss: 0.2180 - accuracy: 0.9275 - val_loss: 0.2056 - val_accuracy: 0.9123\n",
      "Epoch 135/3000\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.18020\n",
      "455/455 - 0s - loss: 0.1766 - accuracy: 0.9341 - val_loss: 0.7077 - val_accuracy: 0.6930\n",
      "Epoch 136/3000\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.18020\n",
      "455/455 - 0s - loss: 0.1924 - accuracy: 0.9143 - val_loss: 0.2076 - val_accuracy: 0.9123\n",
      "Epoch 137/3000\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.18020\n",
      "455/455 - 0s - loss: 0.1486 - accuracy: 0.9385 - val_loss: 0.1904 - val_accuracy: 0.9211\n",
      "Epoch 138/3000\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.18020\n",
      "455/455 - 0s - loss: 0.1784 - accuracy: 0.9275 - val_loss: 0.2167 - val_accuracy: 0.9035\n",
      "Epoch 139/3000\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.18020\n",
      "455/455 - 0s - loss: 0.1718 - accuracy: 0.9275 - val_loss: 0.5694 - val_accuracy: 0.7456\n",
      "Epoch 140/3000\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.18020\n",
      "455/455 - 0s - loss: 0.2232 - accuracy: 0.9033 - val_loss: 0.3675 - val_accuracy: 0.8421\n",
      "Epoch 141/3000\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.18020\n",
      "455/455 - 0s - loss: 0.1535 - accuracy: 0.9363 - val_loss: 0.1976 - val_accuracy: 0.9123\n",
      "Epoch 142/3000\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.18020\n",
      "455/455 - 0s - loss: 0.1596 - accuracy: 0.9407 - val_loss: 0.2081 - val_accuracy: 0.9035\n",
      "Epoch 143/3000\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.18020\n",
      "455/455 - 0s - loss: 0.1441 - accuracy: 0.9407 - val_loss: 0.1883 - val_accuracy: 0.9298\n",
      "Epoch 144/3000\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.18020\n",
      "455/455 - 0s - loss: 0.1767 - accuracy: 0.9363 - val_loss: 0.3298 - val_accuracy: 0.8860\n",
      "Epoch 145/3000\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.18020\n",
      "455/455 - 0s - loss: 0.1771 - accuracy: 0.9407 - val_loss: 0.4473 - val_accuracy: 0.8070\n",
      "Epoch 146/3000\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.18020\n",
      "455/455 - 0s - loss: 0.1687 - accuracy: 0.9297 - val_loss: 0.2881 - val_accuracy: 0.8772\n",
      "Epoch 147/3000\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.18020\n",
      "455/455 - 0s - loss: 0.1489 - accuracy: 0.9319 - val_loss: 0.1894 - val_accuracy: 0.9298\n",
      "Epoch 148/3000\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.18020\n",
      "455/455 - 0s - loss: 0.1562 - accuracy: 0.9407 - val_loss: 0.1904 - val_accuracy: 0.9211\n",
      "Epoch 149/3000\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.18020\n",
      "455/455 - 0s - loss: 0.1375 - accuracy: 0.9407 - val_loss: 0.2553 - val_accuracy: 0.8860\n",
      "Epoch 150/3000\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.18020\n",
      "455/455 - 0s - loss: 0.1445 - accuracy: 0.9341 - val_loss: 0.3258 - val_accuracy: 0.8596\n",
      "Epoch 151/3000\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.18020\n",
      "455/455 - 0s - loss: 0.1607 - accuracy: 0.9385 - val_loss: 0.2550 - val_accuracy: 0.8772\n",
      "Epoch 152/3000\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.18020\n",
      "455/455 - 0s - loss: 0.1433 - accuracy: 0.9385 - val_loss: 0.2196 - val_accuracy: 0.9035\n",
      "Epoch 153/3000\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.18020\n",
      "455/455 - 0s - loss: 0.1480 - accuracy: 0.9407 - val_loss: 0.2418 - val_accuracy: 0.8860\n",
      "Epoch 154/3000\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.18020\n",
      "455/455 - 0s - loss: 0.1559 - accuracy: 0.9319 - val_loss: 0.2089 - val_accuracy: 0.8947\n",
      "Epoch 155/3000\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.18020\n",
      "455/455 - 0s - loss: 0.1647 - accuracy: 0.9341 - val_loss: 0.2077 - val_accuracy: 0.9474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 156/3000\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.18020\n",
      "455/455 - 0s - loss: 0.3376 - accuracy: 0.8725 - val_loss: 0.3030 - val_accuracy: 0.8509\n",
      "Epoch 157/3000\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.18020\n",
      "455/455 - 0s - loss: 0.1674 - accuracy: 0.9275 - val_loss: 0.2433 - val_accuracy: 0.9035\n",
      "Epoch 158/3000\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.18020\n",
      "455/455 - 0s - loss: 0.1758 - accuracy: 0.9209 - val_loss: 0.2266 - val_accuracy: 0.9474\n",
      "Epoch 159/3000\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.18020\n",
      "455/455 - 0s - loss: 0.1757 - accuracy: 0.9297 - val_loss: 0.2670 - val_accuracy: 0.8772\n",
      "Epoch 160/3000\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.18020\n",
      "455/455 - 0s - loss: 0.1977 - accuracy: 0.9077 - val_loss: 0.2019 - val_accuracy: 0.9298\n",
      "Epoch 161/3000\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.18020\n",
      "455/455 - 0s - loss: 0.2095 - accuracy: 0.9253 - val_loss: 0.2360 - val_accuracy: 0.9035\n",
      "Epoch 162/3000\n",
      "\n",
      "Epoch 00162: val_loss improved from 0.18020 to 0.18013, saving model to ../model/cencer162-0.1801.hdf5\n",
      "455/455 - 0s - loss: 0.1379 - accuracy: 0.9341 - val_loss: 0.1801 - val_accuracy: 0.9298\n",
      "Epoch 163/3000\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.18013\n",
      "455/455 - 0s - loss: 0.1526 - accuracy: 0.9429 - val_loss: 0.2197 - val_accuracy: 0.9123\n",
      "Epoch 164/3000\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.18013\n",
      "455/455 - 0s - loss: 0.1426 - accuracy: 0.9407 - val_loss: 0.2269 - val_accuracy: 0.9123\n",
      "Epoch 165/3000\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.18013\n",
      "455/455 - 0s - loss: 0.1421 - accuracy: 0.9429 - val_loss: 0.1813 - val_accuracy: 0.9298\n",
      "Epoch 166/3000\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.18013\n",
      "455/455 - 0s - loss: 0.1575 - accuracy: 0.9407 - val_loss: 0.4950 - val_accuracy: 0.7895\n",
      "Epoch 167/3000\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.18013 to 0.17839, saving model to ../model/cencer167-0.1784.hdf5\n",
      "455/455 - 0s - loss: 0.1820 - accuracy: 0.9319 - val_loss: 0.1784 - val_accuracy: 0.9298\n",
      "Epoch 168/3000\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.17839\n",
      "455/455 - 0s - loss: 0.2395 - accuracy: 0.8945 - val_loss: 0.3759 - val_accuracy: 0.8333\n",
      "Epoch 169/3000\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.17839\n",
      "455/455 - 0s - loss: 0.1788 - accuracy: 0.9429 - val_loss: 0.2358 - val_accuracy: 0.9035\n",
      "Epoch 170/3000\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.17839\n",
      "455/455 - 0s - loss: 0.1475 - accuracy: 0.9363 - val_loss: 0.1841 - val_accuracy: 0.9298\n",
      "Epoch 171/3000\n",
      "\n",
      "Epoch 00171: val_loss improved from 0.17839 to 0.17400, saving model to ../model/cencer171-0.1740.hdf5\n",
      "455/455 - 0s - loss: 0.1445 - accuracy: 0.9341 - val_loss: 0.1740 - val_accuracy: 0.9298\n",
      "Epoch 172/3000\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.17400\n",
      "455/455 - 0s - loss: 0.1454 - accuracy: 0.9407 - val_loss: 0.2175 - val_accuracy: 0.9035\n",
      "Epoch 173/3000\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.17400\n",
      "455/455 - 0s - loss: 0.1991 - accuracy: 0.9187 - val_loss: 0.1805 - val_accuracy: 0.9211\n",
      "Epoch 174/3000\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.17400\n",
      "455/455 - 0s - loss: 0.1935 - accuracy: 0.9319 - val_loss: 0.2889 - val_accuracy: 0.8684\n",
      "Epoch 175/3000\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.17400\n",
      "455/455 - 0s - loss: 0.1428 - accuracy: 0.9451 - val_loss: 0.4695 - val_accuracy: 0.7982\n",
      "Epoch 176/3000\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.17400\n",
      "455/455 - 0s - loss: 0.1399 - accuracy: 0.9451 - val_loss: 0.1961 - val_accuracy: 0.9123\n",
      "Epoch 177/3000\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.17400\n",
      "455/455 - 0s - loss: 0.1607 - accuracy: 0.9407 - val_loss: 0.2793 - val_accuracy: 0.8684\n",
      "Epoch 178/3000\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.17400\n",
      "455/455 - 0s - loss: 0.1478 - accuracy: 0.9363 - val_loss: 0.2087 - val_accuracy: 0.9035\n",
      "Epoch 179/3000\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.17400\n",
      "455/455 - 0s - loss: 0.1708 - accuracy: 0.9297 - val_loss: 0.7107 - val_accuracy: 0.6491\n",
      "Epoch 180/3000\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.17400\n",
      "455/455 - 0s - loss: 0.5173 - accuracy: 0.8066 - val_loss: 0.2110 - val_accuracy: 0.9123\n",
      "Epoch 181/3000\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.17400\n",
      "455/455 - 0s - loss: 0.1475 - accuracy: 0.9407 - val_loss: 0.3416 - val_accuracy: 0.8421\n",
      "Epoch 182/3000\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.17400\n",
      "455/455 - 0s - loss: 0.1502 - accuracy: 0.9407 - val_loss: 0.1827 - val_accuracy: 0.9298\n",
      "Epoch 183/3000\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.17400\n",
      "455/455 - 0s - loss: 0.1473 - accuracy: 0.9407 - val_loss: 0.1849 - val_accuracy: 0.9298\n",
      "Epoch 184/3000\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.17400\n",
      "455/455 - 0s - loss: 0.1791 - accuracy: 0.9253 - val_loss: 0.1847 - val_accuracy: 0.9298\n",
      "Epoch 185/3000\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.17400\n",
      "455/455 - 0s - loss: 0.1384 - accuracy: 0.9407 - val_loss: 0.1798 - val_accuracy: 0.9298\n",
      "Epoch 186/3000\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.17400\n",
      "455/455 - 0s - loss: 0.1388 - accuracy: 0.9363 - val_loss: 0.2287 - val_accuracy: 0.9035\n",
      "Epoch 187/3000\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.17400\n",
      "455/455 - 0s - loss: 0.1405 - accuracy: 0.9297 - val_loss: 0.1893 - val_accuracy: 0.9298\n",
      "Epoch 188/3000\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.17400\n",
      "455/455 - 0s - loss: 0.1447 - accuracy: 0.9385 - val_loss: 0.3575 - val_accuracy: 0.8421\n",
      "Epoch 189/3000\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.17400\n",
      "455/455 - 0s - loss: 0.1576 - accuracy: 0.9451 - val_loss: 0.1980 - val_accuracy: 0.9298\n",
      "Epoch 190/3000\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.17400\n",
      "455/455 - 0s - loss: 0.1395 - accuracy: 0.9407 - val_loss: 0.2226 - val_accuracy: 0.9035\n",
      "Epoch 191/3000\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.17400\n",
      "455/455 - 0s - loss: 0.1478 - accuracy: 0.9407 - val_loss: 0.1751 - val_accuracy: 0.9298\n",
      "Epoch 192/3000\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.17400\n",
      "455/455 - 0s - loss: 0.1562 - accuracy: 0.9297 - val_loss: 0.1740 - val_accuracy: 0.9386\n",
      "Epoch 193/3000\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.17400\n",
      "455/455 - 0s - loss: 0.1814 - accuracy: 0.9253 - val_loss: 0.1749 - val_accuracy: 0.9298\n",
      "Epoch 194/3000\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.17400\n",
      "455/455 - 0s - loss: 0.1438 - accuracy: 0.9407 - val_loss: 0.2100 - val_accuracy: 0.8947\n",
      "Epoch 195/3000\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.17400\n",
      "455/455 - 0s - loss: 0.1293 - accuracy: 0.9429 - val_loss: 0.1828 - val_accuracy: 0.9298\n",
      "Epoch 196/3000\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.17400\n",
      "455/455 - 0s - loss: 0.1451 - accuracy: 0.9363 - val_loss: 0.1956 - val_accuracy: 0.9298\n",
      "Epoch 197/3000\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.17400\n",
      "455/455 - 0s - loss: 0.2353 - accuracy: 0.8989 - val_loss: 0.1877 - val_accuracy: 0.9298\n",
      "Epoch 198/3000\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.17400\n",
      "455/455 - 0s - loss: 0.1591 - accuracy: 0.9363 - val_loss: 0.1921 - val_accuracy: 0.9123\n",
      "Epoch 199/3000\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.17400\n",
      "455/455 - 0s - loss: 0.1559 - accuracy: 0.9297 - val_loss: 0.4708 - val_accuracy: 0.7807\n",
      "Epoch 200/3000\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.17400\n",
      "455/455 - 0s - loss: 0.1751 - accuracy: 0.9253 - val_loss: 0.3586 - val_accuracy: 0.8246\n",
      "Epoch 201/3000\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.17400\n",
      "455/455 - 0s - loss: 0.1543 - accuracy: 0.9319 - val_loss: 0.3139 - val_accuracy: 0.8596\n",
      "Epoch 202/3000\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.17400\n",
      "455/455 - 0s - loss: 0.1433 - accuracy: 0.9429 - val_loss: 0.1839 - val_accuracy: 0.9298\n",
      "Epoch 203/3000\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.17400\n",
      "455/455 - 0s - loss: 0.1390 - accuracy: 0.9407 - val_loss: 0.2029 - val_accuracy: 0.8947\n",
      "Epoch 204/3000\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.17400\n",
      "455/455 - 0s - loss: 0.1326 - accuracy: 0.9429 - val_loss: 0.1761 - val_accuracy: 0.9298\n",
      "Epoch 205/3000\n",
      "\n",
      "Epoch 00205: val_loss improved from 0.17400 to 0.16747, saving model to ../model/cencer205-0.1675.hdf5\n",
      "455/455 - 0s - loss: 0.1468 - accuracy: 0.9385 - val_loss: 0.1675 - val_accuracy: 0.9386\n",
      "Epoch 206/3000\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.16747\n",
      "455/455 - 0s - loss: 0.1351 - accuracy: 0.9341 - val_loss: 0.1870 - val_accuracy: 0.9211\n",
      "Epoch 207/3000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00207: val_loss did not improve from 0.16747\n",
      "455/455 - 0s - loss: 0.1417 - accuracy: 0.9385 - val_loss: 0.2056 - val_accuracy: 0.9035\n",
      "Epoch 208/3000\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.16747\n",
      "455/455 - 0s - loss: 0.1671 - accuracy: 0.9341 - val_loss: 0.2298 - val_accuracy: 0.8860\n",
      "Epoch 209/3000\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.16747\n",
      "455/455 - 0s - loss: 0.1624 - accuracy: 0.9407 - val_loss: 0.1923 - val_accuracy: 0.9386\n",
      "Epoch 210/3000\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.16747\n",
      "455/455 - 0s - loss: 0.2642 - accuracy: 0.8967 - val_loss: 0.2149 - val_accuracy: 0.8947\n",
      "Epoch 211/3000\n",
      "\n",
      "Epoch 00211: val_loss improved from 0.16747 to 0.16672, saving model to ../model/cencer211-0.1667.hdf5\n",
      "455/455 - 0s - loss: 0.2137 - accuracy: 0.9143 - val_loss: 0.1667 - val_accuracy: 0.9298\n",
      "Epoch 212/3000\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.16672\n",
      "455/455 - 0s - loss: 0.1435 - accuracy: 0.9363 - val_loss: 0.2218 - val_accuracy: 0.8947\n",
      "Epoch 213/3000\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.16672\n",
      "455/455 - 0s - loss: 0.1764 - accuracy: 0.9297 - val_loss: 0.1954 - val_accuracy: 0.9298\n",
      "Epoch 214/3000\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.16672\n",
      "455/455 - 0s - loss: 0.1524 - accuracy: 0.9363 - val_loss: 0.1749 - val_accuracy: 0.9298\n",
      "Epoch 215/3000\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.16672\n",
      "455/455 - 0s - loss: 0.1587 - accuracy: 0.9363 - val_loss: 0.2707 - val_accuracy: 0.8772\n",
      "Epoch 216/3000\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.16672\n",
      "455/455 - 0s - loss: 0.1584 - accuracy: 0.9319 - val_loss: 0.1700 - val_accuracy: 0.9386\n",
      "Epoch 217/3000\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.16672\n",
      "455/455 - 0s - loss: 0.1360 - accuracy: 0.9473 - val_loss: 0.1694 - val_accuracy: 0.9386\n",
      "Epoch 218/3000\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.16672\n",
      "455/455 - 0s - loss: 0.1434 - accuracy: 0.9319 - val_loss: 0.4199 - val_accuracy: 0.8070\n",
      "Epoch 219/3000\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.16672\n",
      "455/455 - 0s - loss: 0.1739 - accuracy: 0.9407 - val_loss: 0.2953 - val_accuracy: 0.8684\n",
      "Epoch 220/3000\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.16672\n",
      "455/455 - 0s - loss: 0.1350 - accuracy: 0.9385 - val_loss: 0.1760 - val_accuracy: 0.9386\n",
      "Epoch 221/3000\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.16672\n",
      "455/455 - 0s - loss: 0.1326 - accuracy: 0.9429 - val_loss: 0.2507 - val_accuracy: 0.8772\n",
      "Epoch 222/3000\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.16672\n",
      "455/455 - 0s - loss: 0.1338 - accuracy: 0.9341 - val_loss: 0.2235 - val_accuracy: 0.8947\n",
      "Epoch 223/3000\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.16672\n",
      "455/455 - 0s - loss: 0.1433 - accuracy: 0.9385 - val_loss: 0.5204 - val_accuracy: 0.7632\n",
      "Epoch 224/3000\n",
      "\n",
      "Epoch 00224: val_loss improved from 0.16672 to 0.16659, saving model to ../model/cencer224-0.1666.hdf5\n",
      "455/455 - 0s - loss: 0.1871 - accuracy: 0.9253 - val_loss: 0.1666 - val_accuracy: 0.9386\n",
      "Epoch 225/3000\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.16659\n",
      "455/455 - 0s - loss: 0.1623 - accuracy: 0.9538 - val_loss: 0.2044 - val_accuracy: 0.8947\n",
      "Epoch 226/3000\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.16659\n",
      "455/455 - 0s - loss: 0.1407 - accuracy: 0.9363 - val_loss: 0.2061 - val_accuracy: 0.9386\n",
      "Epoch 227/3000\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.16659\n",
      "455/455 - 0s - loss: 0.2900 - accuracy: 0.8967 - val_loss: 0.3161 - val_accuracy: 0.8596\n",
      "Epoch 228/3000\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.16659\n",
      "455/455 - 0s - loss: 0.1626 - accuracy: 0.9407 - val_loss: 0.2745 - val_accuracy: 0.8860\n",
      "Epoch 229/3000\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.16659\n",
      "455/455 - 0s - loss: 0.1745 - accuracy: 0.9363 - val_loss: 0.2196 - val_accuracy: 0.8947\n",
      "Epoch 230/3000\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.16659\n",
      "455/455 - 0s - loss: 0.1371 - accuracy: 0.9407 - val_loss: 0.3504 - val_accuracy: 0.8421\n",
      "Epoch 231/3000\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.16659\n",
      "455/455 - 0s - loss: 0.1263 - accuracy: 0.9516 - val_loss: 0.1761 - val_accuracy: 0.9386\n",
      "Epoch 232/3000\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.16659\n",
      "455/455 - 0s - loss: 0.1420 - accuracy: 0.9407 - val_loss: 0.3272 - val_accuracy: 0.8421\n",
      "Epoch 233/3000\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.16659\n",
      "455/455 - 0s - loss: 0.1423 - accuracy: 0.9407 - val_loss: 0.1702 - val_accuracy: 0.9386\n",
      "Epoch 234/3000\n",
      "\n",
      "Epoch 00234: val_loss improved from 0.16659 to 0.16382, saving model to ../model/cencer234-0.1638.hdf5\n",
      "455/455 - 0s - loss: 0.1426 - accuracy: 0.9429 - val_loss: 0.1638 - val_accuracy: 0.9298\n",
      "Epoch 235/3000\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.16382\n",
      "455/455 - 0s - loss: 0.1997 - accuracy: 0.9297 - val_loss: 0.1905 - val_accuracy: 0.9474\n",
      "Epoch 236/3000\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.16382\n",
      "455/455 - 0s - loss: 0.1385 - accuracy: 0.9429 - val_loss: 0.3513 - val_accuracy: 0.8421\n",
      "Epoch 237/3000\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.16382\n",
      "455/455 - 0s - loss: 0.1481 - accuracy: 0.9341 - val_loss: 0.3289 - val_accuracy: 0.8509\n",
      "Epoch 238/3000\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.16382\n",
      "455/455 - 0s - loss: 0.1388 - accuracy: 0.9385 - val_loss: 0.1680 - val_accuracy: 0.9386\n",
      "Epoch 239/3000\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.16382\n",
      "455/455 - 0s - loss: 0.2494 - accuracy: 0.9011 - val_loss: 0.1806 - val_accuracy: 0.9386\n",
      "Epoch 240/3000\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.16382\n",
      "455/455 - 0s - loss: 0.1277 - accuracy: 0.9473 - val_loss: 0.2421 - val_accuracy: 0.8772\n",
      "Epoch 241/3000\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.16382\n",
      "455/455 - 0s - loss: 0.1915 - accuracy: 0.9209 - val_loss: 0.2985 - val_accuracy: 0.8684\n",
      "Epoch 242/3000\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.16382\n",
      "455/455 - 0s - loss: 0.1214 - accuracy: 0.9495 - val_loss: 0.2168 - val_accuracy: 0.8947\n",
      "Epoch 243/3000\n",
      "\n",
      "Epoch 00243: val_loss improved from 0.16382 to 0.15959, saving model to ../model/cencer243-0.1596.hdf5\n",
      "455/455 - 0s - loss: 0.1499 - accuracy: 0.9363 - val_loss: 0.1596 - val_accuracy: 0.9298\n",
      "Epoch 244/3000\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.15959\n",
      "455/455 - 0s - loss: 0.1421 - accuracy: 0.9429 - val_loss: 0.1796 - val_accuracy: 0.9298\n",
      "Epoch 245/3000\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.15959\n",
      "455/455 - 0s - loss: 0.1441 - accuracy: 0.9319 - val_loss: 0.2099 - val_accuracy: 0.9035\n",
      "Epoch 246/3000\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.15959\n",
      "455/455 - 0s - loss: 0.1308 - accuracy: 0.9341 - val_loss: 0.1730 - val_accuracy: 0.9474\n",
      "Epoch 247/3000\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.15959\n",
      "455/455 - 0s - loss: 0.1332 - accuracy: 0.9429 - val_loss: 0.2050 - val_accuracy: 0.9035\n",
      "Epoch 248/3000\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.15959\n",
      "455/455 - 0s - loss: 0.1226 - accuracy: 0.9451 - val_loss: 0.1798 - val_accuracy: 0.9386\n",
      "Epoch 249/3000\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.15959\n",
      "455/455 - 0s - loss: 0.1565 - accuracy: 0.9516 - val_loss: 0.1790 - val_accuracy: 0.9298\n",
      "Epoch 250/3000\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.15959\n",
      "455/455 - 0s - loss: 0.1415 - accuracy: 0.9385 - val_loss: 0.1617 - val_accuracy: 0.9474\n",
      "Epoch 251/3000\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.15959\n",
      "455/455 - 0s - loss: 0.1213 - accuracy: 0.9429 - val_loss: 0.1837 - val_accuracy: 0.9386\n",
      "Epoch 252/3000\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.15959\n",
      "455/455 - 0s - loss: 0.1271 - accuracy: 0.9473 - val_loss: 0.4466 - val_accuracy: 0.7719\n",
      "Epoch 253/3000\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.15959\n",
      "455/455 - 0s - loss: 0.1466 - accuracy: 0.9451 - val_loss: 0.4169 - val_accuracy: 0.8070\n",
      "Epoch 254/3000\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.15959\n",
      "455/455 - 0s - loss: 0.1786 - accuracy: 0.9209 - val_loss: 0.1764 - val_accuracy: 0.9474\n",
      "Epoch 255/3000\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.15959\n",
      "455/455 - 0s - loss: 0.1302 - accuracy: 0.9473 - val_loss: 0.3472 - val_accuracy: 0.8509\n",
      "Epoch 256/3000\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.15959\n",
      "455/455 - 0s - loss: 0.1350 - accuracy: 0.9429 - val_loss: 0.7615 - val_accuracy: 0.6579\n",
      "Epoch 257/3000\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.15959\n",
      "455/455 - 0s - loss: 0.2218 - accuracy: 0.9143 - val_loss: 0.4248 - val_accuracy: 0.7895\n",
      "Epoch 258/3000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00258: val_loss did not improve from 0.15959\n",
      "455/455 - 0s - loss: 0.1688 - accuracy: 0.9363 - val_loss: 0.1633 - val_accuracy: 0.9386\n",
      "Epoch 259/3000\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.15959\n",
      "455/455 - 0s - loss: 0.1282 - accuracy: 0.9363 - val_loss: 0.1645 - val_accuracy: 0.9298\n",
      "Epoch 260/3000\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.15959\n",
      "455/455 - 0s - loss: 0.1274 - accuracy: 0.9473 - val_loss: 0.1851 - val_accuracy: 0.9211\n",
      "Epoch 261/3000\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.15959\n",
      "455/455 - 0s - loss: 0.1285 - accuracy: 0.9429 - val_loss: 0.1642 - val_accuracy: 0.9474\n",
      "Epoch 262/3000\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.15959\n",
      "455/455 - 0s - loss: 0.1657 - accuracy: 0.9275 - val_loss: 0.2885 - val_accuracy: 0.8684\n",
      "Epoch 263/3000\n",
      "\n",
      "Epoch 00263: val_loss improved from 0.15959 to 0.15498, saving model to ../model/cencer263-0.1550.hdf5\n",
      "455/455 - 0s - loss: 0.1420 - accuracy: 0.9429 - val_loss: 0.1550 - val_accuracy: 0.9298\n",
      "Epoch 264/3000\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.15498\n",
      "455/455 - 0s - loss: 0.1300 - accuracy: 0.9407 - val_loss: 0.1684 - val_accuracy: 0.9386\n",
      "Epoch 265/3000\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.15498\n",
      "455/455 - 0s - loss: 0.2033 - accuracy: 0.9187 - val_loss: 0.3849 - val_accuracy: 0.8421\n",
      "Epoch 266/3000\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.15498\n",
      "455/455 - 0s - loss: 0.1382 - accuracy: 0.9429 - val_loss: 0.1945 - val_accuracy: 0.9123\n",
      "Epoch 267/3000\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.15498\n",
      "455/455 - 0s - loss: 0.1198 - accuracy: 0.9451 - val_loss: 0.3464 - val_accuracy: 0.8596\n",
      "Epoch 268/3000\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.15498\n",
      "455/455 - 0s - loss: 0.1217 - accuracy: 0.9516 - val_loss: 0.2187 - val_accuracy: 0.9035\n",
      "Epoch 269/3000\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.15498\n",
      "455/455 - 0s - loss: 0.2488 - accuracy: 0.9099 - val_loss: 0.1736 - val_accuracy: 0.9386\n",
      "Epoch 270/3000\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.15498\n",
      "455/455 - 0s - loss: 0.1699 - accuracy: 0.9209 - val_loss: 0.1666 - val_accuracy: 0.9386\n",
      "Epoch 271/3000\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.15498\n",
      "455/455 - 0s - loss: 0.1718 - accuracy: 0.9319 - val_loss: 0.2116 - val_accuracy: 0.8860\n",
      "Epoch 272/3000\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.15498\n",
      "455/455 - 0s - loss: 0.1358 - accuracy: 0.9473 - val_loss: 0.1594 - val_accuracy: 0.9386\n",
      "Epoch 273/3000\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.15498\n",
      "455/455 - 0s - loss: 0.1260 - accuracy: 0.9473 - val_loss: 0.1556 - val_accuracy: 0.9386\n",
      "Epoch 274/3000\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.15498\n",
      "455/455 - 0s - loss: 0.1406 - accuracy: 0.9429 - val_loss: 0.1702 - val_accuracy: 0.9474\n",
      "Epoch 275/3000\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.15498\n",
      "455/455 - 0s - loss: 0.1366 - accuracy: 0.9451 - val_loss: 0.1633 - val_accuracy: 0.9474\n",
      "Epoch 276/3000\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.15498\n",
      "455/455 - 0s - loss: 0.1277 - accuracy: 0.9495 - val_loss: 0.2304 - val_accuracy: 0.9035\n",
      "Epoch 277/3000\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.15498\n",
      "455/455 - 0s - loss: 0.1373 - accuracy: 0.9341 - val_loss: 0.1958 - val_accuracy: 0.9386\n",
      "Epoch 278/3000\n",
      "\n",
      "Epoch 00278: val_loss improved from 0.15498 to 0.14831, saving model to ../model/cencer278-0.1483.hdf5\n",
      "455/455 - 0s - loss: 0.1341 - accuracy: 0.9516 - val_loss: 0.1483 - val_accuracy: 0.9298\n",
      "Epoch 279/3000\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.14831\n",
      "455/455 - 0s - loss: 0.2266 - accuracy: 0.9033 - val_loss: 0.2400 - val_accuracy: 0.8860\n",
      "Epoch 280/3000\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.14831\n",
      "455/455 - 0s - loss: 0.1230 - accuracy: 0.9451 - val_loss: 0.1570 - val_accuracy: 0.9386\n",
      "Epoch 281/3000\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.14831\n",
      "455/455 - 0s - loss: 0.1245 - accuracy: 0.9385 - val_loss: 0.2035 - val_accuracy: 0.8947\n",
      "Epoch 282/3000\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.14831\n",
      "455/455 - 0s - loss: 0.1338 - accuracy: 0.9385 - val_loss: 0.1659 - val_accuracy: 0.9386\n",
      "Epoch 283/3000\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.14831\n",
      "455/455 - 0s - loss: 0.2040 - accuracy: 0.9385 - val_loss: 0.1733 - val_accuracy: 0.9474\n",
      "Epoch 284/3000\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.14831\n",
      "455/455 - 0s - loss: 0.1398 - accuracy: 0.9429 - val_loss: 0.1549 - val_accuracy: 0.9386\n",
      "Epoch 285/3000\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.14831\n",
      "455/455 - 0s - loss: 0.1301 - accuracy: 0.9473 - val_loss: 0.2774 - val_accuracy: 0.8684\n",
      "Epoch 286/3000\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.14831\n",
      "455/455 - 0s - loss: 0.1895 - accuracy: 0.9231 - val_loss: 0.1771 - val_accuracy: 0.9474\n",
      "Epoch 287/3000\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.14831\n",
      "455/455 - 0s - loss: 0.1328 - accuracy: 0.9451 - val_loss: 0.1496 - val_accuracy: 0.9386\n",
      "Epoch 288/3000\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.14831\n",
      "455/455 - 0s - loss: 0.1588 - accuracy: 0.9297 - val_loss: 0.3555 - val_accuracy: 0.8333\n",
      "Epoch 289/3000\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.14831\n",
      "455/455 - 0s - loss: 0.1721 - accuracy: 0.9363 - val_loss: 0.1659 - val_accuracy: 0.9474\n",
      "Epoch 290/3000\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.14831\n",
      "455/455 - 0s - loss: 0.1161 - accuracy: 0.9495 - val_loss: 0.3546 - val_accuracy: 0.8421\n",
      "Epoch 291/3000\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.14831\n",
      "455/455 - 0s - loss: 0.1151 - accuracy: 0.9560 - val_loss: 0.1821 - val_accuracy: 0.9123\n",
      "Epoch 292/3000\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.14831\n",
      "455/455 - 0s - loss: 0.1532 - accuracy: 0.9407 - val_loss: 0.2813 - val_accuracy: 0.8684\n",
      "Epoch 293/3000\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.14831\n",
      "455/455 - 0s - loss: 0.1230 - accuracy: 0.9473 - val_loss: 0.1779 - val_accuracy: 0.9298\n",
      "Epoch 294/3000\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.14831\n",
      "455/455 - 0s - loss: 0.1110 - accuracy: 0.9560 - val_loss: 0.1581 - val_accuracy: 0.9474\n",
      "Epoch 295/3000\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.14831\n",
      "455/455 - 0s - loss: 0.1560 - accuracy: 0.9407 - val_loss: 0.3050 - val_accuracy: 0.8684\n",
      "Epoch 296/3000\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.14831\n",
      "455/455 - 0s - loss: 0.1189 - accuracy: 0.9538 - val_loss: 0.1781 - val_accuracy: 0.9211\n",
      "Epoch 297/3000\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.14831\n",
      "455/455 - 0s - loss: 0.1104 - accuracy: 0.9538 - val_loss: 0.1498 - val_accuracy: 0.9386\n",
      "Epoch 298/3000\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.14831\n",
      "455/455 - 0s - loss: 0.1231 - accuracy: 0.9495 - val_loss: 0.1779 - val_accuracy: 0.9474\n",
      "Epoch 299/3000\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.14831\n",
      "455/455 - 0s - loss: 0.1129 - accuracy: 0.9451 - val_loss: 0.2404 - val_accuracy: 0.8860\n",
      "Epoch 300/3000\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.14831\n",
      "455/455 - 0s - loss: 0.1228 - accuracy: 0.9516 - val_loss: 0.2480 - val_accuracy: 0.8860\n",
      "Epoch 301/3000\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 0.14831\n",
      "455/455 - 0s - loss: 0.1121 - accuracy: 0.9473 - val_loss: 0.1874 - val_accuracy: 0.9035\n",
      "Epoch 302/3000\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 0.14831\n",
      "455/455 - 0s - loss: 0.1304 - accuracy: 0.9495 - val_loss: 0.2104 - val_accuracy: 0.9561\n",
      "Epoch 303/3000\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 0.14831\n",
      "455/455 - 0s - loss: 0.2841 - accuracy: 0.8769 - val_loss: 0.4793 - val_accuracy: 0.7895\n",
      "Epoch 304/3000\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 0.14831\n",
      "455/455 - 0s - loss: 0.1815 - accuracy: 0.9363 - val_loss: 0.1565 - val_accuracy: 0.9386\n",
      "Epoch 305/3000\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 0.14831\n",
      "455/455 - 0s - loss: 0.1210 - accuracy: 0.9538 - val_loss: 0.1729 - val_accuracy: 0.9298\n",
      "Epoch 306/3000\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 0.14831\n",
      "455/455 - 0s - loss: 0.2254 - accuracy: 0.9055 - val_loss: 0.1575 - val_accuracy: 0.9386\n",
      "Epoch 307/3000\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 0.14831\n",
      "455/455 - 0s - loss: 0.1430 - accuracy: 0.9473 - val_loss: 0.1522 - val_accuracy: 0.9386\n",
      "Epoch 308/3000\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 0.14831\n",
      "455/455 - 0s - loss: 0.1338 - accuracy: 0.9473 - val_loss: 0.4876 - val_accuracy: 0.7544\n",
      "Epoch 309/3000\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 0.14831\n",
      "455/455 - 0s - loss: 0.1376 - accuracy: 0.9473 - val_loss: 0.1618 - val_accuracy: 0.9474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 310/3000\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 0.14831\n",
      "455/455 - 0s - loss: 0.1232 - accuracy: 0.9451 - val_loss: 0.2941 - val_accuracy: 0.8596\n",
      "Epoch 311/3000\n",
      "\n",
      "Epoch 00311: val_loss improved from 0.14831 to 0.14215, saving model to ../model/cencer311-0.1422.hdf5\n",
      "455/455 - 0s - loss: 0.1326 - accuracy: 0.9451 - val_loss: 0.1422 - val_accuracy: 0.9474\n",
      "Epoch 312/3000\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1182 - accuracy: 0.9451 - val_loss: 0.1472 - val_accuracy: 0.9474\n",
      "Epoch 313/3000\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1406 - accuracy: 0.9451 - val_loss: 0.2208 - val_accuracy: 0.8947\n",
      "Epoch 314/3000\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1181 - accuracy: 0.9516 - val_loss: 0.1941 - val_accuracy: 0.9123\n",
      "Epoch 315/3000\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1230 - accuracy: 0.9538 - val_loss: 0.1770 - val_accuracy: 0.9386\n",
      "Epoch 316/3000\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1193 - accuracy: 0.9582 - val_loss: 0.1733 - val_accuracy: 0.9386\n",
      "Epoch 317/3000\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1088 - accuracy: 0.9495 - val_loss: 0.2104 - val_accuracy: 0.9211\n",
      "Epoch 318/3000\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1394 - accuracy: 0.9516 - val_loss: 0.2489 - val_accuracy: 0.9035\n",
      "Epoch 319/3000\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1123 - accuracy: 0.9429 - val_loss: 0.1424 - val_accuracy: 0.9474\n",
      "Epoch 320/3000\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1367 - accuracy: 0.9385 - val_loss: 1.5635 - val_accuracy: 0.3772\n",
      "Epoch 321/3000\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 2.9975 - accuracy: 0.6527 - val_loss: 0.6442 - val_accuracy: 0.9211\n",
      "Epoch 322/3000\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 6.7385 - accuracy: 0.5033 - val_loss: 3.4779 - val_accuracy: 0.2281\n",
      "Epoch 323/3000\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 1.7287 - accuracy: 0.5846 - val_loss: 4.1394 - val_accuracy: 0.2281\n",
      "Epoch 324/3000\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.9568 - accuracy: 0.7912 - val_loss: 0.3012 - val_accuracy: 0.9035\n",
      "Epoch 325/3000\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.2696 - accuracy: 0.9011 - val_loss: 0.7165 - val_accuracy: 0.7982\n",
      "Epoch 326/3000\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 1.8562 - accuracy: 0.5582 - val_loss: 0.3398 - val_accuracy: 0.9035\n",
      "Epoch 327/3000\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.4989 - accuracy: 0.8242 - val_loss: 0.2393 - val_accuracy: 0.9211\n",
      "Epoch 328/3000\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.2207 - accuracy: 0.9143 - val_loss: 0.2480 - val_accuracy: 0.9298\n",
      "Epoch 329/3000\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.2368 - accuracy: 0.9099 - val_loss: 0.2793 - val_accuracy: 0.9123\n",
      "Epoch 330/3000\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1735 - accuracy: 0.9319 - val_loss: 0.1910 - val_accuracy: 0.9298\n",
      "Epoch 331/3000\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1740 - accuracy: 0.9319 - val_loss: 0.1885 - val_accuracy: 0.9298\n",
      "Epoch 332/3000\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1698 - accuracy: 0.9297 - val_loss: 0.1837 - val_accuracy: 0.9298\n",
      "Epoch 333/3000\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1725 - accuracy: 0.9297 - val_loss: 0.2454 - val_accuracy: 0.9123\n",
      "Epoch 334/3000\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1562 - accuracy: 0.9341 - val_loss: 0.1864 - val_accuracy: 0.9386\n",
      "Epoch 335/3000\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.2066 - accuracy: 0.9187 - val_loss: 0.2550 - val_accuracy: 0.9035\n",
      "Epoch 336/3000\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1712 - accuracy: 0.9297 - val_loss: 0.1852 - val_accuracy: 0.9211\n",
      "Epoch 337/3000\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1587 - accuracy: 0.9275 - val_loss: 0.2704 - val_accuracy: 0.9035\n",
      "Epoch 338/3000\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1590 - accuracy: 0.9385 - val_loss: 0.2608 - val_accuracy: 0.9035\n",
      "Epoch 339/3000\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1470 - accuracy: 0.9429 - val_loss: 0.2037 - val_accuracy: 0.9211\n",
      "Epoch 340/3000\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1488 - accuracy: 0.9341 - val_loss: 0.2427 - val_accuracy: 0.9123\n",
      "Epoch 341/3000\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1485 - accuracy: 0.9363 - val_loss: 0.2223 - val_accuracy: 0.9123\n",
      "Epoch 342/3000\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1524 - accuracy: 0.9363 - val_loss: 0.1885 - val_accuracy: 0.9386\n",
      "Epoch 343/3000\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.2062 - accuracy: 0.9209 - val_loss: 0.1724 - val_accuracy: 0.9298\n",
      "Epoch 344/3000\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1609 - accuracy: 0.9363 - val_loss: 0.1885 - val_accuracy: 0.9211\n",
      "Epoch 345/3000\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1524 - accuracy: 0.9319 - val_loss: 0.3420 - val_accuracy: 0.8421\n",
      "Epoch 346/3000\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1544 - accuracy: 0.9275 - val_loss: 0.2448 - val_accuracy: 0.9123\n",
      "Epoch 347/3000\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1516 - accuracy: 0.9407 - val_loss: 0.1708 - val_accuracy: 0.9298\n",
      "Epoch 348/3000\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1643 - accuracy: 0.9319 - val_loss: 0.1764 - val_accuracy: 0.9298\n",
      "Epoch 349/3000\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1534 - accuracy: 0.9319 - val_loss: 0.1868 - val_accuracy: 0.9211\n",
      "Epoch 350/3000\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1522 - accuracy: 0.9451 - val_loss: 0.1720 - val_accuracy: 0.9298\n",
      "Epoch 351/3000\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1477 - accuracy: 0.9385 - val_loss: 0.1910 - val_accuracy: 0.9298\n",
      "Epoch 352/3000\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1608 - accuracy: 0.9297 - val_loss: 0.1662 - val_accuracy: 0.9298\n",
      "Epoch 353/3000\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1418 - accuracy: 0.9363 - val_loss: 0.2894 - val_accuracy: 0.8596\n",
      "Epoch 354/3000\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1472 - accuracy: 0.9385 - val_loss: 0.1639 - val_accuracy: 0.9298\n",
      "Epoch 355/3000\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1468 - accuracy: 0.9341 - val_loss: 0.3106 - val_accuracy: 0.8509\n",
      "Epoch 356/3000\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1672 - accuracy: 0.9297 - val_loss: 0.1695 - val_accuracy: 0.9298\n",
      "Epoch 357/3000\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1442 - accuracy: 0.9341 - val_loss: 0.2542 - val_accuracy: 0.9123\n",
      "Epoch 358/3000\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1497 - accuracy: 0.9407 - val_loss: 0.2283 - val_accuracy: 0.9123\n",
      "Epoch 359/3000\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1430 - accuracy: 0.9407 - val_loss: 0.3243 - val_accuracy: 0.8509\n",
      "Epoch 360/3000\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1505 - accuracy: 0.9363 - val_loss: 0.1920 - val_accuracy: 0.9298\n",
      "Epoch 361/3000\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1402 - accuracy: 0.9363 - val_loss: 0.2045 - val_accuracy: 0.9298\n",
      "Epoch 362/3000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00362: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1368 - accuracy: 0.9363 - val_loss: 0.1704 - val_accuracy: 0.9298\n",
      "Epoch 363/3000\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1829 - accuracy: 0.9297 - val_loss: 0.3764 - val_accuracy: 0.8246\n",
      "Epoch 364/3000\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1571 - accuracy: 0.9319 - val_loss: 0.3075 - val_accuracy: 0.8509\n",
      "Epoch 365/3000\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1437 - accuracy: 0.9429 - val_loss: 0.2300 - val_accuracy: 0.9123\n",
      "Epoch 366/3000\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1652 - accuracy: 0.9363 - val_loss: 0.1696 - val_accuracy: 0.9386\n",
      "Epoch 367/3000\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1609 - accuracy: 0.9363 - val_loss: 0.1682 - val_accuracy: 0.9386\n",
      "Epoch 368/3000\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1387 - accuracy: 0.9407 - val_loss: 0.1826 - val_accuracy: 0.9298\n",
      "Epoch 369/3000\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1379 - accuracy: 0.9385 - val_loss: 0.2601 - val_accuracy: 0.9035\n",
      "Epoch 370/3000\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1360 - accuracy: 0.9407 - val_loss: 0.1605 - val_accuracy: 0.9386\n",
      "Epoch 371/3000\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1374 - accuracy: 0.9407 - val_loss: 0.3740 - val_accuracy: 0.8246\n",
      "Epoch 372/3000\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1392 - accuracy: 0.9429 - val_loss: 0.1673 - val_accuracy: 0.9298\n",
      "Epoch 373/3000\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1420 - accuracy: 0.9407 - val_loss: 0.3200 - val_accuracy: 0.8509\n",
      "Epoch 374/3000\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1603 - accuracy: 0.9275 - val_loss: 0.2141 - val_accuracy: 0.9211\n",
      "Epoch 375/3000\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1488 - accuracy: 0.9385 - val_loss: 0.3804 - val_accuracy: 0.8158\n",
      "Epoch 376/3000\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1781 - accuracy: 0.9385 - val_loss: 0.1901 - val_accuracy: 0.9386\n",
      "Epoch 377/3000\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1360 - accuracy: 0.9341 - val_loss: 0.1618 - val_accuracy: 0.9298\n",
      "Epoch 378/3000\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1332 - accuracy: 0.9385 - val_loss: 0.1618 - val_accuracy: 0.9474\n",
      "Epoch 379/3000\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1364 - accuracy: 0.9407 - val_loss: 0.1584 - val_accuracy: 0.9386\n",
      "Epoch 380/3000\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1285 - accuracy: 0.9385 - val_loss: 0.1682 - val_accuracy: 0.9386\n",
      "Epoch 381/3000\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1282 - accuracy: 0.9407 - val_loss: 0.1557 - val_accuracy: 0.9474\n",
      "Epoch 382/3000\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1349 - accuracy: 0.9429 - val_loss: 0.3817 - val_accuracy: 0.8158\n",
      "Epoch 383/3000\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1487 - accuracy: 0.9385 - val_loss: 0.2130 - val_accuracy: 0.9211\n",
      "Epoch 384/3000\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1493 - accuracy: 0.9341 - val_loss: 0.1714 - val_accuracy: 0.9474\n",
      "Epoch 385/3000\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1346 - accuracy: 0.9451 - val_loss: 0.2863 - val_accuracy: 0.8596\n",
      "Epoch 386/3000\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1313 - accuracy: 0.9407 - val_loss: 0.2081 - val_accuracy: 0.9123\n",
      "Epoch 387/3000\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1256 - accuracy: 0.9407 - val_loss: 0.2966 - val_accuracy: 0.8421\n",
      "Epoch 388/3000\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1295 - accuracy: 0.9429 - val_loss: 0.1476 - val_accuracy: 0.9386\n",
      "Epoch 389/3000\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1282 - accuracy: 0.9407 - val_loss: 0.1782 - val_accuracy: 0.9386\n",
      "Epoch 390/3000\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1744 - accuracy: 0.9275 - val_loss: 0.1842 - val_accuracy: 0.9474\n",
      "Epoch 391/3000\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1561 - accuracy: 0.9341 - val_loss: 0.1567 - val_accuracy: 0.9298\n",
      "Epoch 392/3000\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1376 - accuracy: 0.9407 - val_loss: 0.2160 - val_accuracy: 0.9123\n",
      "Epoch 393/3000\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1327 - accuracy: 0.9407 - val_loss: 0.1523 - val_accuracy: 0.9298\n",
      "Epoch 394/3000\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1478 - accuracy: 0.9319 - val_loss: 0.3306 - val_accuracy: 0.8333\n",
      "Epoch 395/3000\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1296 - accuracy: 0.9385 - val_loss: 0.1598 - val_accuracy: 0.9474\n",
      "Epoch 396/3000\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1725 - accuracy: 0.9341 - val_loss: 0.2693 - val_accuracy: 0.8860\n",
      "Epoch 397/3000\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1360 - accuracy: 0.9451 - val_loss: 0.2859 - val_accuracy: 0.8684\n",
      "Epoch 398/3000\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1333 - accuracy: 0.9385 - val_loss: 0.1832 - val_accuracy: 0.9386\n",
      "Epoch 399/3000\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1257 - accuracy: 0.9341 - val_loss: 0.1585 - val_accuracy: 0.9561\n",
      "Epoch 400/3000\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1274 - accuracy: 0.9407 - val_loss: 0.2284 - val_accuracy: 0.9123\n",
      "Epoch 401/3000\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1235 - accuracy: 0.9495 - val_loss: 0.1598 - val_accuracy: 0.9474\n",
      "Epoch 402/3000\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1339 - accuracy: 0.9363 - val_loss: 0.1507 - val_accuracy: 0.9474\n",
      "Epoch 403/3000\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 0.14215\n",
      "455/455 - 0s - loss: 0.1305 - accuracy: 0.9429 - val_loss: 0.1880 - val_accuracy: 0.9298\n",
      "Epoch 404/3000\n",
      "\n",
      "Epoch 00404: val_loss improved from 0.14215 to 0.14018, saving model to ../model/cencer404-0.1402.hdf5\n",
      "455/455 - 0s - loss: 0.1339 - accuracy: 0.9407 - val_loss: 0.1402 - val_accuracy: 0.9386\n",
      "Epoch 405/3000\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 0.14018\n",
      "455/455 - 0s - loss: 0.1240 - accuracy: 0.9429 - val_loss: 0.1438 - val_accuracy: 0.9298\n",
      "Epoch 406/3000\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 0.14018\n",
      "455/455 - 0s - loss: 0.1401 - accuracy: 0.9297 - val_loss: 0.1587 - val_accuracy: 0.9474\n",
      "Epoch 407/3000\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 0.14018\n",
      "455/455 - 0s - loss: 0.1374 - accuracy: 0.9451 - val_loss: 0.2447 - val_accuracy: 0.8860\n",
      "Epoch 408/3000\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 0.14018\n",
      "455/455 - 0s - loss: 0.1269 - accuracy: 0.9451 - val_loss: 0.3749 - val_accuracy: 0.8158\n",
      "Epoch 409/3000\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 0.14018\n",
      "455/455 - 0s - loss: 0.1531 - accuracy: 0.9407 - val_loss: 0.1942 - val_accuracy: 0.9211\n",
      "Epoch 410/3000\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 0.14018\n",
      "455/455 - 0s - loss: 0.1243 - accuracy: 0.9473 - val_loss: 0.1771 - val_accuracy: 0.9474\n",
      "Epoch 411/3000\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 0.14018\n",
      "455/455 - 0s - loss: 0.1334 - accuracy: 0.9473 - val_loss: 0.1981 - val_accuracy: 0.9211\n",
      "Epoch 412/3000\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 0.14018\n",
      "455/455 - 0s - loss: 0.1285 - accuracy: 0.9407 - val_loss: 0.1591 - val_accuracy: 0.9474\n",
      "Epoch 413/3000\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 0.14018\n",
      "455/455 - 0s - loss: 0.1395 - accuracy: 0.9363 - val_loss: 0.1779 - val_accuracy: 0.9386\n",
      "Epoch 414/3000\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 0.14018\n",
      "455/455 - 0s - loss: 0.1667 - accuracy: 0.9319 - val_loss: 0.3021 - val_accuracy: 0.8509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 415/3000\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 0.14018\n",
      "455/455 - 0s - loss: 0.1531 - accuracy: 0.9385 - val_loss: 0.2941 - val_accuracy: 0.8509\n",
      "Epoch 416/3000\n",
      "\n",
      "Epoch 00416: val_loss improved from 0.14018 to 0.13954, saving model to ../model/cencer416-0.1395.hdf5\n",
      "455/455 - 0s - loss: 0.1356 - accuracy: 0.9407 - val_loss: 0.1395 - val_accuracy: 0.9386\n",
      "Epoch 417/3000\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 0.13954\n",
      "455/455 - 0s - loss: 0.1333 - accuracy: 0.9407 - val_loss: 0.1804 - val_accuracy: 0.9211\n",
      "Epoch 418/3000\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 0.13954\n",
      "455/455 - 0s - loss: 0.1359 - accuracy: 0.9407 - val_loss: 0.1789 - val_accuracy: 0.9386\n",
      "Epoch 419/3000\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 0.13954\n",
      "455/455 - 0s - loss: 0.1213 - accuracy: 0.9451 - val_loss: 0.2549 - val_accuracy: 0.8772\n",
      "Epoch 420/3000\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 0.13954\n",
      "455/455 - 0s - loss: 0.1413 - accuracy: 0.9429 - val_loss: 0.1431 - val_accuracy: 0.9386\n",
      "Epoch 421/3000\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 0.13954\n",
      "455/455 - 0s - loss: 0.1447 - accuracy: 0.9363 - val_loss: 0.1452 - val_accuracy: 0.9386\n",
      "Epoch 422/3000\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 0.13954\n",
      "455/455 - 0s - loss: 0.1249 - accuracy: 0.9495 - val_loss: 0.1859 - val_accuracy: 0.9298\n",
      "Epoch 423/3000\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 0.13954\n",
      "455/455 - 0s - loss: 0.1334 - accuracy: 0.9407 - val_loss: 0.9863 - val_accuracy: 0.5789\n",
      "Epoch 424/3000\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 0.13954\n",
      "455/455 - 0s - loss: 0.2660 - accuracy: 0.8769 - val_loss: 0.1725 - val_accuracy: 0.9474\n",
      "Epoch 425/3000\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 0.13954\n",
      "455/455 - 0s - loss: 0.1175 - accuracy: 0.9385 - val_loss: 0.2510 - val_accuracy: 0.8860\n",
      "Epoch 426/3000\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 0.13954\n",
      "455/455 - 0s - loss: 0.1208 - accuracy: 0.9385 - val_loss: 0.1960 - val_accuracy: 0.9211\n",
      "Epoch 427/3000\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 0.13954\n",
      "455/455 - 0s - loss: 0.1151 - accuracy: 0.9385 - val_loss: 0.1619 - val_accuracy: 0.9474\n",
      "Epoch 428/3000\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 0.13954\n",
      "455/455 - 0s - loss: 0.1210 - accuracy: 0.9363 - val_loss: 0.1497 - val_accuracy: 0.9561\n",
      "Epoch 429/3000\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 0.13954\n",
      "455/455 - 0s - loss: 0.1194 - accuracy: 0.9495 - val_loss: 0.1491 - val_accuracy: 0.9298\n",
      "Epoch 430/3000\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 0.13954\n",
      "455/455 - 0s - loss: 0.1541 - accuracy: 0.9385 - val_loss: 0.3801 - val_accuracy: 0.8070\n",
      "Epoch 431/3000\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 0.13954\n",
      "455/455 - 0s - loss: 0.1314 - accuracy: 0.9495 - val_loss: 0.1651 - val_accuracy: 0.9386\n",
      "Epoch 432/3000\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 0.13954\n",
      "455/455 - 0s - loss: 0.1180 - accuracy: 0.9385 - val_loss: 0.3924 - val_accuracy: 0.7895\n",
      "Epoch 433/3000\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 0.13954\n",
      "455/455 - 0s - loss: 0.1323 - accuracy: 0.9451 - val_loss: 0.1747 - val_accuracy: 0.9298\n",
      "Epoch 434/3000\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 0.13954\n",
      "455/455 - 0s - loss: 0.1204 - accuracy: 0.9538 - val_loss: 0.2326 - val_accuracy: 0.8860\n",
      "Epoch 435/3000\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 0.13954\n",
      "455/455 - 0s - loss: 0.1149 - accuracy: 0.9473 - val_loss: 0.4185 - val_accuracy: 0.7719\n",
      "Epoch 436/3000\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 0.13954\n",
      "455/455 - 0s - loss: 0.1552 - accuracy: 0.9319 - val_loss: 0.3841 - val_accuracy: 0.8070\n",
      "Epoch 437/3000\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 0.13954\n",
      "455/455 - 0s - loss: 0.1321 - accuracy: 0.9516 - val_loss: 0.2924 - val_accuracy: 0.8509\n",
      "Epoch 438/3000\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 0.13954\n",
      "455/455 - 0s - loss: 0.1293 - accuracy: 0.9473 - val_loss: 0.2888 - val_accuracy: 0.8509\n",
      "Epoch 439/3000\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 0.13954\n",
      "455/455 - 0s - loss: 0.1400 - accuracy: 0.9495 - val_loss: 0.2202 - val_accuracy: 0.9035\n",
      "Epoch 440/3000\n",
      "\n",
      "Epoch 00440: val_loss improved from 0.13954 to 0.13748, saving model to ../model/cencer440-0.1375.hdf5\n",
      "455/455 - 0s - loss: 0.1366 - accuracy: 0.9473 - val_loss: 0.1375 - val_accuracy: 0.9474\n",
      "Epoch 441/3000\n",
      "\n",
      "Epoch 00441: val_loss improved from 0.13748 to 0.13483, saving model to ../model/cencer441-0.1348.hdf5\n",
      "455/455 - 0s - loss: 0.1265 - accuracy: 0.9495 - val_loss: 0.1348 - val_accuracy: 0.9386\n",
      "Epoch 442/3000\n",
      "\n",
      "Epoch 00442: val_loss improved from 0.13483 to 0.12980, saving model to ../model/cencer442-0.1298.hdf5\n",
      "455/455 - 0s - loss: 0.1243 - accuracy: 0.9451 - val_loss: 0.1298 - val_accuracy: 0.9386\n",
      "Epoch 443/3000\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 0.12980\n",
      "455/455 - 0s - loss: 0.1041 - accuracy: 0.9495 - val_loss: 0.1537 - val_accuracy: 0.9386\n",
      "Epoch 444/3000\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 0.12980\n",
      "455/455 - 0s - loss: 0.1169 - accuracy: 0.9604 - val_loss: 0.1330 - val_accuracy: 0.9474\n",
      "Epoch 445/3000\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 0.12980\n",
      "455/455 - 0s - loss: 0.1438 - accuracy: 0.9385 - val_loss: 0.3596 - val_accuracy: 0.8070\n",
      "Epoch 446/3000\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 0.12980\n",
      "455/455 - 0s - loss: 0.1285 - accuracy: 0.9451 - val_loss: 0.1977 - val_accuracy: 0.9211\n",
      "Epoch 447/3000\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 0.12980\n",
      "455/455 - 0s - loss: 0.1091 - accuracy: 0.9451 - val_loss: 0.1739 - val_accuracy: 0.9298\n",
      "Epoch 448/3000\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 0.12980\n",
      "455/455 - 0s - loss: 0.1093 - accuracy: 0.9538 - val_loss: 0.2137 - val_accuracy: 0.9035\n",
      "Epoch 449/3000\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 0.12980\n",
      "455/455 - 0s - loss: 0.1107 - accuracy: 0.9451 - val_loss: 0.1651 - val_accuracy: 0.9386\n",
      "Epoch 450/3000\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 0.12980\n",
      "455/455 - 0s - loss: 0.1171 - accuracy: 0.9473 - val_loss: 0.2433 - val_accuracy: 0.8860\n",
      "Epoch 451/3000\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 0.12980\n",
      "455/455 - 0s - loss: 0.1521 - accuracy: 0.9297 - val_loss: 0.6754 - val_accuracy: 0.6491\n",
      "Epoch 452/3000\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 0.12980\n",
      "455/455 - 0s - loss: 0.1678 - accuracy: 0.9319 - val_loss: 0.1597 - val_accuracy: 0.9474\n",
      "Epoch 453/3000\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 0.12980\n",
      "455/455 - 0s - loss: 0.1148 - accuracy: 0.9407 - val_loss: 0.4686 - val_accuracy: 0.7719\n",
      "Epoch 454/3000\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 0.12980\n",
      "455/455 - 0s - loss: 0.1389 - accuracy: 0.9363 - val_loss: 0.1478 - val_accuracy: 0.9561\n",
      "Epoch 455/3000\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 0.12980\n",
      "455/455 - 0s - loss: 0.1153 - accuracy: 0.9516 - val_loss: 0.1799 - val_accuracy: 0.9298\n",
      "Epoch 456/3000\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 0.12980\n",
      "455/455 - 0s - loss: 0.1066 - accuracy: 0.9473 - val_loss: 0.2473 - val_accuracy: 0.8860\n",
      "Epoch 457/3000\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 0.12980\n",
      "455/455 - 0s - loss: 0.1170 - accuracy: 0.9429 - val_loss: 0.1375 - val_accuracy: 0.9561\n",
      "Epoch 458/3000\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 0.12980\n",
      "455/455 - 0s - loss: 0.1656 - accuracy: 0.9253 - val_loss: 0.2340 - val_accuracy: 0.8947\n",
      "Epoch 459/3000\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 0.12980\n",
      "455/455 - 0s - loss: 0.1090 - accuracy: 0.9473 - val_loss: 0.2331 - val_accuracy: 0.8860\n",
      "Epoch 460/3000\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 0.12980\n",
      "455/455 - 0s - loss: 0.1120 - accuracy: 0.9495 - val_loss: 0.1970 - val_accuracy: 0.9211\n",
      "Epoch 461/3000\n",
      "\n",
      "Epoch 00461: val_loss improved from 0.12980 to 0.12759, saving model to ../model/cencer461-0.1276.hdf5\n",
      "455/455 - 0s - loss: 0.1115 - accuracy: 0.9473 - val_loss: 0.1276 - val_accuracy: 0.9474\n",
      "Epoch 462/3000\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 0.12759\n",
      "455/455 - 0s - loss: 0.1256 - accuracy: 0.9648 - val_loss: 0.1862 - val_accuracy: 0.9298\n",
      "Epoch 463/3000\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 0.12759\n",
      "455/455 - 0s - loss: 0.1137 - accuracy: 0.9407 - val_loss: 0.1299 - val_accuracy: 0.9386\n",
      "Epoch 464/3000\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 0.12759\n",
      "455/455 - 0s - loss: 0.1377 - accuracy: 0.9407 - val_loss: 0.1739 - val_accuracy: 0.9298\n",
      "Epoch 465/3000\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 0.12759\n",
      "455/455 - 0s - loss: 0.1161 - accuracy: 0.9429 - val_loss: 0.3002 - val_accuracy: 0.8509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 466/3000\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 0.12759\n",
      "455/455 - 0s - loss: 0.1140 - accuracy: 0.9451 - val_loss: 0.2005 - val_accuracy: 0.9298\n",
      "Epoch 467/3000\n",
      "\n",
      "Epoch 00467: val_loss improved from 0.12759 to 0.12185, saving model to ../model/cencer467-0.1219.hdf5\n",
      "455/455 - 0s - loss: 0.1075 - accuracy: 0.9495 - val_loss: 0.1219 - val_accuracy: 0.9474\n",
      "Epoch 468/3000\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 0.12185\n",
      "455/455 - 0s - loss: 0.1144 - accuracy: 0.9451 - val_loss: 0.6736 - val_accuracy: 0.6491\n",
      "Epoch 469/3000\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 0.12185\n",
      "455/455 - 0s - loss: 0.2041 - accuracy: 0.9165 - val_loss: 0.1342 - val_accuracy: 0.9561\n",
      "Epoch 470/3000\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 0.12185\n",
      "455/455 - 0s - loss: 0.1259 - accuracy: 0.9429 - val_loss: 0.2580 - val_accuracy: 0.8684\n",
      "Epoch 471/3000\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 0.12185\n",
      "455/455 - 0s - loss: 0.1086 - accuracy: 0.9451 - val_loss: 0.1363 - val_accuracy: 0.9561\n",
      "Epoch 472/3000\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 0.12185\n",
      "455/455 - 0s - loss: 0.1089 - accuracy: 0.9495 - val_loss: 0.2251 - val_accuracy: 0.8947\n",
      "Epoch 473/3000\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 0.12185\n",
      "455/455 - 0s - loss: 0.1092 - accuracy: 0.9538 - val_loss: 0.5229 - val_accuracy: 0.7368\n",
      "Epoch 474/3000\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 0.12185\n",
      "455/455 - 0s - loss: 0.1360 - accuracy: 0.9385 - val_loss: 0.1254 - val_accuracy: 0.9386\n",
      "Epoch 475/3000\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 0.12185\n",
      "455/455 - 0s - loss: 0.1132 - accuracy: 0.9473 - val_loss: 0.1463 - val_accuracy: 0.9474\n",
      "Epoch 476/3000\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 0.12185\n",
      "455/455 - 0s - loss: 0.1079 - accuracy: 0.9516 - val_loss: 0.1512 - val_accuracy: 0.9474\n",
      "Epoch 477/3000\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 0.12185\n",
      "455/455 - 0s - loss: 0.1098 - accuracy: 0.9407 - val_loss: 0.1400 - val_accuracy: 0.9474\n",
      "Epoch 478/3000\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 0.12185\n",
      "455/455 - 0s - loss: 0.1320 - accuracy: 0.9582 - val_loss: 0.1282 - val_accuracy: 0.9474\n",
      "Epoch 479/3000\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 0.12185\n",
      "455/455 - 0s - loss: 0.1079 - accuracy: 0.9429 - val_loss: 0.1254 - val_accuracy: 0.9561\n",
      "Epoch 480/3000\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 0.12185\n",
      "455/455 - 0s - loss: 0.1102 - accuracy: 0.9495 - val_loss: 0.1783 - val_accuracy: 0.9386\n",
      "Epoch 481/3000\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 0.12185\n",
      "455/455 - 0s - loss: 0.1015 - accuracy: 0.9473 - val_loss: 0.4823 - val_accuracy: 0.7632\n",
      "Epoch 482/3000\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 0.12185\n",
      "455/455 - 0s - loss: 0.3316 - accuracy: 0.8637 - val_loss: 0.1443 - val_accuracy: 0.9561\n",
      "Epoch 483/3000\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 0.12185\n",
      "455/455 - 0s - loss: 0.1311 - accuracy: 0.9451 - val_loss: 0.2010 - val_accuracy: 0.9298\n",
      "Epoch 484/3000\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 0.12185\n",
      "455/455 - 0s - loss: 0.1297 - accuracy: 0.9429 - val_loss: 0.2211 - val_accuracy: 0.9298\n",
      "Epoch 485/3000\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 0.12185\n",
      "455/455 - 0s - loss: 0.1202 - accuracy: 0.9538 - val_loss: 0.1796 - val_accuracy: 0.9474\n",
      "Epoch 486/3000\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 0.12185\n",
      "455/455 - 0s - loss: 0.1141 - accuracy: 0.9473 - val_loss: 0.1316 - val_accuracy: 0.9386\n",
      "Epoch 487/3000\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 0.12185\n",
      "455/455 - 0s - loss: 0.1234 - accuracy: 0.9429 - val_loss: 0.2504 - val_accuracy: 0.8772\n",
      "Epoch 488/3000\n",
      "\n",
      "Epoch 00488: val_loss improved from 0.12185 to 0.11995, saving model to ../model/cencer488-0.1200.hdf5\n",
      "455/455 - 0s - loss: 0.1147 - accuracy: 0.9473 - val_loss: 0.1200 - val_accuracy: 0.9649\n",
      "Epoch 489/3000\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 0.11995\n",
      "455/455 - 0s - loss: 0.1360 - accuracy: 0.9407 - val_loss: 0.3069 - val_accuracy: 0.8509\n",
      "Epoch 490/3000\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 0.11995\n",
      "455/455 - 0s - loss: 0.1266 - accuracy: 0.9516 - val_loss: 0.4008 - val_accuracy: 0.7895\n",
      "Epoch 491/3000\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 0.11995\n",
      "455/455 - 0s - loss: 0.1210 - accuracy: 0.9516 - val_loss: 0.1932 - val_accuracy: 0.9298\n",
      "Epoch 492/3000\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 0.11995\n",
      "455/455 - 0s - loss: 0.1358 - accuracy: 0.9363 - val_loss: 0.2026 - val_accuracy: 0.9298\n",
      "Epoch 493/3000\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 0.11995\n",
      "455/455 - 0s - loss: 0.1071 - accuracy: 0.9538 - val_loss: 0.1308 - val_accuracy: 0.9474\n",
      "Epoch 494/3000\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 0.11995\n",
      "455/455 - 0s - loss: 0.1242 - accuracy: 0.9429 - val_loss: 0.3832 - val_accuracy: 0.7807\n",
      "Epoch 495/3000\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 0.11995\n",
      "455/455 - 0s - loss: 0.1218 - accuracy: 0.9451 - val_loss: 0.1554 - val_accuracy: 0.9474\n",
      "Epoch 496/3000\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 0.11995\n",
      "455/455 - 0s - loss: 0.1171 - accuracy: 0.9516 - val_loss: 0.1530 - val_accuracy: 0.9474\n",
      "Epoch 497/3000\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 0.11995\n",
      "455/455 - 0s - loss: 0.1143 - accuracy: 0.9538 - val_loss: 0.1252 - val_accuracy: 0.9561\n",
      "Epoch 498/3000\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 0.11995\n",
      "455/455 - 0s - loss: 0.1391 - accuracy: 0.9341 - val_loss: 0.1844 - val_accuracy: 0.9298\n",
      "Epoch 499/3000\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 0.11995\n",
      "455/455 - 0s - loss: 0.1074 - accuracy: 0.9473 - val_loss: 0.1376 - val_accuracy: 0.9474\n",
      "Epoch 500/3000\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 0.11995\n",
      "455/455 - 0s - loss: 0.1025 - accuracy: 0.9582 - val_loss: 0.3098 - val_accuracy: 0.8333\n",
      "Epoch 501/3000\n",
      "\n",
      "Epoch 00501: val_loss did not improve from 0.11995\n",
      "455/455 - 0s - loss: 0.0993 - accuracy: 0.9604 - val_loss: 0.1594 - val_accuracy: 0.9474\n",
      "Epoch 502/3000\n",
      "\n",
      "Epoch 00502: val_loss did not improve from 0.11995\n",
      "455/455 - 0s - loss: 0.2147 - accuracy: 0.9187 - val_loss: 0.1283 - val_accuracy: 0.9561\n",
      "Epoch 503/3000\n",
      "\n",
      "Epoch 00503: val_loss did not improve from 0.11995\n",
      "455/455 - 0s - loss: 0.1239 - accuracy: 0.9429 - val_loss: 0.5463 - val_accuracy: 0.7456\n",
      "Epoch 504/3000\n",
      "\n",
      "Epoch 00504: val_loss did not improve from 0.11995\n",
      "455/455 - 0s - loss: 0.1454 - accuracy: 0.9363 - val_loss: 0.1789 - val_accuracy: 0.9386\n",
      "Epoch 505/3000\n",
      "\n",
      "Epoch 00505: val_loss did not improve from 0.11995\n",
      "455/455 - 0s - loss: 0.1105 - accuracy: 0.9473 - val_loss: 0.5282 - val_accuracy: 0.7632\n",
      "Epoch 506/3000\n",
      "\n",
      "Epoch 00506: val_loss did not improve from 0.11995\n",
      "455/455 - 0s - loss: 0.1428 - accuracy: 0.9429 - val_loss: 0.1249 - val_accuracy: 0.9474\n",
      "Epoch 507/3000\n",
      "\n",
      "Epoch 00507: val_loss did not improve from 0.11995\n",
      "455/455 - 0s - loss: 0.1331 - accuracy: 0.9429 - val_loss: 0.1512 - val_accuracy: 0.9474\n",
      "Epoch 508/3000\n",
      "\n",
      "Epoch 00508: val_loss did not improve from 0.11995\n",
      "455/455 - 0s - loss: 0.1082 - accuracy: 0.9451 - val_loss: 0.1601 - val_accuracy: 0.9386\n",
      "Epoch 509/3000\n",
      "\n",
      "Epoch 00509: val_loss did not improve from 0.11995\n",
      "455/455 - 0s - loss: 0.1016 - accuracy: 0.9495 - val_loss: 0.2301 - val_accuracy: 0.8947\n",
      "Epoch 510/3000\n",
      "\n",
      "Epoch 00510: val_loss did not improve from 0.11995\n",
      "455/455 - 0s - loss: 0.1118 - accuracy: 0.9495 - val_loss: 0.1243 - val_accuracy: 0.9649\n",
      "Epoch 511/3000\n",
      "\n",
      "Epoch 00511: val_loss improved from 0.11995 to 0.11467, saving model to ../model/cencer511-0.1147.hdf5\n",
      "455/455 - 0s - loss: 0.1028 - accuracy: 0.9604 - val_loss: 0.1147 - val_accuracy: 0.9561\n",
      "Epoch 512/3000\n",
      "\n",
      "Epoch 00512: val_loss did not improve from 0.11467\n",
      "455/455 - 0s - loss: 0.1166 - accuracy: 0.9538 - val_loss: 0.1152 - val_accuracy: 0.9474\n",
      "Epoch 513/3000\n",
      "\n",
      "Epoch 00513: val_loss did not improve from 0.11467\n",
      "455/455 - 0s - loss: 0.1083 - accuracy: 0.9407 - val_loss: 0.1658 - val_accuracy: 0.9386\n",
      "Epoch 514/3000\n",
      "\n",
      "Epoch 00514: val_loss did not improve from 0.11467\n",
      "455/455 - 0s - loss: 0.1389 - accuracy: 0.9429 - val_loss: 0.5889 - val_accuracy: 0.6930\n",
      "Epoch 515/3000\n",
      "\n",
      "Epoch 00515: val_loss did not improve from 0.11467\n",
      "455/455 - 0s - loss: 0.1419 - accuracy: 0.9385 - val_loss: 0.1308 - val_accuracy: 0.9561\n",
      "Epoch 516/3000\n",
      "\n",
      "Epoch 00516: val_loss did not improve from 0.11467\n",
      "455/455 - 0s - loss: 0.1195 - accuracy: 0.9451 - val_loss: 0.1433 - val_accuracy: 0.9474\n",
      "Epoch 517/3000\n",
      "\n",
      "Epoch 00517: val_loss did not improve from 0.11467\n",
      "455/455 - 0s - loss: 0.1219 - accuracy: 0.9451 - val_loss: 0.1746 - val_accuracy: 0.9386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 518/3000\n",
      "\n",
      "Epoch 00518: val_loss did not improve from 0.11467\n",
      "455/455 - 0s - loss: 0.1004 - accuracy: 0.9495 - val_loss: 0.1186 - val_accuracy: 0.9474\n",
      "Epoch 519/3000\n",
      "\n",
      "Epoch 00519: val_loss did not improve from 0.11467\n",
      "455/455 - 0s - loss: 0.1190 - accuracy: 0.9473 - val_loss: 0.1560 - val_accuracy: 0.9386\n",
      "Epoch 520/3000\n",
      "\n",
      "Epoch 00520: val_loss did not improve from 0.11467\n",
      "455/455 - 0s - loss: 0.1007 - accuracy: 0.9495 - val_loss: 0.3028 - val_accuracy: 0.8421\n",
      "Epoch 521/3000\n",
      "\n",
      "Epoch 00521: val_loss did not improve from 0.11467\n",
      "455/455 - 0s - loss: 0.1155 - accuracy: 0.9495 - val_loss: 0.1526 - val_accuracy: 0.9474\n",
      "Epoch 522/3000\n",
      "\n",
      "Epoch 00522: val_loss did not improve from 0.11467\n",
      "455/455 - 0s - loss: 0.1058 - accuracy: 0.9538 - val_loss: 0.1159 - val_accuracy: 0.9474\n",
      "Epoch 523/3000\n",
      "\n",
      "Epoch 00523: val_loss did not improve from 0.11467\n",
      "455/455 - 0s - loss: 0.1326 - accuracy: 0.9495 - val_loss: 0.1354 - val_accuracy: 0.9474\n",
      "Epoch 524/3000\n",
      "\n",
      "Epoch 00524: val_loss did not improve from 0.11467\n",
      "455/455 - 0s - loss: 0.1054 - accuracy: 0.9538 - val_loss: 0.1153 - val_accuracy: 0.9561\n",
      "Epoch 525/3000\n",
      "\n",
      "Epoch 00525: val_loss did not improve from 0.11467\n",
      "455/455 - 0s - loss: 0.1262 - accuracy: 0.9495 - val_loss: 0.1266 - val_accuracy: 0.9649\n",
      "Epoch 526/3000\n",
      "\n",
      "Epoch 00526: val_loss did not improve from 0.11467\n",
      "455/455 - 0s - loss: 0.1221 - accuracy: 0.9495 - val_loss: 0.3305 - val_accuracy: 0.8333\n",
      "Epoch 527/3000\n",
      "\n",
      "Epoch 00527: val_loss did not improve from 0.11467\n",
      "455/455 - 0s - loss: 0.1265 - accuracy: 0.9451 - val_loss: 0.1278 - val_accuracy: 0.9561\n",
      "Epoch 528/3000\n",
      "\n",
      "Epoch 00528: val_loss did not improve from 0.11467\n",
      "455/455 - 0s - loss: 0.1190 - accuracy: 0.9538 - val_loss: 0.1215 - val_accuracy: 0.9474\n",
      "Epoch 529/3000\n",
      "\n",
      "Epoch 00529: val_loss did not improve from 0.11467\n",
      "455/455 - 0s - loss: 0.1201 - accuracy: 0.9538 - val_loss: 0.1296 - val_accuracy: 0.9474\n",
      "Epoch 530/3000\n",
      "\n",
      "Epoch 00530: val_loss did not improve from 0.11467\n",
      "455/455 - 0s - loss: 0.0981 - accuracy: 0.9516 - val_loss: 0.1572 - val_accuracy: 0.9561\n",
      "Epoch 531/3000\n",
      "\n",
      "Epoch 00531: val_loss improved from 0.11467 to 0.11107, saving model to ../model/cencer531-0.1111.hdf5\n",
      "455/455 - 0s - loss: 0.1175 - accuracy: 0.9516 - val_loss: 0.1111 - val_accuracy: 0.9561\n",
      "Epoch 532/3000\n",
      "\n",
      "Epoch 00532: val_loss did not improve from 0.11107\n",
      "455/455 - 0s - loss: 0.3099 - accuracy: 0.8725 - val_loss: 0.1567 - val_accuracy: 0.9474\n",
      "Epoch 533/3000\n",
      "\n",
      "Epoch 00533: val_loss did not improve from 0.11107\n",
      "455/455 - 0s - loss: 0.1460 - accuracy: 0.9429 - val_loss: 0.2255 - val_accuracy: 0.9298\n",
      "Epoch 534/3000\n",
      "\n",
      "Epoch 00534: val_loss did not improve from 0.11107\n",
      "455/455 - 0s - loss: 0.1430 - accuracy: 0.9495 - val_loss: 0.1590 - val_accuracy: 0.9474\n",
      "Epoch 535/3000\n",
      "\n",
      "Epoch 00535: val_loss did not improve from 0.11107\n",
      "455/455 - 0s - loss: 0.1272 - accuracy: 0.9495 - val_loss: 0.1933 - val_accuracy: 0.9298\n",
      "Epoch 536/3000\n",
      "\n",
      "Epoch 00536: val_loss did not improve from 0.11107\n",
      "455/455 - 0s - loss: 0.1226 - accuracy: 0.9473 - val_loss: 0.1919 - val_accuracy: 0.9298\n",
      "Epoch 537/3000\n",
      "\n",
      "Epoch 00537: val_loss did not improve from 0.11107\n",
      "455/455 - 0s - loss: 0.1148 - accuracy: 0.9451 - val_loss: 0.2081 - val_accuracy: 0.9386\n",
      "Epoch 538/3000\n",
      "\n",
      "Epoch 00538: val_loss did not improve from 0.11107\n",
      "455/455 - 0s - loss: 0.1177 - accuracy: 0.9516 - val_loss: 0.2030 - val_accuracy: 0.9298\n",
      "Epoch 539/3000\n",
      "\n",
      "Epoch 00539: val_loss did not improve from 0.11107\n",
      "455/455 - 0s - loss: 0.1291 - accuracy: 0.9495 - val_loss: 0.1938 - val_accuracy: 0.9298\n",
      "Epoch 540/3000\n",
      "\n",
      "Epoch 00540: val_loss did not improve from 0.11107\n",
      "455/455 - 0s - loss: 0.1194 - accuracy: 0.9473 - val_loss: 0.1619 - val_accuracy: 0.9298\n",
      "Epoch 541/3000\n",
      "\n",
      "Epoch 00541: val_loss did not improve from 0.11107\n",
      "455/455 - 0s - loss: 0.1053 - accuracy: 0.9495 - val_loss: 0.1508 - val_accuracy: 0.9386\n",
      "Epoch 542/3000\n",
      "\n",
      "Epoch 00542: val_loss did not improve from 0.11107\n",
      "455/455 - 0s - loss: 0.1078 - accuracy: 0.9495 - val_loss: 0.5637 - val_accuracy: 0.7368\n",
      "Epoch 543/3000\n",
      "\n",
      "Epoch 00543: val_loss did not improve from 0.11107\n",
      "455/455 - 0s - loss: 0.2387 - accuracy: 0.9165 - val_loss: 0.1332 - val_accuracy: 0.9649\n",
      "Epoch 544/3000\n",
      "\n",
      "Epoch 00544: val_loss did not improve from 0.11107\n",
      "455/455 - 0s - loss: 0.1063 - accuracy: 0.9582 - val_loss: 0.1302 - val_accuracy: 0.9649\n",
      "Epoch 545/3000\n",
      "\n",
      "Epoch 00545: val_loss did not improve from 0.11107\n",
      "455/455 - 0s - loss: 0.1016 - accuracy: 0.9648 - val_loss: 0.2626 - val_accuracy: 0.8860\n",
      "Epoch 546/3000\n",
      "\n",
      "Epoch 00546: val_loss did not improve from 0.11107\n",
      "455/455 - 0s - loss: 0.1097 - accuracy: 0.9429 - val_loss: 0.1380 - val_accuracy: 0.9474\n",
      "Epoch 547/3000\n",
      "\n",
      "Epoch 00547: val_loss did not improve from 0.11107\n",
      "455/455 - 0s - loss: 0.1004 - accuracy: 0.9538 - val_loss: 0.1827 - val_accuracy: 0.9386\n",
      "Epoch 548/3000\n",
      "\n",
      "Epoch 00548: val_loss did not improve from 0.11107\n",
      "455/455 - 0s - loss: 0.1048 - accuracy: 0.9538 - val_loss: 0.1389 - val_accuracy: 0.9561\n",
      "Epoch 549/3000\n",
      "\n",
      "Epoch 00549: val_loss did not improve from 0.11107\n",
      "455/455 - 0s - loss: 0.1239 - accuracy: 0.9516 - val_loss: 0.1122 - val_accuracy: 0.9386\n",
      "Epoch 550/3000\n",
      "\n",
      "Epoch 00550: val_loss did not improve from 0.11107\n",
      "455/455 - 0s - loss: 0.1148 - accuracy: 0.9451 - val_loss: 0.1527 - val_accuracy: 0.9386\n",
      "Epoch 551/3000\n",
      "\n",
      "Epoch 00551: val_loss did not improve from 0.11107\n",
      "455/455 - 0s - loss: 0.1115 - accuracy: 0.9516 - val_loss: 0.1533 - val_accuracy: 0.9386\n",
      "Epoch 552/3000\n",
      "\n",
      "Epoch 00552: val_loss did not improve from 0.11107\n",
      "455/455 - 0s - loss: 0.0998 - accuracy: 0.9560 - val_loss: 0.1167 - val_accuracy: 0.9649\n",
      "Epoch 553/3000\n",
      "\n",
      "Epoch 00553: val_loss improved from 0.11107 to 0.11006, saving model to ../model/cencer553-0.1101.hdf5\n",
      "455/455 - 0s - loss: 0.0992 - accuracy: 0.9560 - val_loss: 0.1101 - val_accuracy: 0.9649\n",
      "Epoch 554/3000\n",
      "\n",
      "Epoch 00554: val_loss did not improve from 0.11006\n",
      "455/455 - 0s - loss: 0.1645 - accuracy: 0.9429 - val_loss: 0.1143 - val_accuracy: 0.9386\n",
      "Epoch 555/3000\n",
      "\n",
      "Epoch 00555: val_loss did not improve from 0.11006\n",
      "455/455 - 0s - loss: 0.1138 - accuracy: 0.9560 - val_loss: 0.1649 - val_accuracy: 0.9386\n",
      "Epoch 556/3000\n",
      "\n",
      "Epoch 00556: val_loss did not improve from 0.11006\n",
      "455/455 - 0s - loss: 0.0965 - accuracy: 0.9538 - val_loss: 0.1191 - val_accuracy: 0.9649\n",
      "Epoch 557/3000\n",
      "\n",
      "Epoch 00557: val_loss did not improve from 0.11006\n",
      "455/455 - 0s - loss: 0.1040 - accuracy: 0.9516 - val_loss: 0.2881 - val_accuracy: 0.8596\n",
      "Epoch 558/3000\n",
      "\n",
      "Epoch 00558: val_loss did not improve from 0.11006\n",
      "455/455 - 0s - loss: 0.1404 - accuracy: 0.9451 - val_loss: 0.1182 - val_accuracy: 0.9561\n",
      "Epoch 559/3000\n",
      "\n",
      "Epoch 00559: val_loss did not improve from 0.11006\n",
      "455/455 - 0s - loss: 0.1258 - accuracy: 0.9495 - val_loss: 0.1788 - val_accuracy: 0.9298\n",
      "Epoch 560/3000\n",
      "\n",
      "Epoch 00560: val_loss did not improve from 0.11006\n",
      "455/455 - 0s - loss: 0.0941 - accuracy: 0.9582 - val_loss: 0.1127 - val_accuracy: 0.9474\n",
      "Epoch 561/3000\n",
      "\n",
      "Epoch 00561: val_loss did not improve from 0.11006\n",
      "455/455 - 0s - loss: 0.1072 - accuracy: 0.9560 - val_loss: 0.2819 - val_accuracy: 0.8596\n",
      "Epoch 562/3000\n",
      "\n",
      "Epoch 00562: val_loss did not improve from 0.11006\n",
      "455/455 - 0s - loss: 0.1065 - accuracy: 0.9538 - val_loss: 0.1663 - val_accuracy: 0.9474\n",
      "Epoch 563/3000\n",
      "\n",
      "Epoch 00563: val_loss did not improve from 0.11006\n",
      "455/455 - 0s - loss: 0.0973 - accuracy: 0.9516 - val_loss: 0.1294 - val_accuracy: 0.9474\n",
      "Epoch 564/3000\n",
      "\n",
      "Epoch 00564: val_loss did not improve from 0.11006\n",
      "455/455 - 0s - loss: 0.0938 - accuracy: 0.9516 - val_loss: 0.2166 - val_accuracy: 0.9211\n",
      "Epoch 565/3000\n",
      "\n",
      "Epoch 00565: val_loss did not improve from 0.11006\n",
      "455/455 - 0s - loss: 0.1031 - accuracy: 0.9626 - val_loss: 0.2183 - val_accuracy: 0.9211\n",
      "Epoch 566/3000\n",
      "\n",
      "Epoch 00566: val_loss did not improve from 0.11006\n",
      "455/455 - 0s - loss: 0.1051 - accuracy: 0.9604 - val_loss: 0.4524 - val_accuracy: 0.7544\n",
      "Epoch 567/3000\n",
      "\n",
      "Epoch 00567: val_loss did not improve from 0.11006\n",
      "455/455 - 0s - loss: 0.1241 - accuracy: 0.9407 - val_loss: 0.1104 - val_accuracy: 0.9561\n",
      "Epoch 568/3000\n",
      "\n",
      "Epoch 00568: val_loss did not improve from 0.11006\n",
      "455/455 - 0s - loss: 0.0962 - accuracy: 0.9538 - val_loss: 0.1614 - val_accuracy: 0.9474\n",
      "Epoch 569/3000\n",
      "\n",
      "Epoch 00569: val_loss did not improve from 0.11006\n",
      "455/455 - 0s - loss: 0.0954 - accuracy: 0.9538 - val_loss: 0.1249 - val_accuracy: 0.9474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 570/3000\n",
      "\n",
      "Epoch 00570: val_loss did not improve from 0.11006\n",
      "455/455 - 0s - loss: 0.1082 - accuracy: 0.9516 - val_loss: 0.1197 - val_accuracy: 0.9561\n",
      "Epoch 571/3000\n",
      "\n",
      "Epoch 00571: val_loss did not improve from 0.11006\n",
      "455/455 - 0s - loss: 0.1498 - accuracy: 0.9407 - val_loss: 0.1140 - val_accuracy: 0.9561\n",
      "Epoch 572/3000\n",
      "\n",
      "Epoch 00572: val_loss did not improve from 0.11006\n",
      "455/455 - 0s - loss: 0.1168 - accuracy: 0.9429 - val_loss: 0.1634 - val_accuracy: 0.9386\n",
      "Epoch 573/3000\n",
      "\n",
      "Epoch 00573: val_loss did not improve from 0.11006\n",
      "455/455 - 0s - loss: 0.1097 - accuracy: 0.9516 - val_loss: 0.1795 - val_accuracy: 0.9386\n",
      "Epoch 574/3000\n",
      "\n",
      "Epoch 00574: val_loss did not improve from 0.11006\n",
      "455/455 - 0s - loss: 0.1189 - accuracy: 0.9516 - val_loss: 0.6067 - val_accuracy: 0.7193\n",
      "Epoch 575/3000\n",
      "\n",
      "Epoch 00575: val_loss did not improve from 0.11006\n",
      "455/455 - 0s - loss: 0.1622 - accuracy: 0.9429 - val_loss: 0.2614 - val_accuracy: 0.8772\n",
      "Epoch 576/3000\n",
      "\n",
      "Epoch 00576: val_loss did not improve from 0.11006\n",
      "455/455 - 0s - loss: 0.0988 - accuracy: 0.9516 - val_loss: 0.1115 - val_accuracy: 0.9561\n",
      "Epoch 577/3000\n",
      "\n",
      "Epoch 00577: val_loss did not improve from 0.11006\n",
      "455/455 - 0s - loss: 0.1023 - accuracy: 0.9538 - val_loss: 0.2647 - val_accuracy: 0.8596\n",
      "Epoch 578/3000\n",
      "\n",
      "Epoch 00578: val_loss did not improve from 0.11006\n",
      "455/455 - 0s - loss: 0.1551 - accuracy: 0.9385 - val_loss: 0.1173 - val_accuracy: 0.9561\n",
      "Epoch 579/3000\n",
      "\n",
      "Epoch 00579: val_loss did not improve from 0.11006\n",
      "455/455 - 0s - loss: 0.0997 - accuracy: 0.9648 - val_loss: 0.1532 - val_accuracy: 0.9386\n",
      "Epoch 580/3000\n",
      "\n",
      "Epoch 00580: val_loss did not improve from 0.11006\n",
      "455/455 - 0s - loss: 0.0987 - accuracy: 0.9538 - val_loss: 0.1343 - val_accuracy: 0.9474\n",
      "Epoch 581/3000\n",
      "\n",
      "Epoch 00581: val_loss did not improve from 0.11006\n",
      "455/455 - 0s - loss: 0.1043 - accuracy: 0.9604 - val_loss: 0.1270 - val_accuracy: 0.9474\n",
      "Epoch 582/3000\n",
      "\n",
      "Epoch 00582: val_loss did not improve from 0.11006\n",
      "455/455 - 0s - loss: 0.1235 - accuracy: 0.9538 - val_loss: 0.2690 - val_accuracy: 0.8596\n",
      "Epoch 583/3000\n",
      "\n",
      "Epoch 00583: val_loss did not improve from 0.11006\n",
      "455/455 - 0s - loss: 0.0962 - accuracy: 0.9604 - val_loss: 0.4564 - val_accuracy: 0.7632\n",
      "Epoch 584/3000\n",
      "\n",
      "Epoch 00584: val_loss did not improve from 0.11006\n",
      "455/455 - 0s - loss: 0.1349 - accuracy: 0.9495 - val_loss: 0.1122 - val_accuracy: 0.9561\n",
      "Epoch 585/3000\n",
      "\n",
      "Epoch 00585: val_loss did not improve from 0.11006\n",
      "455/455 - 0s - loss: 0.1074 - accuracy: 0.9495 - val_loss: 0.2168 - val_accuracy: 0.9211\n",
      "Epoch 586/3000\n",
      "\n",
      "Epoch 00586: val_loss did not improve from 0.11006\n",
      "455/455 - 0s - loss: 0.0899 - accuracy: 0.9626 - val_loss: 0.2504 - val_accuracy: 0.8860\n",
      "Epoch 587/3000\n",
      "\n",
      "Epoch 00587: val_loss did not improve from 0.11006\n",
      "455/455 - 0s - loss: 0.1051 - accuracy: 0.9560 - val_loss: 0.1403 - val_accuracy: 0.9386\n",
      "Epoch 588/3000\n",
      "\n",
      "Epoch 00588: val_loss improved from 0.11006 to 0.10626, saving model to ../model/cencer588-0.1063.hdf5\n",
      "455/455 - 0s - loss: 0.1102 - accuracy: 0.9582 - val_loss: 0.1063 - val_accuracy: 0.9474\n",
      "Epoch 589/3000\n",
      "\n",
      "Epoch 00589: val_loss did not improve from 0.10626\n",
      "455/455 - 0s - loss: 0.1177 - accuracy: 0.9495 - val_loss: 0.2679 - val_accuracy: 0.8596\n",
      "Epoch 590/3000\n",
      "\n",
      "Epoch 00590: val_loss did not improve from 0.10626\n",
      "455/455 - 0s - loss: 0.0950 - accuracy: 0.9560 - val_loss: 0.1933 - val_accuracy: 0.9386\n",
      "Epoch 591/3000\n",
      "\n",
      "Epoch 00591: val_loss did not improve from 0.10626\n",
      "455/455 - 0s - loss: 0.0936 - accuracy: 0.9626 - val_loss: 0.2159 - val_accuracy: 0.9211\n",
      "Epoch 592/3000\n",
      "\n",
      "Epoch 00592: val_loss did not improve from 0.10626\n",
      "455/455 - 0s - loss: 0.1234 - accuracy: 0.9516 - val_loss: 0.2061 - val_accuracy: 0.9211\n",
      "Epoch 593/3000\n",
      "\n",
      "Epoch 00593: val_loss did not improve from 0.10626\n",
      "455/455 - 0s - loss: 0.1022 - accuracy: 0.9582 - val_loss: 0.2132 - val_accuracy: 0.9211\n",
      "Epoch 594/3000\n",
      "\n",
      "Epoch 00594: val_loss did not improve from 0.10626\n",
      "455/455 - 0s - loss: 0.0968 - accuracy: 0.9495 - val_loss: 0.2188 - val_accuracy: 0.9123\n",
      "Epoch 595/3000\n",
      "\n",
      "Epoch 00595: val_loss improved from 0.10626 to 0.10534, saving model to ../model/cencer595-0.1053.hdf5\n",
      "455/455 - 0s - loss: 0.0913 - accuracy: 0.9560 - val_loss: 0.1053 - val_accuracy: 0.9649\n",
      "Epoch 596/3000\n",
      "\n",
      "Epoch 00596: val_loss did not improve from 0.10534\n",
      "455/455 - 0s - loss: 0.2312 - accuracy: 0.9187 - val_loss: 0.1440 - val_accuracy: 0.9386\n",
      "Epoch 597/3000\n",
      "\n",
      "Epoch 00597: val_loss did not improve from 0.10534\n",
      "455/455 - 0s - loss: 0.1038 - accuracy: 0.9560 - val_loss: 0.2912 - val_accuracy: 0.8596\n",
      "Epoch 598/3000\n",
      "\n",
      "Epoch 00598: val_loss did not improve from 0.10534\n",
      "455/455 - 0s - loss: 0.1195 - accuracy: 0.9538 - val_loss: 0.1839 - val_accuracy: 0.9386\n",
      "Epoch 599/3000\n",
      "\n",
      "Epoch 00599: val_loss did not improve from 0.10534\n",
      "455/455 - 0s - loss: 0.0970 - accuracy: 0.9582 - val_loss: 0.1481 - val_accuracy: 0.9386\n",
      "Epoch 600/3000\n",
      "\n",
      "Epoch 00600: val_loss did not improve from 0.10534\n",
      "455/455 - 0s - loss: 0.1073 - accuracy: 0.9538 - val_loss: 0.1303 - val_accuracy: 0.9386\n",
      "Epoch 601/3000\n",
      "\n",
      "Epoch 00601: val_loss did not improve from 0.10534\n",
      "455/455 - 0s - loss: 0.0890 - accuracy: 0.9582 - val_loss: 0.2747 - val_accuracy: 0.8509\n",
      "Epoch 602/3000\n",
      "\n",
      "Epoch 00602: val_loss did not improve from 0.10534\n",
      "455/455 - 0s - loss: 0.1183 - accuracy: 0.9538 - val_loss: 0.1265 - val_accuracy: 0.9386\n",
      "Epoch 603/3000\n",
      "\n",
      "Epoch 00603: val_loss did not improve from 0.10534\n",
      "455/455 - 0s - loss: 0.2236 - accuracy: 0.9297 - val_loss: 0.1231 - val_accuracy: 0.9561\n",
      "Epoch 604/3000\n",
      "\n",
      "Epoch 00604: val_loss did not improve from 0.10534\n",
      "455/455 - 0s - loss: 0.1170 - accuracy: 0.9451 - val_loss: 0.1189 - val_accuracy: 0.9561\n",
      "Epoch 605/3000\n",
      "\n",
      "Epoch 00605: val_loss did not improve from 0.10534\n",
      "455/455 - 0s - loss: 0.1125 - accuracy: 0.9560 - val_loss: 0.1285 - val_accuracy: 0.9649\n",
      "Epoch 606/3000\n",
      "\n",
      "Epoch 00606: val_loss did not improve from 0.10534\n",
      "455/455 - 0s - loss: 0.1068 - accuracy: 0.9538 - val_loss: 0.1443 - val_accuracy: 0.9386\n",
      "Epoch 607/3000\n",
      "\n",
      "Epoch 00607: val_loss did not improve from 0.10534\n",
      "455/455 - 0s - loss: 0.1033 - accuracy: 0.9538 - val_loss: 0.1842 - val_accuracy: 0.9386\n",
      "Epoch 608/3000\n",
      "\n",
      "Epoch 00608: val_loss did not improve from 0.10534\n",
      "455/455 - 0s - loss: 0.1036 - accuracy: 0.9473 - val_loss: 0.1090 - val_accuracy: 0.9561\n",
      "Epoch 609/3000\n",
      "\n",
      "Epoch 00609: val_loss did not improve from 0.10534\n",
      "455/455 - 0s - loss: 0.0921 - accuracy: 0.9604 - val_loss: 0.1331 - val_accuracy: 0.9386\n",
      "Epoch 610/3000\n",
      "\n",
      "Epoch 00610: val_loss did not improve from 0.10534\n",
      "455/455 - 0s - loss: 0.0947 - accuracy: 0.9692 - val_loss: 0.2368 - val_accuracy: 0.8947\n",
      "Epoch 611/3000\n",
      "\n",
      "Epoch 00611: val_loss did not improve from 0.10534\n",
      "455/455 - 0s - loss: 0.0983 - accuracy: 0.9495 - val_loss: 0.1799 - val_accuracy: 0.9386\n",
      "Epoch 612/3000\n",
      "\n",
      "Epoch 00612: val_loss did not improve from 0.10534\n",
      "455/455 - 0s - loss: 0.0909 - accuracy: 0.9538 - val_loss: 0.1076 - val_accuracy: 0.9649\n",
      "Epoch 613/3000\n",
      "\n",
      "Epoch 00613: val_loss did not improve from 0.10534\n",
      "455/455 - 0s - loss: 0.0952 - accuracy: 0.9495 - val_loss: 0.6375 - val_accuracy: 0.6930\n",
      "Epoch 614/3000\n",
      "\n",
      "Epoch 00614: val_loss did not improve from 0.10534\n",
      "455/455 - 0s - loss: 0.2086 - accuracy: 0.9099 - val_loss: 0.1086 - val_accuracy: 0.9649\n",
      "Epoch 615/3000\n",
      "\n",
      "Epoch 00615: val_loss did not improve from 0.10534\n",
      "455/455 - 0s - loss: 0.1176 - accuracy: 0.9538 - val_loss: 0.1155 - val_accuracy: 0.9649\n",
      "Epoch 616/3000\n",
      "\n",
      "Epoch 00616: val_loss did not improve from 0.10534\n",
      "455/455 - 0s - loss: 0.1032 - accuracy: 0.9604 - val_loss: 0.1308 - val_accuracy: 0.9474\n",
      "Epoch 617/3000\n",
      "\n",
      "Epoch 00617: val_loss did not improve from 0.10534\n",
      "455/455 - 0s - loss: 0.0941 - accuracy: 0.9516 - val_loss: 0.1484 - val_accuracy: 0.9474\n",
      "Epoch 618/3000\n",
      "\n",
      "Epoch 00618: val_loss did not improve from 0.10534\n",
      "455/455 - 0s - loss: 0.0952 - accuracy: 0.9473 - val_loss: 0.1557 - val_accuracy: 0.9474\n",
      "Epoch 619/3000\n",
      "\n",
      "Epoch 00619: val_loss did not improve from 0.10534\n",
      "455/455 - 0s - loss: 0.0999 - accuracy: 0.9516 - val_loss: 0.1962 - val_accuracy: 0.9211\n",
      "Epoch 620/3000\n",
      "\n",
      "Epoch 00620: val_loss did not improve from 0.10534\n",
      "455/455 - 0s - loss: 0.1022 - accuracy: 0.9560 - val_loss: 0.2721 - val_accuracy: 0.8596\n",
      "Epoch 621/3000\n",
      "\n",
      "Epoch 00621: val_loss did not improve from 0.10534\n",
      "455/455 - 0s - loss: 0.0902 - accuracy: 0.9516 - val_loss: 0.1422 - val_accuracy: 0.9386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 622/3000\n",
      "\n",
      "Epoch 00622: val_loss did not improve from 0.10534\n",
      "455/455 - 0s - loss: 0.0969 - accuracy: 0.9582 - val_loss: 0.1721 - val_accuracy: 0.9386\n",
      "Epoch 623/3000\n",
      "\n",
      "Epoch 00623: val_loss did not improve from 0.10534\n",
      "455/455 - 0s - loss: 0.0878 - accuracy: 0.9538 - val_loss: 0.1141 - val_accuracy: 0.9474\n",
      "Epoch 624/3000\n",
      "\n",
      "Epoch 00624: val_loss did not improve from 0.10534\n",
      "455/455 - 0s - loss: 0.0924 - accuracy: 0.9670 - val_loss: 0.1411 - val_accuracy: 0.9474\n",
      "Epoch 625/3000\n",
      "\n",
      "Epoch 00625: val_loss did not improve from 0.10534\n",
      "455/455 - 0s - loss: 0.0943 - accuracy: 0.9560 - val_loss: 0.2184 - val_accuracy: 0.9211\n",
      "Epoch 626/3000\n",
      "\n",
      "Epoch 00626: val_loss improved from 0.10534 to 0.10278, saving model to ../model/cencer626-0.1028.hdf5\n",
      "455/455 - 0s - loss: 0.0955 - accuracy: 0.9560 - val_loss: 0.1028 - val_accuracy: 0.9649\n",
      "Epoch 627/3000\n",
      "\n",
      "Epoch 00627: val_loss did not improve from 0.10278\n",
      "455/455 - 0s - loss: 0.1349 - accuracy: 0.9516 - val_loss: 0.1076 - val_accuracy: 0.9649\n",
      "Epoch 628/3000\n",
      "\n",
      "Epoch 00628: val_loss did not improve from 0.10278\n",
      "455/455 - 0s - loss: 0.1002 - accuracy: 0.9560 - val_loss: 0.1356 - val_accuracy: 0.9386\n",
      "Epoch 629/3000\n",
      "\n",
      "Epoch 00629: val_loss did not improve from 0.10278\n",
      "455/455 - 0s - loss: 0.0969 - accuracy: 0.9582 - val_loss: 0.1258 - val_accuracy: 0.9386\n",
      "Epoch 630/3000\n",
      "\n",
      "Epoch 00630: val_loss did not improve from 0.10278\n",
      "455/455 - 0s - loss: 0.1004 - accuracy: 0.9582 - val_loss: 0.1477 - val_accuracy: 0.9386\n",
      "Epoch 631/3000\n",
      "\n",
      "Epoch 00631: val_loss did not improve from 0.10278\n",
      "455/455 - 0s - loss: 0.1003 - accuracy: 0.9560 - val_loss: 0.1419 - val_accuracy: 0.9386\n",
      "Epoch 632/3000\n",
      "\n",
      "Epoch 00632: val_loss did not improve from 0.10278\n",
      "455/455 - 0s - loss: 0.0936 - accuracy: 0.9560 - val_loss: 0.3659 - val_accuracy: 0.8070\n",
      "Epoch 633/3000\n",
      "\n",
      "Epoch 00633: val_loss did not improve from 0.10278\n",
      "455/455 - 0s - loss: 0.0956 - accuracy: 0.9670 - val_loss: 0.1067 - val_accuracy: 0.9649\n",
      "Epoch 634/3000\n",
      "\n",
      "Epoch 00634: val_loss did not improve from 0.10278\n",
      "455/455 - 0s - loss: 0.0915 - accuracy: 0.9560 - val_loss: 0.1353 - val_accuracy: 0.9474\n",
      "Epoch 635/3000\n",
      "\n",
      "Epoch 00635: val_loss did not improve from 0.10278\n",
      "455/455 - 0s - loss: 0.0955 - accuracy: 0.9626 - val_loss: 0.1070 - val_accuracy: 0.9561\n",
      "Epoch 636/3000\n",
      "\n",
      "Epoch 00636: val_loss did not improve from 0.10278\n",
      "455/455 - 0s - loss: 0.1115 - accuracy: 0.9560 - val_loss: 0.1666 - val_accuracy: 0.9474\n",
      "Epoch 637/3000\n",
      "\n",
      "Epoch 00637: val_loss did not improve from 0.10278\n",
      "455/455 - 0s - loss: 0.1201 - accuracy: 0.9560 - val_loss: 0.1155 - val_accuracy: 0.9561\n",
      "Epoch 638/3000\n",
      "\n",
      "Epoch 00638: val_loss improved from 0.10278 to 0.10034, saving model to ../model/cencer638-0.1003.hdf5\n",
      "455/455 - 0s - loss: 0.0848 - accuracy: 0.9604 - val_loss: 0.1003 - val_accuracy: 0.9649\n",
      "Epoch 639/3000\n",
      "\n",
      "Epoch 00639: val_loss did not improve from 0.10034\n",
      "455/455 - 0s - loss: 0.0899 - accuracy: 0.9604 - val_loss: 0.3629 - val_accuracy: 0.7982\n",
      "Epoch 640/3000\n",
      "\n",
      "Epoch 00640: val_loss did not improve from 0.10034\n",
      "455/455 - 0s - loss: 0.1377 - accuracy: 0.9582 - val_loss: 0.3076 - val_accuracy: 0.8333\n",
      "Epoch 641/3000\n",
      "\n",
      "Epoch 00641: val_loss did not improve from 0.10034\n",
      "455/455 - 0s - loss: 0.0927 - accuracy: 0.9670 - val_loss: 0.1263 - val_accuracy: 0.9386\n",
      "Epoch 642/3000\n",
      "\n",
      "Epoch 00642: val_loss improved from 0.10034 to 0.09893, saving model to ../model/cencer642-0.0989.hdf5\n",
      "455/455 - 0s - loss: 0.1013 - accuracy: 0.9560 - val_loss: 0.0989 - val_accuracy: 0.9649\n",
      "Epoch 643/3000\n",
      "\n",
      "Epoch 00643: val_loss did not improve from 0.09893\n",
      "455/455 - 0s - loss: 0.0982 - accuracy: 0.9582 - val_loss: 0.1110 - val_accuracy: 0.9561\n",
      "Epoch 644/3000\n",
      "\n",
      "Epoch 00644: val_loss did not improve from 0.09893\n",
      "455/455 - 0s - loss: 0.0880 - accuracy: 0.9692 - val_loss: 0.1195 - val_accuracy: 0.9386\n",
      "Epoch 645/3000\n",
      "\n",
      "Epoch 00645: val_loss did not improve from 0.09893\n",
      "455/455 - 0s - loss: 0.0879 - accuracy: 0.9582 - val_loss: 0.2557 - val_accuracy: 0.8684\n",
      "Epoch 646/3000\n",
      "\n",
      "Epoch 00646: val_loss did not improve from 0.09893\n",
      "455/455 - 0s - loss: 0.1307 - accuracy: 0.9407 - val_loss: 0.1880 - val_accuracy: 0.9211\n",
      "Epoch 647/3000\n",
      "\n",
      "Epoch 00647: val_loss did not improve from 0.09893\n",
      "455/455 - 0s - loss: 0.0825 - accuracy: 0.9604 - val_loss: 0.1618 - val_accuracy: 0.9474\n",
      "Epoch 648/3000\n",
      "\n",
      "Epoch 00648: val_loss did not improve from 0.09893\n",
      "455/455 - 0s - loss: 0.0830 - accuracy: 0.9648 - val_loss: 0.1729 - val_accuracy: 0.9298\n",
      "Epoch 649/3000\n",
      "\n",
      "Epoch 00649: val_loss did not improve from 0.09893\n",
      "455/455 - 0s - loss: 0.0896 - accuracy: 0.9648 - val_loss: 0.1294 - val_accuracy: 0.9474\n",
      "Epoch 650/3000\n",
      "\n",
      "Epoch 00650: val_loss did not improve from 0.09893\n",
      "455/455 - 0s - loss: 0.1177 - accuracy: 0.9538 - val_loss: 0.1755 - val_accuracy: 0.9298\n",
      "Epoch 651/3000\n",
      "\n",
      "Epoch 00651: val_loss did not improve from 0.09893\n",
      "455/455 - 0s - loss: 0.1084 - accuracy: 0.9538 - val_loss: 0.1356 - val_accuracy: 0.9561\n",
      "Epoch 652/3000\n",
      "\n",
      "Epoch 00652: val_loss did not improve from 0.09893\n",
      "455/455 - 0s - loss: 0.0940 - accuracy: 0.9538 - val_loss: 0.2415 - val_accuracy: 0.8947\n",
      "Epoch 653/3000\n",
      "\n",
      "Epoch 00653: val_loss did not improve from 0.09893\n",
      "455/455 - 0s - loss: 0.0961 - accuracy: 0.9582 - val_loss: 0.1654 - val_accuracy: 0.9386\n",
      "Epoch 654/3000\n",
      "\n",
      "Epoch 00654: val_loss did not improve from 0.09893\n",
      "455/455 - 0s - loss: 0.0862 - accuracy: 0.9582 - val_loss: 0.1152 - val_accuracy: 0.9386\n",
      "Epoch 655/3000\n",
      "\n",
      "Epoch 00655: val_loss did not improve from 0.09893\n",
      "455/455 - 0s - loss: 0.0877 - accuracy: 0.9582 - val_loss: 0.1019 - val_accuracy: 0.9561\n",
      "Epoch 656/3000\n",
      "\n",
      "Epoch 00656: val_loss did not improve from 0.09893\n",
      "455/455 - 0s - loss: 0.1221 - accuracy: 0.9495 - val_loss: 0.1134 - val_accuracy: 0.9561\n",
      "Epoch 657/3000\n",
      "\n",
      "Epoch 00657: val_loss did not improve from 0.09893\n",
      "455/455 - 0s - loss: 0.1332 - accuracy: 0.9429 - val_loss: 0.3305 - val_accuracy: 0.8246\n",
      "Epoch 658/3000\n",
      "\n",
      "Epoch 00658: val_loss did not improve from 0.09893\n",
      "455/455 - 0s - loss: 0.0977 - accuracy: 0.9560 - val_loss: 0.1178 - val_accuracy: 0.9386\n",
      "Epoch 659/3000\n",
      "\n",
      "Epoch 00659: val_loss did not improve from 0.09893\n",
      "455/455 - 0s - loss: 0.0989 - accuracy: 0.9516 - val_loss: 0.1236 - val_accuracy: 0.9561\n",
      "Epoch 660/3000\n",
      "\n",
      "Epoch 00660: val_loss did not improve from 0.09893\n",
      "455/455 - 0s - loss: 0.1019 - accuracy: 0.9714 - val_loss: 0.1077 - val_accuracy: 0.9561\n",
      "Epoch 661/3000\n",
      "\n",
      "Epoch 00661: val_loss did not improve from 0.09893\n",
      "455/455 - 0s - loss: 0.0992 - accuracy: 0.9648 - val_loss: 0.1560 - val_accuracy: 0.9474\n",
      "Epoch 662/3000\n",
      "\n",
      "Epoch 00662: val_loss did not improve from 0.09893\n",
      "455/455 - 0s - loss: 0.0882 - accuracy: 0.9648 - val_loss: 0.1068 - val_accuracy: 0.9561\n",
      "Epoch 663/3000\n",
      "\n",
      "Epoch 00663: val_loss did not improve from 0.09893\n",
      "455/455 - 0s - loss: 0.1437 - accuracy: 0.9516 - val_loss: 0.1055 - val_accuracy: 0.9737\n",
      "Epoch 664/3000\n",
      "\n",
      "Epoch 00664: val_loss did not improve from 0.09893\n",
      "455/455 - 0s - loss: 0.1572 - accuracy: 0.9231 - val_loss: 0.2402 - val_accuracy: 0.9123\n",
      "Epoch 665/3000\n",
      "\n",
      "Epoch 00665: val_loss did not improve from 0.09893\n",
      "455/455 - 0s - loss: 0.0950 - accuracy: 0.9626 - val_loss: 0.1464 - val_accuracy: 0.9474\n",
      "Epoch 666/3000\n",
      "\n",
      "Epoch 00666: val_loss did not improve from 0.09893\n",
      "455/455 - 0s - loss: 0.0899 - accuracy: 0.9670 - val_loss: 0.2280 - val_accuracy: 0.9035\n",
      "Epoch 667/3000\n",
      "\n",
      "Epoch 00667: val_loss improved from 0.09893 to 0.09824, saving model to ../model/cencer667-0.0982.hdf5\n",
      "455/455 - 0s - loss: 0.0912 - accuracy: 0.9648 - val_loss: 0.0982 - val_accuracy: 0.9561\n",
      "Epoch 668/3000\n",
      "\n",
      "Epoch 00668: val_loss did not improve from 0.09824\n",
      "455/455 - 0s - loss: 0.1068 - accuracy: 0.9582 - val_loss: 0.1226 - val_accuracy: 0.9386\n",
      "Epoch 669/3000\n",
      "\n",
      "Epoch 00669: val_loss did not improve from 0.09824\n",
      "455/455 - 0s - loss: 0.1120 - accuracy: 0.9451 - val_loss: 0.1014 - val_accuracy: 0.9561\n",
      "Epoch 670/3000\n",
      "\n",
      "Epoch 00670: val_loss improved from 0.09824 to 0.09746, saving model to ../model/cencer670-0.0975.hdf5\n",
      "455/455 - 0s - loss: 0.0861 - accuracy: 0.9692 - val_loss: 0.0975 - val_accuracy: 0.9649\n",
      "Epoch 671/3000\n",
      "\n",
      "Epoch 00671: val_loss did not improve from 0.09746\n",
      "455/455 - 0s - loss: 0.0869 - accuracy: 0.9670 - val_loss: 0.8769 - val_accuracy: 0.6228\n",
      "Epoch 672/3000\n",
      "\n",
      "Epoch 00672: val_loss did not improve from 0.09746\n",
      "455/455 - 0s - loss: 0.1827 - accuracy: 0.9143 - val_loss: 0.1562 - val_accuracy: 0.9474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 673/3000\n",
      "\n",
      "Epoch 00673: val_loss did not improve from 0.09746\n",
      "455/455 - 0s - loss: 0.0888 - accuracy: 0.9626 - val_loss: 0.1535 - val_accuracy: 0.9474\n",
      "Epoch 674/3000\n",
      "\n",
      "Epoch 00674: val_loss did not improve from 0.09746\n",
      "455/455 - 0s - loss: 0.0933 - accuracy: 0.9604 - val_loss: 0.2157 - val_accuracy: 0.9035\n",
      "Epoch 675/3000\n",
      "\n",
      "Epoch 00675: val_loss improved from 0.09746 to 0.09510, saving model to ../model/cencer675-0.0951.hdf5\n",
      "455/455 - 0s - loss: 0.0902 - accuracy: 0.9582 - val_loss: 0.0951 - val_accuracy: 0.9561\n",
      "Epoch 676/3000\n",
      "\n",
      "Epoch 00676: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.0977 - accuracy: 0.9604 - val_loss: 0.5198 - val_accuracy: 0.7281\n",
      "Epoch 677/3000\n",
      "\n",
      "Epoch 00677: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.1129 - accuracy: 0.9429 - val_loss: 0.1418 - val_accuracy: 0.9474\n",
      "Epoch 678/3000\n",
      "\n",
      "Epoch 00678: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.0805 - accuracy: 0.9604 - val_loss: 0.0988 - val_accuracy: 0.9561\n",
      "Epoch 679/3000\n",
      "\n",
      "Epoch 00679: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.0912 - accuracy: 0.9648 - val_loss: 0.3927 - val_accuracy: 0.7719\n",
      "Epoch 680/3000\n",
      "\n",
      "Epoch 00680: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.1198 - accuracy: 0.9495 - val_loss: 0.1326 - val_accuracy: 0.9474\n",
      "Epoch 681/3000\n",
      "\n",
      "Epoch 00681: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.0883 - accuracy: 0.9670 - val_loss: 0.1078 - val_accuracy: 0.9474\n",
      "Epoch 682/3000\n",
      "\n",
      "Epoch 00682: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.0869 - accuracy: 0.9626 - val_loss: 0.2157 - val_accuracy: 0.9123\n",
      "Epoch 683/3000\n",
      "\n",
      "Epoch 00683: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.0996 - accuracy: 0.9538 - val_loss: 0.6147 - val_accuracy: 0.7105\n",
      "Epoch 684/3000\n",
      "\n",
      "Epoch 00684: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.1529 - accuracy: 0.9275 - val_loss: 0.2940 - val_accuracy: 0.8333\n",
      "Epoch 685/3000\n",
      "\n",
      "Epoch 00685: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.1176 - accuracy: 0.9516 - val_loss: 0.2918 - val_accuracy: 0.8421\n",
      "Epoch 686/3000\n",
      "\n",
      "Epoch 00686: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.0909 - accuracy: 0.9670 - val_loss: 0.2855 - val_accuracy: 0.8421\n",
      "Epoch 687/3000\n",
      "\n",
      "Epoch 00687: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.0934 - accuracy: 0.9582 - val_loss: 0.1446 - val_accuracy: 0.9474\n",
      "Epoch 688/3000\n",
      "\n",
      "Epoch 00688: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.0939 - accuracy: 0.9538 - val_loss: 0.1746 - val_accuracy: 0.9298\n",
      "Epoch 689/3000\n",
      "\n",
      "Epoch 00689: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.0789 - accuracy: 0.9648 - val_loss: 0.1524 - val_accuracy: 0.9474\n",
      "Epoch 690/3000\n",
      "\n",
      "Epoch 00690: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.0839 - accuracy: 0.9626 - val_loss: 0.1302 - val_accuracy: 0.9474\n",
      "Epoch 691/3000\n",
      "\n",
      "Epoch 00691: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.1045 - accuracy: 0.9626 - val_loss: 0.1564 - val_accuracy: 0.9474\n",
      "Epoch 692/3000\n",
      "\n",
      "Epoch 00692: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.0787 - accuracy: 0.9758 - val_loss: 0.1528 - val_accuracy: 0.9474\n",
      "Epoch 693/3000\n",
      "\n",
      "Epoch 00693: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.1385 - accuracy: 0.9429 - val_loss: 0.1099 - val_accuracy: 0.9561\n",
      "Epoch 694/3000\n",
      "\n",
      "Epoch 00694: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.0999 - accuracy: 0.9582 - val_loss: 0.2629 - val_accuracy: 0.8684\n",
      "Epoch 695/3000\n",
      "\n",
      "Epoch 00695: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.0954 - accuracy: 0.9604 - val_loss: 0.1253 - val_accuracy: 0.9386\n",
      "Epoch 696/3000\n",
      "\n",
      "Epoch 00696: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.0864 - accuracy: 0.9670 - val_loss: 0.1425 - val_accuracy: 0.9474\n",
      "Epoch 697/3000\n",
      "\n",
      "Epoch 00697: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.0866 - accuracy: 0.9582 - val_loss: 0.1091 - val_accuracy: 0.9386\n",
      "Epoch 698/3000\n",
      "\n",
      "Epoch 00698: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.1016 - accuracy: 0.9560 - val_loss: 0.1058 - val_accuracy: 0.9561\n",
      "Epoch 699/3000\n",
      "\n",
      "Epoch 00699: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.1411 - accuracy: 0.9429 - val_loss: 0.1090 - val_accuracy: 0.9561\n",
      "Epoch 700/3000\n",
      "\n",
      "Epoch 00700: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.0870 - accuracy: 0.9648 - val_loss: 0.1493 - val_accuracy: 0.9474\n",
      "Epoch 701/3000\n",
      "\n",
      "Epoch 00701: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.0838 - accuracy: 0.9692 - val_loss: 0.1102 - val_accuracy: 0.9474\n",
      "Epoch 702/3000\n",
      "\n",
      "Epoch 00702: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.1082 - accuracy: 0.9538 - val_loss: 0.1257 - val_accuracy: 0.9386\n",
      "Epoch 703/3000\n",
      "\n",
      "Epoch 00703: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.0867 - accuracy: 0.9473 - val_loss: 0.1238 - val_accuracy: 0.9386\n",
      "Epoch 704/3000\n",
      "\n",
      "Epoch 00704: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.0918 - accuracy: 0.9560 - val_loss: 0.1629 - val_accuracy: 0.9386\n",
      "Epoch 705/3000\n",
      "\n",
      "Epoch 00705: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.0915 - accuracy: 0.9604 - val_loss: 0.1045 - val_accuracy: 0.9474\n",
      "Epoch 706/3000\n",
      "\n",
      "Epoch 00706: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.0793 - accuracy: 0.9648 - val_loss: 0.1427 - val_accuracy: 0.9474\n",
      "Epoch 707/3000\n",
      "\n",
      "Epoch 00707: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.0966 - accuracy: 0.9560 - val_loss: 0.9630 - val_accuracy: 0.6053\n",
      "Epoch 708/3000\n",
      "\n",
      "Epoch 00708: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.1796 - accuracy: 0.9341 - val_loss: 0.1502 - val_accuracy: 0.9386\n",
      "Epoch 709/3000\n",
      "\n",
      "Epoch 00709: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.0895 - accuracy: 0.9560 - val_loss: 0.1676 - val_accuracy: 0.9386\n",
      "Epoch 710/3000\n",
      "\n",
      "Epoch 00710: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.0880 - accuracy: 0.9670 - val_loss: 0.0965 - val_accuracy: 0.9649\n",
      "Epoch 711/3000\n",
      "\n",
      "Epoch 00711: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.0950 - accuracy: 0.9582 - val_loss: 0.0957 - val_accuracy: 0.9649\n",
      "Epoch 712/3000\n",
      "\n",
      "Epoch 00712: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.0827 - accuracy: 0.9560 - val_loss: 0.1996 - val_accuracy: 0.9211\n",
      "Epoch 713/3000\n",
      "\n",
      "Epoch 00713: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.0795 - accuracy: 0.9648 - val_loss: 0.2857 - val_accuracy: 0.8509\n",
      "Epoch 714/3000\n",
      "\n",
      "Epoch 00714: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.0881 - accuracy: 0.9626 - val_loss: 0.1110 - val_accuracy: 0.9386\n",
      "Epoch 715/3000\n",
      "\n",
      "Epoch 00715: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.0782 - accuracy: 0.9626 - val_loss: 0.1797 - val_accuracy: 0.9211\n",
      "Epoch 716/3000\n",
      "\n",
      "Epoch 00716: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.1121 - accuracy: 0.9560 - val_loss: 0.1381 - val_accuracy: 0.9474\n",
      "Epoch 717/3000\n",
      "\n",
      "Epoch 00717: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.1113 - accuracy: 0.9451 - val_loss: 0.1965 - val_accuracy: 0.9474\n",
      "Epoch 718/3000\n",
      "\n",
      "Epoch 00718: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.1410 - accuracy: 0.9407 - val_loss: 0.2294 - val_accuracy: 0.9035\n",
      "Epoch 719/3000\n",
      "\n",
      "Epoch 00719: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.0918 - accuracy: 0.9538 - val_loss: 0.1488 - val_accuracy: 0.9386\n",
      "Epoch 720/3000\n",
      "\n",
      "Epoch 00720: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.0807 - accuracy: 0.9582 - val_loss: 0.1901 - val_accuracy: 0.9211\n",
      "Epoch 721/3000\n",
      "\n",
      "Epoch 00721: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.0888 - accuracy: 0.9648 - val_loss: 0.1892 - val_accuracy: 0.9211\n",
      "Epoch 722/3000\n",
      "\n",
      "Epoch 00722: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.0748 - accuracy: 0.9648 - val_loss: 0.1145 - val_accuracy: 0.9474\n",
      "Epoch 723/3000\n",
      "\n",
      "Epoch 00723: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.0812 - accuracy: 0.9626 - val_loss: 0.5925 - val_accuracy: 0.7105\n",
      "Epoch 724/3000\n",
      "\n",
      "Epoch 00724: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.1180 - accuracy: 0.9407 - val_loss: 0.1816 - val_accuracy: 0.9298\n",
      "Epoch 725/3000\n",
      "\n",
      "Epoch 00725: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.0785 - accuracy: 0.9582 - val_loss: 0.2478 - val_accuracy: 0.8947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 726/3000\n",
      "\n",
      "Epoch 00726: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.0798 - accuracy: 0.9626 - val_loss: 0.1095 - val_accuracy: 0.9737\n",
      "Epoch 727/3000\n",
      "\n",
      "Epoch 00727: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.1911 - accuracy: 0.9231 - val_loss: 0.1361 - val_accuracy: 0.9386\n",
      "Epoch 728/3000\n",
      "\n",
      "Epoch 00728: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.0906 - accuracy: 0.9582 - val_loss: 0.1316 - val_accuracy: 0.9386\n",
      "Epoch 729/3000\n",
      "\n",
      "Epoch 00729: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.0832 - accuracy: 0.9582 - val_loss: 0.1500 - val_accuracy: 0.9474\n",
      "Epoch 730/3000\n",
      "\n",
      "Epoch 00730: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.0851 - accuracy: 0.9626 - val_loss: 0.1067 - val_accuracy: 0.9474\n",
      "Epoch 731/3000\n",
      "\n",
      "Epoch 00731: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.0996 - accuracy: 0.9582 - val_loss: 0.1022 - val_accuracy: 0.9649\n",
      "Epoch 732/3000\n",
      "\n",
      "Epoch 00732: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.0841 - accuracy: 0.9604 - val_loss: 0.2872 - val_accuracy: 0.8596\n",
      "Epoch 733/3000\n",
      "\n",
      "Epoch 00733: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.0843 - accuracy: 0.9516 - val_loss: 0.0965 - val_accuracy: 0.9737\n",
      "Epoch 734/3000\n",
      "\n",
      "Epoch 00734: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.0870 - accuracy: 0.9626 - val_loss: 0.1170 - val_accuracy: 0.9386\n",
      "Epoch 735/3000\n",
      "\n",
      "Epoch 00735: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.1072 - accuracy: 0.9516 - val_loss: 0.2265 - val_accuracy: 0.9211\n",
      "Epoch 736/3000\n",
      "\n",
      "Epoch 00736: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.1051 - accuracy: 0.9560 - val_loss: 0.3612 - val_accuracy: 0.8158\n",
      "Epoch 737/3000\n",
      "\n",
      "Epoch 00737: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.1012 - accuracy: 0.9582 - val_loss: 0.1728 - val_accuracy: 0.9298\n",
      "Epoch 738/3000\n",
      "\n",
      "Epoch 00738: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.0788 - accuracy: 0.9582 - val_loss: 0.1102 - val_accuracy: 0.9386\n",
      "Epoch 739/3000\n",
      "\n",
      "Epoch 00739: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.0867 - accuracy: 0.9626 - val_loss: 0.0966 - val_accuracy: 0.9561\n",
      "Epoch 740/3000\n",
      "\n",
      "Epoch 00740: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.1132 - accuracy: 0.9516 - val_loss: 0.1183 - val_accuracy: 0.9386\n",
      "Epoch 741/3000\n",
      "\n",
      "Epoch 00741: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.0822 - accuracy: 0.9648 - val_loss: 0.1876 - val_accuracy: 0.9211\n",
      "Epoch 742/3000\n",
      "\n",
      "Epoch 00742: val_loss did not improve from 0.09510\n",
      "455/455 - 0s - loss: 0.0776 - accuracy: 0.9648 - val_loss: 0.3527 - val_accuracy: 0.8158\n",
      "Epoch 743/3000\n",
      "\n",
      "Epoch 00743: val_loss improved from 0.09510 to 0.09363, saving model to ../model/cencer743-0.0936.hdf5\n",
      "455/455 - 0s - loss: 0.0893 - accuracy: 0.9648 - val_loss: 0.0936 - val_accuracy: 0.9649\n",
      "Epoch 744/3000\n",
      "\n",
      "Epoch 00744: val_loss did not improve from 0.09363\n",
      "455/455 - 0s - loss: 0.0983 - accuracy: 0.9538 - val_loss: 0.1125 - val_accuracy: 0.9474\n",
      "Epoch 745/3000\n",
      "\n",
      "Epoch 00745: val_loss did not improve from 0.09363\n",
      "455/455 - 0s - loss: 0.0979 - accuracy: 0.9560 - val_loss: 0.2220 - val_accuracy: 0.9123\n",
      "Epoch 746/3000\n",
      "\n",
      "Epoch 00746: val_loss did not improve from 0.09363\n",
      "455/455 - 0s - loss: 0.0809 - accuracy: 0.9692 - val_loss: 0.1617 - val_accuracy: 0.9386\n",
      "Epoch 747/3000\n",
      "\n",
      "Epoch 00747: val_loss did not improve from 0.09363\n",
      "455/455 - 0s - loss: 0.0734 - accuracy: 0.9648 - val_loss: 0.1437 - val_accuracy: 0.9386\n",
      "Epoch 748/3000\n",
      "\n",
      "Epoch 00748: val_loss did not improve from 0.09363\n",
      "455/455 - 0s - loss: 0.1036 - accuracy: 0.9582 - val_loss: 0.1580 - val_accuracy: 0.9386\n",
      "Epoch 749/3000\n",
      "\n",
      "Epoch 00749: val_loss did not improve from 0.09363\n",
      "455/455 - 0s - loss: 0.1077 - accuracy: 0.9516 - val_loss: 0.1157 - val_accuracy: 0.9561\n",
      "Epoch 750/3000\n",
      "\n",
      "Epoch 00750: val_loss did not improve from 0.09363\n",
      "455/455 - 0s - loss: 0.1018 - accuracy: 0.9648 - val_loss: 0.0964 - val_accuracy: 0.9649\n",
      "Epoch 751/3000\n",
      "\n",
      "Epoch 00751: val_loss did not improve from 0.09363\n",
      "455/455 - 0s - loss: 0.1063 - accuracy: 0.9560 - val_loss: 0.1274 - val_accuracy: 0.9474\n",
      "Epoch 752/3000\n",
      "\n",
      "Epoch 00752: val_loss did not improve from 0.09363\n",
      "455/455 - 0s - loss: 0.0823 - accuracy: 0.9626 - val_loss: 0.3580 - val_accuracy: 0.7807\n",
      "Epoch 753/3000\n",
      "\n",
      "Epoch 00753: val_loss did not improve from 0.09363\n",
      "455/455 - 0s - loss: 0.0844 - accuracy: 0.9670 - val_loss: 0.1358 - val_accuracy: 0.9474\n",
      "Epoch 754/3000\n",
      "\n",
      "Epoch 00754: val_loss did not improve from 0.09363\n",
      "455/455 - 0s - loss: 0.0735 - accuracy: 0.9736 - val_loss: 0.1130 - val_accuracy: 0.9474\n",
      "Epoch 755/3000\n",
      "\n",
      "Epoch 00755: val_loss improved from 0.09363 to 0.09048, saving model to ../model/cencer755-0.0905.hdf5\n",
      "455/455 - 0s - loss: 0.0734 - accuracy: 0.9648 - val_loss: 0.0905 - val_accuracy: 0.9737\n",
      "Epoch 756/3000\n",
      "\n",
      "Epoch 00756: val_loss improved from 0.09048 to 0.08972, saving model to ../model/cencer756-0.0897.hdf5\n",
      "455/455 - 0s - loss: 0.0867 - accuracy: 0.9604 - val_loss: 0.0897 - val_accuracy: 0.9825\n",
      "Epoch 757/3000\n",
      "\n",
      "Epoch 00757: val_loss did not improve from 0.08972\n",
      "455/455 - 0s - loss: 0.1335 - accuracy: 0.9363 - val_loss: 0.1168 - val_accuracy: 0.9561\n",
      "Epoch 758/3000\n",
      "\n",
      "Epoch 00758: val_loss did not improve from 0.08972\n",
      "455/455 - 0s - loss: 0.0844 - accuracy: 0.9648 - val_loss: 0.1265 - val_accuracy: 0.9386\n",
      "Epoch 759/3000\n",
      "\n",
      "Epoch 00759: val_loss did not improve from 0.08972\n",
      "455/455 - 0s - loss: 0.0862 - accuracy: 0.9604 - val_loss: 0.1251 - val_accuracy: 0.9386\n",
      "Epoch 760/3000\n",
      "\n",
      "Epoch 00760: val_loss did not improve from 0.08972\n",
      "455/455 - 0s - loss: 0.0738 - accuracy: 0.9604 - val_loss: 0.0967 - val_accuracy: 0.9649\n",
      "Epoch 761/3000\n",
      "\n",
      "Epoch 00761: val_loss did not improve from 0.08972\n",
      "455/455 - 0s - loss: 0.0805 - accuracy: 0.9648 - val_loss: 0.1834 - val_accuracy: 0.9211\n",
      "Epoch 762/3000\n",
      "\n",
      "Epoch 00762: val_loss did not improve from 0.08972\n",
      "455/455 - 0s - loss: 0.1087 - accuracy: 0.9604 - val_loss: 0.6371 - val_accuracy: 0.7018\n",
      "Epoch 763/3000\n",
      "\n",
      "Epoch 00763: val_loss did not improve from 0.08972\n",
      "455/455 - 0s - loss: 0.1287 - accuracy: 0.9516 - val_loss: 0.1296 - val_accuracy: 0.9386\n",
      "Epoch 764/3000\n",
      "\n",
      "Epoch 00764: val_loss did not improve from 0.08972\n",
      "455/455 - 0s - loss: 0.0839 - accuracy: 0.9560 - val_loss: 0.2204 - val_accuracy: 0.9211\n",
      "Epoch 765/3000\n",
      "\n",
      "Epoch 00765: val_loss did not improve from 0.08972\n",
      "455/455 - 0s - loss: 0.1014 - accuracy: 0.9495 - val_loss: 0.2742 - val_accuracy: 0.8684\n",
      "Epoch 766/3000\n",
      "\n",
      "Epoch 00766: val_loss did not improve from 0.08972\n",
      "455/455 - 0s - loss: 0.0824 - accuracy: 0.9560 - val_loss: 0.0998 - val_accuracy: 0.9649\n",
      "Epoch 767/3000\n",
      "\n",
      "Epoch 00767: val_loss did not improve from 0.08972\n",
      "455/455 - 0s - loss: 0.0791 - accuracy: 0.9692 - val_loss: 0.1123 - val_accuracy: 0.9386\n",
      "Epoch 768/3000\n",
      "\n",
      "Epoch 00768: val_loss did not improve from 0.08972\n",
      "455/455 - 0s - loss: 0.0800 - accuracy: 0.9604 - val_loss: 0.1208 - val_accuracy: 0.9474\n",
      "Epoch 769/3000\n",
      "\n",
      "Epoch 00769: val_loss did not improve from 0.08972\n",
      "455/455 - 0s - loss: 0.0732 - accuracy: 0.9670 - val_loss: 0.1107 - val_accuracy: 0.9737\n",
      "Epoch 770/3000\n",
      "\n",
      "Epoch 00770: val_loss did not improve from 0.08972\n",
      "455/455 - 0s - loss: 0.0840 - accuracy: 0.9626 - val_loss: 0.1114 - val_accuracy: 0.9474\n",
      "Epoch 771/3000\n",
      "\n",
      "Epoch 00771: val_loss did not improve from 0.08972\n",
      "455/455 - 0s - loss: 0.0784 - accuracy: 0.9604 - val_loss: 0.2034 - val_accuracy: 0.9211\n",
      "Epoch 772/3000\n",
      "\n",
      "Epoch 00772: val_loss did not improve from 0.08972\n",
      "455/455 - 0s - loss: 0.0744 - accuracy: 0.9670 - val_loss: 0.1465 - val_accuracy: 0.9298\n",
      "Epoch 773/3000\n",
      "\n",
      "Epoch 00773: val_loss did not improve from 0.08972\n",
      "455/455 - 0s - loss: 0.1138 - accuracy: 0.9604 - val_loss: 0.2357 - val_accuracy: 0.8947\n",
      "Epoch 774/3000\n",
      "\n",
      "Epoch 00774: val_loss did not improve from 0.08972\n",
      "455/455 - 0s - loss: 0.0807 - accuracy: 0.9648 - val_loss: 0.1872 - val_accuracy: 0.9211\n",
      "Epoch 775/3000\n",
      "\n",
      "Epoch 00775: val_loss did not improve from 0.08972\n",
      "455/455 - 0s - loss: 0.0766 - accuracy: 0.9670 - val_loss: 0.1470 - val_accuracy: 0.9386\n",
      "Epoch 776/3000\n",
      "\n",
      "Epoch 00776: val_loss did not improve from 0.08972\n",
      "455/455 - 0s - loss: 0.1074 - accuracy: 0.9516 - val_loss: 0.1185 - val_accuracy: 0.9561\n",
      "Epoch 777/3000\n",
      "\n",
      "Epoch 00777: val_loss did not improve from 0.08972\n",
      "455/455 - 0s - loss: 0.0933 - accuracy: 0.9560 - val_loss: 0.1454 - val_accuracy: 0.9386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 778/3000\n",
      "\n",
      "Epoch 00778: val_loss did not improve from 0.08972\n",
      "455/455 - 0s - loss: 0.0751 - accuracy: 0.9648 - val_loss: 0.2213 - val_accuracy: 0.9211\n",
      "Epoch 779/3000\n",
      "\n",
      "Epoch 00779: val_loss did not improve from 0.08972\n",
      "455/455 - 0s - loss: 0.0763 - accuracy: 0.9648 - val_loss: 0.1010 - val_accuracy: 0.9561\n",
      "Epoch 780/3000\n",
      "\n",
      "Epoch 00780: val_loss did not improve from 0.08972\n",
      "455/455 - 0s - loss: 0.0854 - accuracy: 0.9670 - val_loss: 0.0944 - val_accuracy: 0.9474\n",
      "Epoch 781/3000\n",
      "\n",
      "Epoch 00781: val_loss did not improve from 0.08972\n",
      "455/455 - 0s - loss: 0.0983 - accuracy: 0.9582 - val_loss: 0.1620 - val_accuracy: 0.9298\n",
      "Epoch 782/3000\n",
      "\n",
      "Epoch 00782: val_loss did not improve from 0.08972\n",
      "455/455 - 0s - loss: 0.0991 - accuracy: 0.9538 - val_loss: 0.3752 - val_accuracy: 0.7982\n",
      "Epoch 783/3000\n",
      "\n",
      "Epoch 00783: val_loss did not improve from 0.08972\n",
      "455/455 - 0s - loss: 0.1078 - accuracy: 0.9516 - val_loss: 0.1802 - val_accuracy: 0.9298\n",
      "Epoch 784/3000\n",
      "\n",
      "Epoch 00784: val_loss did not improve from 0.08972\n",
      "455/455 - 0s - loss: 0.0754 - accuracy: 0.9692 - val_loss: 0.3307 - val_accuracy: 0.8246\n",
      "Epoch 785/3000\n",
      "\n",
      "Epoch 00785: val_loss did not improve from 0.08972\n",
      "455/455 - 0s - loss: 0.1893 - accuracy: 0.9275 - val_loss: 0.1487 - val_accuracy: 0.9386\n",
      "Epoch 786/3000\n",
      "\n",
      "Epoch 00786: val_loss did not improve from 0.08972\n",
      "455/455 - 0s - loss: 0.0887 - accuracy: 0.9626 - val_loss: 0.1270 - val_accuracy: 0.9386\n",
      "Epoch 787/3000\n",
      "\n",
      "Epoch 00787: val_loss did not improve from 0.08972\n",
      "455/455 - 0s - loss: 0.0763 - accuracy: 0.9670 - val_loss: 0.0981 - val_accuracy: 0.9649\n",
      "Epoch 788/3000\n",
      "\n",
      "Epoch 00788: val_loss did not improve from 0.08972\n",
      "455/455 - 0s - loss: 0.1547 - accuracy: 0.9363 - val_loss: 0.2195 - val_accuracy: 0.9123\n",
      "Epoch 789/3000\n",
      "\n",
      "Epoch 00789: val_loss did not improve from 0.08972\n",
      "455/455 - 0s - loss: 0.0819 - accuracy: 0.9626 - val_loss: 0.2117 - val_accuracy: 0.9211\n",
      "Epoch 790/3000\n",
      "\n",
      "Epoch 00790: val_loss did not improve from 0.08972\n",
      "455/455 - 0s - loss: 0.0835 - accuracy: 0.9604 - val_loss: 0.1623 - val_accuracy: 0.9298\n",
      "Epoch 791/3000\n",
      "\n",
      "Epoch 00791: val_loss did not improve from 0.08972\n",
      "455/455 - 0s - loss: 0.0742 - accuracy: 0.9714 - val_loss: 0.0980 - val_accuracy: 0.9474\n",
      "Epoch 792/3000\n",
      "\n",
      "Epoch 00792: val_loss did not improve from 0.08972\n",
      "455/455 - 0s - loss: 0.1554 - accuracy: 0.9451 - val_loss: 0.1606 - val_accuracy: 0.9474\n",
      "Epoch 793/3000\n",
      "\n",
      "Epoch 00793: val_loss did not improve from 0.08972\n",
      "455/455 - 0s - loss: 0.1531 - accuracy: 0.9451 - val_loss: 0.1275 - val_accuracy: 0.9561\n",
      "Epoch 794/3000\n",
      "\n",
      "Epoch 00794: val_loss did not improve from 0.08972\n",
      "455/455 - 0s - loss: 0.0868 - accuracy: 0.9714 - val_loss: 0.1326 - val_accuracy: 0.9474\n",
      "Epoch 795/3000\n",
      "\n",
      "Epoch 00795: val_loss did not improve from 0.08972\n",
      "455/455 - 0s - loss: 0.1241 - accuracy: 0.9495 - val_loss: 0.0984 - val_accuracy: 0.9561\n",
      "Epoch 796/3000\n",
      "\n",
      "Epoch 00796: val_loss improved from 0.08972 to 0.08831, saving model to ../model/cencer796-0.0883.hdf5\n",
      "455/455 - 0s - loss: 0.0751 - accuracy: 0.9670 - val_loss: 0.0883 - val_accuracy: 0.9649\n",
      "Epoch 797/3000\n",
      "\n",
      "Epoch 00797: val_loss did not improve from 0.08831\n",
      "455/455 - 0s - loss: 0.0749 - accuracy: 0.9604 - val_loss: 0.1063 - val_accuracy: 0.9474\n",
      "Epoch 798/3000\n",
      "\n",
      "Epoch 00798: val_loss did not improve from 0.08831\n",
      "455/455 - 0s - loss: 0.1103 - accuracy: 0.9516 - val_loss: 0.0999 - val_accuracy: 0.9649\n",
      "Epoch 799/3000\n",
      "\n",
      "Epoch 00799: val_loss did not improve from 0.08831\n",
      "455/455 - 0s - loss: 0.1729 - accuracy: 0.9231 - val_loss: 0.1179 - val_accuracy: 0.9386\n",
      "Epoch 800/3000\n",
      "\n",
      "Epoch 00800: val_loss did not improve from 0.08831\n",
      "455/455 - 0s - loss: 0.0847 - accuracy: 0.9604 - val_loss: 0.1869 - val_accuracy: 0.9298\n",
      "Epoch 801/3000\n",
      "\n",
      "Epoch 00801: val_loss did not improve from 0.08831\n",
      "455/455 - 0s - loss: 0.0801 - accuracy: 0.9648 - val_loss: 0.2385 - val_accuracy: 0.8947\n",
      "Epoch 802/3000\n",
      "\n",
      "Epoch 00802: val_loss did not improve from 0.08831\n",
      "455/455 - 0s - loss: 0.0816 - accuracy: 0.9758 - val_loss: 0.1471 - val_accuracy: 0.9386\n",
      "Epoch 803/3000\n",
      "\n",
      "Epoch 00803: val_loss did not improve from 0.08831\n",
      "455/455 - 0s - loss: 0.0790 - accuracy: 0.9626 - val_loss: 0.1036 - val_accuracy: 0.9474\n",
      "Epoch 804/3000\n",
      "\n",
      "Epoch 00804: val_loss did not improve from 0.08831\n",
      "455/455 - 0s - loss: 0.0845 - accuracy: 0.9648 - val_loss: 0.1066 - val_accuracy: 0.9474\n",
      "Epoch 805/3000\n",
      "\n",
      "Epoch 00805: val_loss did not improve from 0.08831\n",
      "455/455 - 0s - loss: 0.0804 - accuracy: 0.9648 - val_loss: 0.1178 - val_accuracy: 0.9474\n",
      "Epoch 806/3000\n",
      "\n",
      "Epoch 00806: val_loss did not improve from 0.08831\n",
      "455/455 - 0s - loss: 0.0720 - accuracy: 0.9736 - val_loss: 0.1680 - val_accuracy: 0.9298\n",
      "Epoch 807/3000\n",
      "\n",
      "Epoch 00807: val_loss did not improve from 0.08831\n",
      "455/455 - 0s - loss: 0.0925 - accuracy: 0.9495 - val_loss: 0.1075 - val_accuracy: 0.9474\n",
      "Epoch 808/3000\n",
      "\n",
      "Epoch 00808: val_loss did not improve from 0.08831\n",
      "455/455 - 0s - loss: 0.0734 - accuracy: 0.9648 - val_loss: 0.0927 - val_accuracy: 0.9649\n",
      "Epoch 809/3000\n",
      "\n",
      "Epoch 00809: val_loss did not improve from 0.08831\n",
      "455/455 - 0s - loss: 0.0785 - accuracy: 0.9714 - val_loss: 0.0931 - val_accuracy: 0.9737\n",
      "Epoch 810/3000\n",
      "\n",
      "Epoch 00810: val_loss did not improve from 0.08831\n",
      "455/455 - 0s - loss: 0.0825 - accuracy: 0.9604 - val_loss: 0.1484 - val_accuracy: 0.9386\n",
      "Epoch 811/3000\n",
      "\n",
      "Epoch 00811: val_loss improved from 0.08831 to 0.08590, saving model to ../model/cencer811-0.0859.hdf5\n",
      "455/455 - 0s - loss: 0.0832 - accuracy: 0.9582 - val_loss: 0.0859 - val_accuracy: 0.9737\n",
      "Epoch 812/3000\n",
      "\n",
      "Epoch 00812: val_loss improved from 0.08590 to 0.08455, saving model to ../model/cencer812-0.0845.hdf5\n",
      "455/455 - 0s - loss: 0.0904 - accuracy: 0.9604 - val_loss: 0.0845 - val_accuracy: 0.9737\n",
      "Epoch 813/3000\n",
      "\n",
      "Epoch 00813: val_loss did not improve from 0.08455\n",
      "455/455 - 0s - loss: 0.1765 - accuracy: 0.9143 - val_loss: 0.1088 - val_accuracy: 0.9561\n",
      "Epoch 814/3000\n",
      "\n",
      "Epoch 00814: val_loss did not improve from 0.08455\n",
      "455/455 - 0s - loss: 0.0924 - accuracy: 0.9648 - val_loss: 0.1043 - val_accuracy: 0.9649\n",
      "Epoch 815/3000\n",
      "\n",
      "Epoch 00815: val_loss did not improve from 0.08455\n",
      "455/455 - 0s - loss: 0.0814 - accuracy: 0.9604 - val_loss: 0.1444 - val_accuracy: 0.9386\n",
      "Epoch 816/3000\n",
      "\n",
      "Epoch 00816: val_loss did not improve from 0.08455\n",
      "455/455 - 0s - loss: 0.0731 - accuracy: 0.9670 - val_loss: 0.1096 - val_accuracy: 0.9474\n",
      "Epoch 817/3000\n",
      "\n",
      "Epoch 00817: val_loss did not improve from 0.08455\n",
      "455/455 - 0s - loss: 0.0829 - accuracy: 0.9626 - val_loss: 0.1004 - val_accuracy: 0.9737\n",
      "Epoch 818/3000\n",
      "\n",
      "Epoch 00818: val_loss did not improve from 0.08455\n",
      "455/455 - 0s - loss: 0.0881 - accuracy: 0.9648 - val_loss: 0.1622 - val_accuracy: 0.9298\n",
      "Epoch 819/3000\n",
      "\n",
      "Epoch 00819: val_loss did not improve from 0.08455\n",
      "455/455 - 0s - loss: 0.0773 - accuracy: 0.9648 - val_loss: 0.3694 - val_accuracy: 0.8246\n",
      "Epoch 820/3000\n",
      "\n",
      "Epoch 00820: val_loss did not improve from 0.08455\n",
      "455/455 - 0s - loss: 0.0899 - accuracy: 0.9516 - val_loss: 0.1342 - val_accuracy: 0.9386\n",
      "Epoch 821/3000\n",
      "\n",
      "Epoch 00821: val_loss did not improve from 0.08455\n",
      "455/455 - 0s - loss: 0.0747 - accuracy: 0.9626 - val_loss: 0.3021 - val_accuracy: 0.8421\n",
      "Epoch 822/3000\n",
      "\n",
      "Epoch 00822: val_loss did not improve from 0.08455\n",
      "455/455 - 0s - loss: 0.0864 - accuracy: 0.9626 - val_loss: 0.1292 - val_accuracy: 0.9386\n",
      "Epoch 823/3000\n",
      "\n",
      "Epoch 00823: val_loss did not improve from 0.08455\n",
      "455/455 - 0s - loss: 0.0699 - accuracy: 0.9626 - val_loss: 0.1128 - val_accuracy: 0.9474\n",
      "Epoch 824/3000\n",
      "\n",
      "Epoch 00824: val_loss did not improve from 0.08455\n",
      "455/455 - 0s - loss: 0.0785 - accuracy: 0.9604 - val_loss: 0.1428 - val_accuracy: 0.9386\n",
      "Epoch 825/3000\n",
      "\n",
      "Epoch 00825: val_loss did not improve from 0.08455\n",
      "455/455 - 0s - loss: 0.0677 - accuracy: 0.9648 - val_loss: 0.1604 - val_accuracy: 0.9298\n",
      "Epoch 826/3000\n",
      "\n",
      "Epoch 00826: val_loss did not improve from 0.08455\n",
      "455/455 - 0s - loss: 0.1124 - accuracy: 0.9451 - val_loss: 0.1345 - val_accuracy: 0.9474\n",
      "Epoch 827/3000\n",
      "\n",
      "Epoch 00827: val_loss did not improve from 0.08455\n",
      "455/455 - 0s - loss: 0.0906 - accuracy: 0.9495 - val_loss: 0.8717 - val_accuracy: 0.6228\n",
      "Epoch 828/3000\n",
      "\n",
      "Epoch 00828: val_loss did not improve from 0.08455\n",
      "455/455 - 0s - loss: 0.1723 - accuracy: 0.9297 - val_loss: 0.1177 - val_accuracy: 0.9649\n",
      "Epoch 829/3000\n",
      "\n",
      "Epoch 00829: val_loss did not improve from 0.08455\n",
      "455/455 - 0s - loss: 0.0888 - accuracy: 0.9626 - val_loss: 0.0990 - val_accuracy: 0.9649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 830/3000\n",
      "\n",
      "Epoch 00830: val_loss did not improve from 0.08455\n",
      "455/455 - 0s - loss: 0.0854 - accuracy: 0.9604 - val_loss: 0.0960 - val_accuracy: 0.9474\n",
      "Epoch 831/3000\n",
      "\n",
      "Epoch 00831: val_loss did not improve from 0.08455\n",
      "455/455 - 0s - loss: 0.0811 - accuracy: 0.9670 - val_loss: 0.1012 - val_accuracy: 0.9474\n",
      "Epoch 832/3000\n",
      "\n",
      "Epoch 00832: val_loss did not improve from 0.08455\n",
      "455/455 - 0s - loss: 0.0926 - accuracy: 0.9582 - val_loss: 0.0887 - val_accuracy: 0.9561\n",
      "Epoch 833/3000\n",
      "\n",
      "Epoch 00833: val_loss did not improve from 0.08455\n",
      "455/455 - 0s - loss: 0.0813 - accuracy: 0.9604 - val_loss: 0.1625 - val_accuracy: 0.9737\n",
      "Epoch 834/3000\n",
      "\n",
      "Epoch 00834: val_loss did not improve from 0.08455\n",
      "455/455 - 0s - loss: 0.2386 - accuracy: 0.9055 - val_loss: 0.1325 - val_accuracy: 0.9386\n",
      "Epoch 835/3000\n",
      "\n",
      "Epoch 00835: val_loss did not improve from 0.08455\n",
      "455/455 - 0s - loss: 0.0851 - accuracy: 0.9648 - val_loss: 0.1269 - val_accuracy: 0.9386\n",
      "Epoch 836/3000\n",
      "\n",
      "Epoch 00836: val_loss did not improve from 0.08455\n",
      "455/455 - 0s - loss: 0.0840 - accuracy: 0.9648 - val_loss: 0.1638 - val_accuracy: 0.9298\n",
      "Epoch 837/3000\n",
      "\n",
      "Epoch 00837: val_loss did not improve from 0.08455\n",
      "455/455 - 0s - loss: 0.0789 - accuracy: 0.9736 - val_loss: 0.1728 - val_accuracy: 0.9298\n",
      "Epoch 838/3000\n",
      "\n",
      "Epoch 00838: val_loss did not improve from 0.08455\n",
      "455/455 - 0s - loss: 0.0698 - accuracy: 0.9648 - val_loss: 0.0932 - val_accuracy: 0.9561\n",
      "Epoch 839/3000\n",
      "\n",
      "Epoch 00839: val_loss did not improve from 0.08455\n",
      "455/455 - 0s - loss: 0.0731 - accuracy: 0.9714 - val_loss: 0.2232 - val_accuracy: 0.9123\n",
      "Epoch 840/3000\n",
      "\n",
      "Epoch 00840: val_loss did not improve from 0.08455\n",
      "455/455 - 0s - loss: 0.0876 - accuracy: 0.9604 - val_loss: 0.5401 - val_accuracy: 0.7281\n",
      "Epoch 841/3000\n",
      "\n",
      "Epoch 00841: val_loss did not improve from 0.08455\n",
      "455/455 - 0s - loss: 0.1078 - accuracy: 0.9495 - val_loss: 0.0869 - val_accuracy: 0.9737\n",
      "Epoch 842/3000\n",
      "\n",
      "Epoch 00842: val_loss did not improve from 0.08455\n",
      "455/455 - 0s - loss: 0.0938 - accuracy: 0.9538 - val_loss: 0.1857 - val_accuracy: 0.9211\n",
      "Epoch 843/3000\n",
      "\n",
      "Epoch 00843: val_loss did not improve from 0.08455\n",
      "455/455 - 0s - loss: 0.0812 - accuracy: 0.9582 - val_loss: 0.3107 - val_accuracy: 0.8421\n",
      "Epoch 844/3000\n",
      "\n",
      "Epoch 00844: val_loss did not improve from 0.08455\n",
      "455/455 - 0s - loss: 0.0854 - accuracy: 0.9604 - val_loss: 0.1617 - val_accuracy: 0.9298\n",
      "Epoch 845/3000\n",
      "\n",
      "Epoch 00845: val_loss did not improve from 0.08455\n",
      "455/455 - 0s - loss: 0.0715 - accuracy: 0.9648 - val_loss: 0.0988 - val_accuracy: 0.9561\n",
      "Epoch 846/3000\n",
      "\n",
      "Epoch 00846: val_loss did not improve from 0.08455\n",
      "455/455 - 0s - loss: 0.0934 - accuracy: 0.9626 - val_loss: 0.0954 - val_accuracy: 0.9737\n",
      "Epoch 847/3000\n",
      "\n",
      "Epoch 00847: val_loss did not improve from 0.08455\n",
      "455/455 - 0s - loss: 0.0875 - accuracy: 0.9560 - val_loss: 0.2737 - val_accuracy: 0.8947\n",
      "Epoch 848/3000\n",
      "\n",
      "Epoch 00848: val_loss did not improve from 0.08455\n",
      "455/455 - 0s - loss: 0.0819 - accuracy: 0.9648 - val_loss: 0.1449 - val_accuracy: 0.9386\n",
      "Epoch 849/3000\n",
      "\n",
      "Epoch 00849: val_loss did not improve from 0.08455\n",
      "455/455 - 0s - loss: 0.0679 - accuracy: 0.9714 - val_loss: 0.0950 - val_accuracy: 0.9561\n",
      "Epoch 850/3000\n",
      "\n",
      "Epoch 00850: val_loss did not improve from 0.08455\n",
      "455/455 - 0s - loss: 0.0967 - accuracy: 0.9626 - val_loss: 0.7559 - val_accuracy: 0.6579\n",
      "Epoch 851/3000\n",
      "\n",
      "Epoch 00851: val_loss did not improve from 0.08455\n",
      "455/455 - 0s - loss: 0.1359 - accuracy: 0.9363 - val_loss: 0.1264 - val_accuracy: 0.9474\n",
      "Epoch 852/3000\n",
      "\n",
      "Epoch 00852: val_loss did not improve from 0.08455\n",
      "455/455 - 0s - loss: 0.0726 - accuracy: 0.9648 - val_loss: 0.0971 - val_accuracy: 0.9561\n",
      "Epoch 853/3000\n",
      "\n",
      "Epoch 00853: val_loss did not improve from 0.08455\n",
      "455/455 - 0s - loss: 0.0693 - accuracy: 0.9692 - val_loss: 0.1630 - val_accuracy: 0.9211\n",
      "Epoch 854/3000\n",
      "\n",
      "Epoch 00854: val_loss did not improve from 0.08455\n",
      "455/455 - 0s - loss: 0.0688 - accuracy: 0.9648 - val_loss: 0.4299 - val_accuracy: 0.8070\n",
      "Epoch 855/3000\n",
      "\n",
      "Epoch 00855: val_loss did not improve from 0.08455\n",
      "455/455 - 0s - loss: 0.0886 - accuracy: 0.9670 - val_loss: 0.1104 - val_accuracy: 0.9386\n",
      "Epoch 856/3000\n",
      "\n",
      "Epoch 00856: val_loss did not improve from 0.08455\n",
      "455/455 - 0s - loss: 0.0801 - accuracy: 0.9626 - val_loss: 0.5584 - val_accuracy: 0.7193\n",
      "Epoch 857/3000\n",
      "\n",
      "Epoch 00857: val_loss did not improve from 0.08455\n",
      "455/455 - 0s - loss: 0.1218 - accuracy: 0.9297 - val_loss: 0.1859 - val_accuracy: 0.9211\n",
      "Epoch 858/3000\n",
      "\n",
      "Epoch 00858: val_loss did not improve from 0.08455\n",
      "455/455 - 0s - loss: 0.0680 - accuracy: 0.9692 - val_loss: 0.1105 - val_accuracy: 0.9649\n",
      "Epoch 859/3000\n",
      "\n",
      "Epoch 00859: val_loss did not improve from 0.08455\n",
      "455/455 - 0s - loss: 0.1333 - accuracy: 0.9495 - val_loss: 0.2219 - val_accuracy: 0.9211\n",
      "Epoch 860/3000\n",
      "\n",
      "Epoch 00860: val_loss improved from 0.08455 to 0.08055, saving model to ../model/cencer860-0.0805.hdf5\n",
      "455/455 - 0s - loss: 0.0757 - accuracy: 0.9670 - val_loss: 0.0805 - val_accuracy: 0.9737\n",
      "Epoch 861/3000\n",
      "\n",
      "Epoch 00861: val_loss did not improve from 0.08055\n",
      "455/455 - 0s - loss: 0.0699 - accuracy: 0.9714 - val_loss: 0.1737 - val_accuracy: 0.9211\n",
      "Epoch 862/3000\n",
      "\n",
      "Epoch 00862: val_loss did not improve from 0.08055\n",
      "455/455 - 0s - loss: 0.0665 - accuracy: 0.9648 - val_loss: 0.1884 - val_accuracy: 0.9211\n",
      "Epoch 863/3000\n",
      "\n",
      "Epoch 00863: val_loss did not improve from 0.08055\n",
      "455/455 - 0s - loss: 0.0735 - accuracy: 0.9714 - val_loss: 0.7614 - val_accuracy: 0.7105\n",
      "Epoch 864/3000\n",
      "\n",
      "Epoch 00864: val_loss did not improve from 0.08055\n",
      "455/455 - 0s - loss: 0.4655 - accuracy: 0.8264 - val_loss: 0.1631 - val_accuracy: 0.9561\n",
      "Epoch 865/3000\n",
      "\n",
      "Epoch 00865: val_loss did not improve from 0.08055\n",
      "455/455 - 0s - loss: 0.1098 - accuracy: 0.9560 - val_loss: 0.1802 - val_accuracy: 0.9298\n",
      "Epoch 866/3000\n",
      "\n",
      "Epoch 00866: val_loss did not improve from 0.08055\n",
      "455/455 - 0s - loss: 0.0914 - accuracy: 0.9582 - val_loss: 0.1026 - val_accuracy: 0.9737\n",
      "Epoch 867/3000\n",
      "\n",
      "Epoch 00867: val_loss did not improve from 0.08055\n",
      "455/455 - 0s - loss: 0.0991 - accuracy: 0.9604 - val_loss: 0.1003 - val_accuracy: 0.9649\n",
      "Epoch 868/3000\n",
      "\n",
      "Epoch 00868: val_loss did not improve from 0.08055\n",
      "455/455 - 0s - loss: 0.0908 - accuracy: 0.9516 - val_loss: 0.1059 - val_accuracy: 0.9561\n",
      "Epoch 869/3000\n",
      "\n",
      "Epoch 00869: val_loss did not improve from 0.08055\n",
      "455/455 - 0s - loss: 0.0856 - accuracy: 0.9582 - val_loss: 0.0977 - val_accuracy: 0.9561\n",
      "Epoch 870/3000\n",
      "\n",
      "Epoch 00870: val_loss did not improve from 0.08055\n",
      "455/455 - 0s - loss: 0.0868 - accuracy: 0.9670 - val_loss: 0.1952 - val_accuracy: 0.9298\n",
      "Epoch 871/3000\n",
      "\n",
      "Epoch 00871: val_loss did not improve from 0.08055\n",
      "455/455 - 0s - loss: 0.0818 - accuracy: 0.9648 - val_loss: 0.5612 - val_accuracy: 0.7281\n",
      "Epoch 872/3000\n",
      "\n",
      "Epoch 00872: val_loss did not improve from 0.08055\n",
      "455/455 - 0s - loss: 0.1309 - accuracy: 0.9495 - val_loss: 0.1768 - val_accuracy: 0.9298\n",
      "Epoch 873/3000\n",
      "\n",
      "Epoch 00873: val_loss did not improve from 0.08055\n",
      "455/455 - 0s - loss: 0.0881 - accuracy: 0.9516 - val_loss: 0.1524 - val_accuracy: 0.9298\n",
      "Epoch 874/3000\n",
      "\n",
      "Epoch 00874: val_loss did not improve from 0.08055\n",
      "455/455 - 0s - loss: 0.0805 - accuracy: 0.9604 - val_loss: 0.1088 - val_accuracy: 0.9474\n",
      "Epoch 875/3000\n",
      "\n",
      "Epoch 00875: val_loss did not improve from 0.08055\n",
      "455/455 - 0s - loss: 0.0741 - accuracy: 0.9626 - val_loss: 0.1338 - val_accuracy: 0.9386\n",
      "Epoch 876/3000\n",
      "\n",
      "Epoch 00876: val_loss did not improve from 0.08055\n",
      "455/455 - 0s - loss: 0.0698 - accuracy: 0.9758 - val_loss: 0.1628 - val_accuracy: 0.9211\n",
      "Epoch 877/3000\n",
      "\n",
      "Epoch 00877: val_loss did not improve from 0.08055\n",
      "455/455 - 0s - loss: 0.1610 - accuracy: 0.9407 - val_loss: 0.1353 - val_accuracy: 0.9474\n",
      "Epoch 878/3000\n",
      "\n",
      "Epoch 00878: val_loss did not improve from 0.08055\n",
      "455/455 - 0s - loss: 0.0795 - accuracy: 0.9648 - val_loss: 0.1049 - val_accuracy: 0.9561\n",
      "Epoch 879/3000\n",
      "\n",
      "Epoch 00879: val_loss did not improve from 0.08055\n",
      "455/455 - 0s - loss: 0.0825 - accuracy: 0.9560 - val_loss: 0.1071 - val_accuracy: 0.9474\n",
      "Epoch 880/3000\n",
      "\n",
      "Epoch 00880: val_loss did not improve from 0.08055\n",
      "455/455 - 0s - loss: 0.0819 - accuracy: 0.9626 - val_loss: 0.1058 - val_accuracy: 0.9474\n",
      "Epoch 881/3000\n",
      "\n",
      "Epoch 00881: val_loss did not improve from 0.08055\n",
      "455/455 - 0s - loss: 0.0739 - accuracy: 0.9648 - val_loss: 0.0967 - val_accuracy: 0.9561\n",
      "Epoch 882/3000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00882: val_loss did not improve from 0.08055\n",
      "455/455 - 0s - loss: 0.0740 - accuracy: 0.9648 - val_loss: 0.1015 - val_accuracy: 0.9737\n",
      "Epoch 883/3000\n",
      "\n",
      "Epoch 00883: val_loss did not improve from 0.08055\n",
      "455/455 - 0s - loss: 0.0913 - accuracy: 0.9582 - val_loss: 0.1089 - val_accuracy: 0.9386\n",
      "Epoch 884/3000\n",
      "\n",
      "Epoch 00884: val_loss did not improve from 0.08055\n",
      "455/455 - 0s - loss: 0.0958 - accuracy: 0.9516 - val_loss: 0.1273 - val_accuracy: 0.9386\n",
      "Epoch 885/3000\n",
      "\n",
      "Epoch 00885: val_loss did not improve from 0.08055\n",
      "455/455 - 0s - loss: 0.0782 - accuracy: 0.9736 - val_loss: 0.0971 - val_accuracy: 0.9649\n",
      "Epoch 886/3000\n",
      "\n",
      "Epoch 00886: val_loss did not improve from 0.08055\n",
      "455/455 - 0s - loss: 0.0999 - accuracy: 0.9538 - val_loss: 0.3373 - val_accuracy: 0.8158\n",
      "Epoch 887/3000\n",
      "\n",
      "Epoch 00887: val_loss did not improve from 0.08055\n",
      "455/455 - 0s - loss: 0.0837 - accuracy: 0.9604 - val_loss: 0.0897 - val_accuracy: 0.9561\n",
      "Epoch 888/3000\n",
      "\n",
      "Epoch 00888: val_loss did not improve from 0.08055\n",
      "455/455 - 0s - loss: 0.0740 - accuracy: 0.9648 - val_loss: 0.1240 - val_accuracy: 0.9386\n",
      "Epoch 889/3000\n",
      "\n",
      "Epoch 00889: val_loss did not improve from 0.08055\n",
      "455/455 - 0s - loss: 0.0753 - accuracy: 0.9692 - val_loss: 0.0984 - val_accuracy: 0.9561\n",
      "Epoch 890/3000\n",
      "\n",
      "Epoch 00890: val_loss did not improve from 0.08055\n",
      "455/455 - 0s - loss: 0.0765 - accuracy: 0.9648 - val_loss: 0.2037 - val_accuracy: 0.9035\n",
      "Epoch 891/3000\n",
      "\n",
      "Epoch 00891: val_loss did not improve from 0.08055\n",
      "455/455 - 0s - loss: 0.1025 - accuracy: 0.9648 - val_loss: 0.0895 - val_accuracy: 0.9649\n",
      "Epoch 892/3000\n",
      "\n",
      "Epoch 00892: val_loss did not improve from 0.08055\n",
      "455/455 - 0s - loss: 0.0864 - accuracy: 0.9648 - val_loss: 0.1117 - val_accuracy: 0.9386\n",
      "Epoch 893/3000\n",
      "\n",
      "Epoch 00893: val_loss did not improve from 0.08055\n",
      "455/455 - 0s - loss: 0.0975 - accuracy: 0.9538 - val_loss: 0.1165 - val_accuracy: 0.9474\n",
      "Epoch 894/3000\n",
      "\n",
      "Epoch 00894: val_loss did not improve from 0.08055\n",
      "455/455 - 0s - loss: 0.0747 - accuracy: 0.9692 - val_loss: 0.1970 - val_accuracy: 0.9211\n",
      "Epoch 895/3000\n",
      "\n",
      "Epoch 00895: val_loss did not improve from 0.08055\n",
      "455/455 - 0s - loss: 0.0680 - accuracy: 0.9670 - val_loss: 0.0935 - val_accuracy: 0.9737\n",
      "Epoch 896/3000\n",
      "\n",
      "Epoch 00896: val_loss did not improve from 0.08055\n",
      "455/455 - 0s - loss: 0.1105 - accuracy: 0.9560 - val_loss: 0.1157 - val_accuracy: 0.9474\n",
      "Epoch 897/3000\n",
      "\n",
      "Epoch 00897: val_loss did not improve from 0.08055\n",
      "455/455 - 0s - loss: 0.0722 - accuracy: 0.9692 - val_loss: 0.1251 - val_accuracy: 0.9386\n",
      "Epoch 898/3000\n",
      "\n",
      "Epoch 00898: val_loss did not improve from 0.08055\n",
      "455/455 - 0s - loss: 0.0810 - accuracy: 0.9670 - val_loss: 0.0922 - val_accuracy: 0.9649\n",
      "Epoch 899/3000\n",
      "\n",
      "Epoch 00899: val_loss did not improve from 0.08055\n",
      "455/455 - 0s - loss: 0.0776 - accuracy: 0.9692 - val_loss: 0.1027 - val_accuracy: 0.9474\n",
      "Epoch 900/3000\n",
      "\n",
      "Epoch 00900: val_loss did not improve from 0.08055\n",
      "455/455 - 0s - loss: 0.1034 - accuracy: 0.9538 - val_loss: 0.1370 - val_accuracy: 0.9474\n",
      "Epoch 901/3000\n",
      "\n",
      "Epoch 00901: val_loss did not improve from 0.08055\n",
      "455/455 - 0s - loss: 0.0641 - accuracy: 0.9736 - val_loss: 0.1733 - val_accuracy: 0.9298\n",
      "Epoch 902/3000\n",
      "\n",
      "Epoch 00902: val_loss did not improve from 0.08055\n",
      "455/455 - 0s - loss: 0.0882 - accuracy: 0.9626 - val_loss: 0.1734 - val_accuracy: 0.9298\n",
      "Epoch 903/3000\n",
      "\n",
      "Epoch 00903: val_loss did not improve from 0.08055\n",
      "455/455 - 0s - loss: 0.0718 - accuracy: 0.9670 - val_loss: 0.1558 - val_accuracy: 0.9386\n",
      "Epoch 904/3000\n",
      "\n",
      "Epoch 00904: val_loss did not improve from 0.08055\n",
      "455/455 - 0s - loss: 0.0648 - accuracy: 0.9714 - val_loss: 0.2108 - val_accuracy: 0.9035\n",
      "Epoch 905/3000\n",
      "\n",
      "Epoch 00905: val_loss did not improve from 0.08055\n",
      "455/455 - 0s - loss: 0.0643 - accuracy: 0.9714 - val_loss: 0.0847 - val_accuracy: 0.9561\n",
      "Epoch 906/3000\n",
      "\n",
      "Epoch 00906: val_loss did not improve from 0.08055\n",
      "455/455 - 0s - loss: 0.0794 - accuracy: 0.9626 - val_loss: 0.0841 - val_accuracy: 0.9649\n",
      "Epoch 907/3000\n",
      "\n",
      "Epoch 00907: val_loss did not improve from 0.08055\n",
      "455/455 - 0s - loss: 0.0837 - accuracy: 0.9670 - val_loss: 0.1578 - val_accuracy: 0.9211\n",
      "Epoch 908/3000\n",
      "\n",
      "Epoch 00908: val_loss improved from 0.08055 to 0.07999, saving model to ../model/cencer908-0.0800.hdf5\n",
      "455/455 - 0s - loss: 0.0807 - accuracy: 0.9604 - val_loss: 0.0800 - val_accuracy: 0.9649\n",
      "Epoch 909/3000\n",
      "\n",
      "Epoch 00909: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0659 - accuracy: 0.9736 - val_loss: 0.0915 - val_accuracy: 0.9737\n",
      "Epoch 910/3000\n",
      "\n",
      "Epoch 00910: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.1747 - accuracy: 0.9253 - val_loss: 0.1179 - val_accuracy: 0.9474\n",
      "Epoch 911/3000\n",
      "\n",
      "Epoch 00911: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0728 - accuracy: 0.9648 - val_loss: 0.1992 - val_accuracy: 0.9211\n",
      "Epoch 912/3000\n",
      "\n",
      "Epoch 00912: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0692 - accuracy: 0.9670 - val_loss: 0.1321 - val_accuracy: 0.9386\n",
      "Epoch 913/3000\n",
      "\n",
      "Epoch 00913: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0989 - accuracy: 0.9604 - val_loss: 0.1534 - val_accuracy: 0.9298\n",
      "Epoch 914/3000\n",
      "\n",
      "Epoch 00914: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0694 - accuracy: 0.9692 - val_loss: 0.1161 - val_accuracy: 0.9474\n",
      "Epoch 915/3000\n",
      "\n",
      "Epoch 00915: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0804 - accuracy: 0.9670 - val_loss: 0.1043 - val_accuracy: 0.9649\n",
      "Epoch 916/3000\n",
      "\n",
      "Epoch 00916: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0788 - accuracy: 0.9648 - val_loss: 0.1788 - val_accuracy: 0.9298\n",
      "Epoch 917/3000\n",
      "\n",
      "Epoch 00917: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0727 - accuracy: 0.9692 - val_loss: 0.1709 - val_accuracy: 0.9298\n",
      "Epoch 918/3000\n",
      "\n",
      "Epoch 00918: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0689 - accuracy: 0.9670 - val_loss: 0.1398 - val_accuracy: 0.9386\n",
      "Epoch 919/3000\n",
      "\n",
      "Epoch 00919: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0694 - accuracy: 0.9670 - val_loss: 0.0932 - val_accuracy: 0.9649\n",
      "Epoch 920/3000\n",
      "\n",
      "Epoch 00920: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0697 - accuracy: 0.9604 - val_loss: 0.1590 - val_accuracy: 0.9298\n",
      "Epoch 921/3000\n",
      "\n",
      "Epoch 00921: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0740 - accuracy: 0.9692 - val_loss: 0.1101 - val_accuracy: 0.9386\n",
      "Epoch 922/3000\n",
      "\n",
      "Epoch 00922: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0694 - accuracy: 0.9648 - val_loss: 0.1462 - val_accuracy: 0.9386\n",
      "Epoch 923/3000\n",
      "\n",
      "Epoch 00923: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0727 - accuracy: 0.9582 - val_loss: 0.1793 - val_accuracy: 0.9298\n",
      "Epoch 924/3000\n",
      "\n",
      "Epoch 00924: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0787 - accuracy: 0.9758 - val_loss: 0.1300 - val_accuracy: 0.9386\n",
      "Epoch 925/3000\n",
      "\n",
      "Epoch 00925: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0720 - accuracy: 0.9736 - val_loss: 0.2345 - val_accuracy: 0.8947\n",
      "Epoch 926/3000\n",
      "\n",
      "Epoch 00926: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0804 - accuracy: 0.9604 - val_loss: 0.3934 - val_accuracy: 0.8070\n",
      "Epoch 927/3000\n",
      "\n",
      "Epoch 00927: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0700 - accuracy: 0.9626 - val_loss: 0.1232 - val_accuracy: 0.9386\n",
      "Epoch 928/3000\n",
      "\n",
      "Epoch 00928: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0624 - accuracy: 0.9736 - val_loss: 0.1246 - val_accuracy: 0.9386\n",
      "Epoch 929/3000\n",
      "\n",
      "Epoch 00929: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.1502 - accuracy: 0.9407 - val_loss: 0.1085 - val_accuracy: 0.9474\n",
      "Epoch 930/3000\n",
      "\n",
      "Epoch 00930: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0657 - accuracy: 0.9648 - val_loss: 0.5905 - val_accuracy: 0.7281\n",
      "Epoch 931/3000\n",
      "\n",
      "Epoch 00931: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.1509 - accuracy: 0.9538 - val_loss: 0.1399 - val_accuracy: 0.9386\n",
      "Epoch 932/3000\n",
      "\n",
      "Epoch 00932: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0851 - accuracy: 0.9692 - val_loss: 0.1178 - val_accuracy: 0.9474\n",
      "Epoch 933/3000\n",
      "\n",
      "Epoch 00933: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.1040 - accuracy: 0.9473 - val_loss: 0.0948 - val_accuracy: 0.9737\n",
      "Epoch 934/3000\n",
      "\n",
      "Epoch 00934: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0755 - accuracy: 0.9648 - val_loss: 0.0871 - val_accuracy: 0.9649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 935/3000\n",
      "\n",
      "Epoch 00935: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0713 - accuracy: 0.9670 - val_loss: 0.0924 - val_accuracy: 0.9649\n",
      "Epoch 936/3000\n",
      "\n",
      "Epoch 00936: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0763 - accuracy: 0.9626 - val_loss: 0.2554 - val_accuracy: 0.9474\n",
      "Epoch 937/3000\n",
      "\n",
      "Epoch 00937: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.1162 - accuracy: 0.9495 - val_loss: 0.3139 - val_accuracy: 0.8421\n",
      "Epoch 938/3000\n",
      "\n",
      "Epoch 00938: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0690 - accuracy: 0.9824 - val_loss: 0.1065 - val_accuracy: 0.9474\n",
      "Epoch 939/3000\n",
      "\n",
      "Epoch 00939: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0678 - accuracy: 0.9692 - val_loss: 0.1065 - val_accuracy: 0.9386\n",
      "Epoch 940/3000\n",
      "\n",
      "Epoch 00940: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0815 - accuracy: 0.9648 - val_loss: 0.0824 - val_accuracy: 0.9737\n",
      "Epoch 941/3000\n",
      "\n",
      "Epoch 00941: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0756 - accuracy: 0.9670 - val_loss: 0.1429 - val_accuracy: 0.9386\n",
      "Epoch 942/3000\n",
      "\n",
      "Epoch 00942: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0778 - accuracy: 0.9626 - val_loss: 0.1096 - val_accuracy: 0.9737\n",
      "Epoch 943/3000\n",
      "\n",
      "Epoch 00943: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.1010 - accuracy: 0.9582 - val_loss: 0.1063 - val_accuracy: 0.9649\n",
      "Epoch 944/3000\n",
      "\n",
      "Epoch 00944: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.1630 - accuracy: 0.9253 - val_loss: 0.0903 - val_accuracy: 0.9649\n",
      "Epoch 945/3000\n",
      "\n",
      "Epoch 00945: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0660 - accuracy: 0.9758 - val_loss: 0.1740 - val_accuracy: 0.9298\n",
      "Epoch 946/3000\n",
      "\n",
      "Epoch 00946: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0705 - accuracy: 0.9758 - val_loss: 0.0846 - val_accuracy: 0.9737\n",
      "Epoch 947/3000\n",
      "\n",
      "Epoch 00947: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0748 - accuracy: 0.9648 - val_loss: 0.1047 - val_accuracy: 0.9474\n",
      "Epoch 948/3000\n",
      "\n",
      "Epoch 00948: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0670 - accuracy: 0.9648 - val_loss: 0.2894 - val_accuracy: 0.8509\n",
      "Epoch 949/3000\n",
      "\n",
      "Epoch 00949: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0750 - accuracy: 0.9648 - val_loss: 0.0839 - val_accuracy: 0.9649\n",
      "Epoch 950/3000\n",
      "\n",
      "Epoch 00950: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0745 - accuracy: 0.9736 - val_loss: 0.6271 - val_accuracy: 0.7018\n",
      "Epoch 951/3000\n",
      "\n",
      "Epoch 00951: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.1033 - accuracy: 0.9560 - val_loss: 0.1014 - val_accuracy: 0.9649\n",
      "Epoch 952/3000\n",
      "\n",
      "Epoch 00952: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0766 - accuracy: 0.9604 - val_loss: 0.0821 - val_accuracy: 0.9649\n",
      "Epoch 953/3000\n",
      "\n",
      "Epoch 00953: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0676 - accuracy: 0.9670 - val_loss: 0.1500 - val_accuracy: 0.9298\n",
      "Epoch 954/3000\n",
      "\n",
      "Epoch 00954: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0687 - accuracy: 0.9670 - val_loss: 0.1378 - val_accuracy: 0.9386\n",
      "Epoch 955/3000\n",
      "\n",
      "Epoch 00955: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0604 - accuracy: 0.9736 - val_loss: 0.0951 - val_accuracy: 0.9649\n",
      "Epoch 956/3000\n",
      "\n",
      "Epoch 00956: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.1106 - accuracy: 0.9538 - val_loss: 0.2527 - val_accuracy: 0.8947\n",
      "Epoch 957/3000\n",
      "\n",
      "Epoch 00957: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0857 - accuracy: 0.9626 - val_loss: 0.0884 - val_accuracy: 0.9649\n",
      "Epoch 958/3000\n",
      "\n",
      "Epoch 00958: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0780 - accuracy: 0.9670 - val_loss: 0.2331 - val_accuracy: 0.9035\n",
      "Epoch 959/3000\n",
      "\n",
      "Epoch 00959: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0822 - accuracy: 0.9670 - val_loss: 0.1563 - val_accuracy: 0.9298\n",
      "Epoch 960/3000\n",
      "\n",
      "Epoch 00960: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0972 - accuracy: 0.9692 - val_loss: 0.0824 - val_accuracy: 0.9649\n",
      "Epoch 961/3000\n",
      "\n",
      "Epoch 00961: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0677 - accuracy: 0.9736 - val_loss: 0.0905 - val_accuracy: 0.9737\n",
      "Epoch 962/3000\n",
      "\n",
      "Epoch 00962: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0767 - accuracy: 0.9560 - val_loss: 0.1726 - val_accuracy: 0.9386\n",
      "Epoch 963/3000\n",
      "\n",
      "Epoch 00963: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0683 - accuracy: 0.9714 - val_loss: 0.2147 - val_accuracy: 0.9123\n",
      "Epoch 964/3000\n",
      "\n",
      "Epoch 00964: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0819 - accuracy: 0.9692 - val_loss: 0.0827 - val_accuracy: 0.9825\n",
      "Epoch 965/3000\n",
      "\n",
      "Epoch 00965: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0627 - accuracy: 0.9736 - val_loss: 0.0841 - val_accuracy: 0.9737\n",
      "Epoch 966/3000\n",
      "\n",
      "Epoch 00966: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.1325 - accuracy: 0.9363 - val_loss: 0.1546 - val_accuracy: 0.9386\n",
      "Epoch 967/3000\n",
      "\n",
      "Epoch 00967: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0697 - accuracy: 0.9692 - val_loss: 0.1483 - val_accuracy: 0.9386\n",
      "Epoch 968/3000\n",
      "\n",
      "Epoch 00968: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0655 - accuracy: 0.9692 - val_loss: 0.1054 - val_accuracy: 0.9561\n",
      "Epoch 969/3000\n",
      "\n",
      "Epoch 00969: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0660 - accuracy: 0.9714 - val_loss: 0.2953 - val_accuracy: 0.8684\n",
      "Epoch 970/3000\n",
      "\n",
      "Epoch 00970: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0801 - accuracy: 0.9648 - val_loss: 0.0938 - val_accuracy: 0.9649\n",
      "Epoch 971/3000\n",
      "\n",
      "Epoch 00971: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0821 - accuracy: 0.9714 - val_loss: 0.0952 - val_accuracy: 0.9474\n",
      "Epoch 972/3000\n",
      "\n",
      "Epoch 00972: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0647 - accuracy: 0.9670 - val_loss: 0.1449 - val_accuracy: 0.9386\n",
      "Epoch 973/3000\n",
      "\n",
      "Epoch 00973: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0588 - accuracy: 0.9736 - val_loss: 0.0894 - val_accuracy: 0.9649\n",
      "Epoch 974/3000\n",
      "\n",
      "Epoch 00974: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0700 - accuracy: 0.9648 - val_loss: 0.1050 - val_accuracy: 0.9649\n",
      "Epoch 975/3000\n",
      "\n",
      "Epoch 00975: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0922 - accuracy: 0.9626 - val_loss: 0.2475 - val_accuracy: 0.8860\n",
      "Epoch 976/3000\n",
      "\n",
      "Epoch 00976: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0677 - accuracy: 0.9692 - val_loss: 0.3953 - val_accuracy: 0.7982\n",
      "Epoch 977/3000\n",
      "\n",
      "Epoch 00977: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.1066 - accuracy: 0.9538 - val_loss: 0.1879 - val_accuracy: 0.9298\n",
      "Epoch 978/3000\n",
      "\n",
      "Epoch 00978: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0652 - accuracy: 0.9626 - val_loss: 0.2010 - val_accuracy: 0.9211\n",
      "Epoch 979/3000\n",
      "\n",
      "Epoch 00979: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0656 - accuracy: 0.9670 - val_loss: 0.0953 - val_accuracy: 0.9649\n",
      "Epoch 980/3000\n",
      "\n",
      "Epoch 00980: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0923 - accuracy: 0.9692 - val_loss: 0.1085 - val_accuracy: 0.9474\n",
      "Epoch 981/3000\n",
      "\n",
      "Epoch 00981: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0758 - accuracy: 0.9714 - val_loss: 0.1009 - val_accuracy: 0.9561\n",
      "Epoch 982/3000\n",
      "\n",
      "Epoch 00982: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0676 - accuracy: 0.9670 - val_loss: 0.1187 - val_accuracy: 0.9386\n",
      "Epoch 983/3000\n",
      "\n",
      "Epoch 00983: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0628 - accuracy: 0.9736 - val_loss: 0.1445 - val_accuracy: 0.9298\n",
      "Epoch 984/3000\n",
      "\n",
      "Epoch 00984: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0708 - accuracy: 0.9670 - val_loss: 0.7605 - val_accuracy: 0.7105\n",
      "Epoch 985/3000\n",
      "\n",
      "Epoch 00985: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.1145 - accuracy: 0.9451 - val_loss: 0.1221 - val_accuracy: 0.9561\n",
      "Epoch 986/3000\n",
      "\n",
      "Epoch 00986: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0657 - accuracy: 0.9626 - val_loss: 0.1025 - val_accuracy: 0.9561\n",
      "Epoch 987/3000\n",
      "\n",
      "Epoch 00987: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0616 - accuracy: 0.9692 - val_loss: 0.5448 - val_accuracy: 0.7544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 988/3000\n",
      "\n",
      "Epoch 00988: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.1082 - accuracy: 0.9560 - val_loss: 0.0894 - val_accuracy: 0.9649\n",
      "Epoch 989/3000\n",
      "\n",
      "Epoch 00989: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0602 - accuracy: 0.9736 - val_loss: 0.2261 - val_accuracy: 0.8947\n",
      "Epoch 990/3000\n",
      "\n",
      "Epoch 00990: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0905 - accuracy: 0.9560 - val_loss: 0.7624 - val_accuracy: 0.7018\n",
      "Epoch 991/3000\n",
      "\n",
      "Epoch 00991: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.1139 - accuracy: 0.9560 - val_loss: 0.1363 - val_accuracy: 0.9386\n",
      "Epoch 992/3000\n",
      "\n",
      "Epoch 00992: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0653 - accuracy: 0.9714 - val_loss: 0.1673 - val_accuracy: 0.9298\n",
      "Epoch 993/3000\n",
      "\n",
      "Epoch 00993: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0684 - accuracy: 0.9692 - val_loss: 0.6333 - val_accuracy: 0.7193\n",
      "Epoch 994/3000\n",
      "\n",
      "Epoch 00994: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.1023 - accuracy: 0.9538 - val_loss: 0.1785 - val_accuracy: 0.9298\n",
      "Epoch 995/3000\n",
      "\n",
      "Epoch 00995: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0562 - accuracy: 0.9736 - val_loss: 0.1091 - val_accuracy: 0.9474\n",
      "Epoch 996/3000\n",
      "\n",
      "Epoch 00996: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0690 - accuracy: 0.9758 - val_loss: 0.1252 - val_accuracy: 0.9386\n",
      "Epoch 997/3000\n",
      "\n",
      "Epoch 00997: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0612 - accuracy: 0.9714 - val_loss: 0.7510 - val_accuracy: 0.7018\n",
      "Epoch 998/3000\n",
      "\n",
      "Epoch 00998: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.1103 - accuracy: 0.9407 - val_loss: 0.1174 - val_accuracy: 0.9474\n",
      "Epoch 999/3000\n",
      "\n",
      "Epoch 00999: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0570 - accuracy: 0.9758 - val_loss: 0.0912 - val_accuracy: 0.9649\n",
      "Epoch 1000/3000\n",
      "\n",
      "Epoch 01000: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0651 - accuracy: 0.9692 - val_loss: 0.7305 - val_accuracy: 0.7105\n",
      "Epoch 1001/3000\n",
      "\n",
      "Epoch 01001: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0977 - accuracy: 0.9495 - val_loss: 0.0837 - val_accuracy: 0.9649\n",
      "Epoch 1002/3000\n",
      "\n",
      "Epoch 01002: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0594 - accuracy: 0.9714 - val_loss: 0.1006 - val_accuracy: 0.9561\n",
      "Epoch 1003/3000\n",
      "\n",
      "Epoch 01003: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0584 - accuracy: 0.9780 - val_loss: 0.3516 - val_accuracy: 0.8246\n",
      "Epoch 1004/3000\n",
      "\n",
      "Epoch 01004: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0586 - accuracy: 0.9736 - val_loss: 0.1532 - val_accuracy: 0.9386\n",
      "Epoch 1005/3000\n",
      "\n",
      "Epoch 01005: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0582 - accuracy: 0.9714 - val_loss: 0.2202 - val_accuracy: 0.8860\n",
      "Epoch 1006/3000\n",
      "\n",
      "Epoch 01006: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0542 - accuracy: 0.9736 - val_loss: 0.2378 - val_accuracy: 0.8947\n",
      "Epoch 1007/3000\n",
      "\n",
      "Epoch 01007: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0745 - accuracy: 0.9560 - val_loss: 0.0903 - val_accuracy: 0.9561\n",
      "Epoch 1008/3000\n",
      "\n",
      "Epoch 01008: val_loss did not improve from 0.07999\n",
      "455/455 - 0s - loss: 0.0631 - accuracy: 0.9714 - val_loss: 0.2185 - val_accuracy: 0.9035\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x, y, epochs=3000, validation_split=0.2, batch_size= 100, verbose=2, callbacks=[earlystopping_cb, checkpointer_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('../model/cencer908-0.0800.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569/569 [==============================] - 0s 148us/sample - loss: 0.0793 - accuracy: 0.9631\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.96309316"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x, y)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_vloss =history.history['val_loss']\n",
    "y_acc = history.history['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_len = np.arange(len(y_acc))\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.ylim(0.0, 1.1)\n",
    "plt.plot(x_len, y_vloss, 'o', color='red', markersize=2)\n",
    "plt.plot(x_len, y_acc, 'o', color='blue', markersize=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load_digits = 다중분류 ->팀 회식\n",
    "### random_seed = 2020, train/test 8:2 validation 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2020\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "digs = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = digs.data.astype(np.float32)\n",
    "y_data = digs.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = LabelEncoder().fit_transform(y_data)\n",
    "y_data = np_utils.to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(250, input_dim=64, activation='selu', kernel_initializer='lecun_normal'),\n",
    "    Dense(100, activation='selu', kernel_initializer='lecun_normal'),\n",
    "    Dense(50, activation='selu', kernel_initializer='lecun_normal'),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopping_cb = EarlyStopping(monitor='val_loss', patience=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "             optimizer = keras.optimizers.Adam(lr=0.006),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1149 samples, validate on 288 samples\n",
      "Epoch 1/3000\n",
      "1149/1149 [==============================] - 0s 432us/sample - loss: 1.2295 - accuracy: 0.7319 - val_loss: 0.3908 - val_accuracy: 0.8889\n",
      "Epoch 2/3000\n",
      "1149/1149 [==============================] - 0s 59us/sample - loss: 0.1734 - accuracy: 0.9452 - val_loss: 0.1549 - val_accuracy: 0.9375\n",
      "Epoch 3/3000\n",
      "1149/1149 [==============================] - 0s 52us/sample - loss: 0.0769 - accuracy: 0.9739 - val_loss: 0.1309 - val_accuracy: 0.9583\n",
      "Epoch 4/3000\n",
      "1149/1149 [==============================] - 0s 50us/sample - loss: 0.1600 - accuracy: 0.9460 - val_loss: 0.1833 - val_accuracy: 0.9514\n",
      "Epoch 5/3000\n",
      "1149/1149 [==============================] - 0s 55us/sample - loss: 0.1156 - accuracy: 0.9617 - val_loss: 0.3827 - val_accuracy: 0.8958\n",
      "Epoch 6/3000\n",
      "1149/1149 [==============================] - 0s 59us/sample - loss: 0.3283 - accuracy: 0.9182 - val_loss: 0.3005 - val_accuracy: 0.9340\n",
      "Epoch 7/3000\n",
      "1149/1149 [==============================] - 0s 63us/sample - loss: 0.2314 - accuracy: 0.9434 - val_loss: 0.2416 - val_accuracy: 0.9549\n",
      "Epoch 8/3000\n",
      "1149/1149 [==============================] - 0s 67us/sample - loss: 0.1122 - accuracy: 0.9687 - val_loss: 0.1765 - val_accuracy: 0.9479\n",
      "Epoch 9/3000\n",
      "1149/1149 [==============================] - 0s 54us/sample - loss: 0.1364 - accuracy: 0.9565 - val_loss: 0.1810 - val_accuracy: 0.9549\n",
      "Epoch 10/3000\n",
      "1149/1149 [==============================] - 0s 49us/sample - loss: 0.1115 - accuracy: 0.9678 - val_loss: 0.5220 - val_accuracy: 0.8889\n",
      "Epoch 11/3000\n",
      "1149/1149 [==============================] - 0s 48us/sample - loss: 0.0868 - accuracy: 0.9730 - val_loss: 0.1493 - val_accuracy: 0.9514\n",
      "Epoch 12/3000\n",
      "1149/1149 [==============================] - 0s 61us/sample - loss: 0.0854 - accuracy: 0.9809 - val_loss: 0.4565 - val_accuracy: 0.9062\n",
      "Epoch 13/3000\n",
      "1149/1149 [==============================] - 0s 58us/sample - loss: 0.0281 - accuracy: 0.9904 - val_loss: 0.1675 - val_accuracy: 0.9583\n",
      "Epoch 14/3000\n",
      "1149/1149 [==============================] - 0s 54us/sample - loss: 0.0083 - accuracy: 0.9956 - val_loss: 0.1351 - val_accuracy: 0.9688\n",
      "Epoch 15/3000\n",
      "1149/1149 [==============================] - 0s 53us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1009 - val_accuracy: 0.9757\n",
      "Epoch 16/3000\n",
      "1149/1149 [==============================] - 0s 55us/sample - loss: 2.1865e-04 - accuracy: 1.0000 - val_loss: 0.0951 - val_accuracy: 0.9757\n",
      "Epoch 17/3000\n",
      "1149/1149 [==============================] - 0s 67us/sample - loss: 1.5977e-04 - accuracy: 1.0000 - val_loss: 0.0958 - val_accuracy: 0.9722\n",
      "Epoch 18/3000\n",
      "1149/1149 [==============================] - 0s 56us/sample - loss: 1.3425e-04 - accuracy: 1.0000 - val_loss: 0.0953 - val_accuracy: 0.9722\n",
      "Epoch 19/3000\n",
      "1149/1149 [==============================] - 0s 48us/sample - loss: 1.1876e-04 - accuracy: 1.0000 - val_loss: 0.0963 - val_accuracy: 0.9722\n",
      "Epoch 20/3000\n",
      "1149/1149 [==============================] - 0s 49us/sample - loss: 1.0511e-04 - accuracy: 1.0000 - val_loss: 0.0965 - val_accuracy: 0.9722\n",
      "Epoch 21/3000\n",
      "1149/1149 [==============================] - 0s 49us/sample - loss: 9.6167e-05 - accuracy: 1.0000 - val_loss: 0.0962 - val_accuracy: 0.9722\n",
      "Epoch 22/3000\n",
      "1149/1149 [==============================] - 0s 50us/sample - loss: 8.7622e-05 - accuracy: 1.0000 - val_loss: 0.0962 - val_accuracy: 0.9722\n",
      "Epoch 23/3000\n",
      "1149/1149 [==============================] - 0s 50us/sample - loss: 8.0762e-05 - accuracy: 1.0000 - val_loss: 0.0961 - val_accuracy: 0.9722\n",
      "Epoch 24/3000\n",
      "1149/1149 [==============================] - 0s 49us/sample - loss: 7.4644e-05 - accuracy: 1.0000 - val_loss: 0.0956 - val_accuracy: 0.9722\n",
      "Epoch 25/3000\n",
      "1149/1149 [==============================] - 0s 56us/sample - loss: 6.9205e-05 - accuracy: 1.0000 - val_loss: 0.0962 - val_accuracy: 0.9722\n",
      "Epoch 26/3000\n",
      "1149/1149 [==============================] - 0s 62us/sample - loss: 6.4854e-05 - accuracy: 1.0000 - val_loss: 0.0965 - val_accuracy: 0.9722\n",
      "Epoch 27/3000\n",
      "1149/1149 [==============================] - 0s 61us/sample - loss: 6.1117e-05 - accuracy: 1.0000 - val_loss: 0.0964 - val_accuracy: 0.9722\n",
      "Epoch 28/3000\n",
      "1149/1149 [==============================] - 0s 61us/sample - loss: 5.6899e-05 - accuracy: 1.0000 - val_loss: 0.0965 - val_accuracy: 0.9722\n",
      "Epoch 29/3000\n",
      "1149/1149 [==============================] - 0s 59us/sample - loss: 5.3724e-05 - accuracy: 1.0000 - val_loss: 0.0963 - val_accuracy: 0.9722\n",
      "Epoch 30/3000\n",
      "1149/1149 [==============================] - 0s 60us/sample - loss: 5.0934e-05 - accuracy: 1.0000 - val_loss: 0.0967 - val_accuracy: 0.9722\n",
      "Epoch 31/3000\n",
      "1149/1149 [==============================] - 0s 61us/sample - loss: 4.7766e-05 - accuracy: 1.0000 - val_loss: 0.0963 - val_accuracy: 0.9722\n",
      "Epoch 32/3000\n",
      "1149/1149 [==============================] - 0s 61us/sample - loss: 4.4777e-05 - accuracy: 1.0000 - val_loss: 0.0965 - val_accuracy: 0.9722\n",
      "Epoch 33/3000\n",
      "1149/1149 [==============================] - 0s 60us/sample - loss: 4.2507e-05 - accuracy: 1.0000 - val_loss: 0.0964 - val_accuracy: 0.9722\n",
      "Epoch 34/3000\n",
      "1149/1149 [==============================] - 0s 63us/sample - loss: 4.0237e-05 - accuracy: 1.0000 - val_loss: 0.0967 - val_accuracy: 0.9722\n",
      "Epoch 35/3000\n",
      "1149/1149 [==============================] - 0s 57us/sample - loss: 3.8350e-05 - accuracy: 1.0000 - val_loss: 0.0964 - val_accuracy: 0.9722\n",
      "Epoch 36/3000\n",
      "1149/1149 [==============================] - 0s 62us/sample - loss: 3.6497e-05 - accuracy: 1.0000 - val_loss: 0.0968 - val_accuracy: 0.9722\n",
      "Epoch 37/3000\n",
      "1149/1149 [==============================] - 0s 67us/sample - loss: 3.4784e-05 - accuracy: 1.0000 - val_loss: 0.0966 - val_accuracy: 0.9722\n",
      "Epoch 38/3000\n",
      "1149/1149 [==============================] - 0s 68us/sample - loss: 3.3337e-05 - accuracy: 1.0000 - val_loss: 0.0971 - val_accuracy: 0.9722\n",
      "Epoch 39/3000\n",
      "1149/1149 [==============================] - 0s 67us/sample - loss: 3.1681e-05 - accuracy: 1.0000 - val_loss: 0.0971 - val_accuracy: 0.9722\n",
      "Epoch 40/3000\n",
      "1149/1149 [==============================] - 0s 63us/sample - loss: 3.0316e-05 - accuracy: 1.0000 - val_loss: 0.0977 - val_accuracy: 0.9722\n",
      "Epoch 41/3000\n",
      "1149/1149 [==============================] - 0s 64us/sample - loss: 2.8968e-05 - accuracy: 1.0000 - val_loss: 0.0977 - val_accuracy: 0.9722\n",
      "Epoch 42/3000\n",
      "1149/1149 [==============================] - 0s 65us/sample - loss: 2.7825e-05 - accuracy: 1.0000 - val_loss: 0.0972 - val_accuracy: 0.9722\n",
      "Epoch 43/3000\n",
      "1149/1149 [==============================] - 0s 66us/sample - loss: 2.6746e-05 - accuracy: 1.0000 - val_loss: 0.0980 - val_accuracy: 0.9722\n",
      "Epoch 44/3000\n",
      "1149/1149 [==============================] - 0s 53us/sample - loss: 2.5693e-05 - accuracy: 1.0000 - val_loss: 0.0976 - val_accuracy: 0.9722\n",
      "Epoch 45/3000\n",
      "1149/1149 [==============================] - 0s 52us/sample - loss: 2.4521e-05 - accuracy: 1.0000 - val_loss: 0.0987 - val_accuracy: 0.9722\n",
      "Epoch 46/3000\n",
      "1149/1149 [==============================] - 0s 60us/sample - loss: 2.3539e-05 - accuracy: 1.0000 - val_loss: 0.0985 - val_accuracy: 0.9722\n",
      "Epoch 47/3000\n",
      "1149/1149 [==============================] - 0s 55us/sample - loss: 2.2609e-05 - accuracy: 1.0000 - val_loss: 0.0987 - val_accuracy: 0.9722\n",
      "Epoch 48/3000\n",
      "1149/1149 [==============================] - 0s 64us/sample - loss: 2.1767e-05 - accuracy: 1.0000 - val_loss: 0.0984 - val_accuracy: 0.9722\n",
      "Epoch 49/3000\n",
      "1149/1149 [==============================] - 0s 59us/sample - loss: 2.0914e-05 - accuracy: 1.0000 - val_loss: 0.0988 - val_accuracy: 0.9722\n",
      "Epoch 50/3000\n",
      "1149/1149 [==============================] - 0s 61us/sample - loss: 2.0123e-05 - accuracy: 1.0000 - val_loss: 0.0989 - val_accuracy: 0.9722\n",
      "Epoch 51/3000\n",
      "1149/1149 [==============================] - 0s 64us/sample - loss: 1.9431e-05 - accuracy: 1.0000 - val_loss: 0.0991 - val_accuracy: 0.9722\n",
      "Epoch 52/3000\n",
      "1149/1149 [==============================] - 0s 65us/sample - loss: 1.8716e-05 - accuracy: 1.0000 - val_loss: 0.0994 - val_accuracy: 0.9722\n",
      "Epoch 53/3000\n",
      "1149/1149 [==============================] - 0s 57us/sample - loss: 1.8019e-05 - accuracy: 1.0000 - val_loss: 0.0998 - val_accuracy: 0.9722\n",
      "Epoch 54/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1149/1149 [==============================] - 0s 53us/sample - loss: 1.7339e-05 - accuracy: 1.0000 - val_loss: 0.0994 - val_accuracy: 0.9722\n",
      "Epoch 55/3000\n",
      "1149/1149 [==============================] - 0s 62us/sample - loss: 1.6842e-05 - accuracy: 1.0000 - val_loss: 0.0995 - val_accuracy: 0.9722\n",
      "Epoch 56/3000\n",
      "1149/1149 [==============================] - 0s 63us/sample - loss: 1.6194e-05 - accuracy: 1.0000 - val_loss: 0.1001 - val_accuracy: 0.9722\n",
      "Epoch 57/3000\n",
      "1149/1149 [==============================] - 0s 60us/sample - loss: 1.5531e-05 - accuracy: 1.0000 - val_loss: 0.0992 - val_accuracy: 0.9722\n",
      "Epoch 58/3000\n",
      "1149/1149 [==============================] - 0s 54us/sample - loss: 1.4944e-05 - accuracy: 1.0000 - val_loss: 0.0989 - val_accuracy: 0.9722\n",
      "Epoch 59/3000\n",
      "1149/1149 [==============================] - 0s 61us/sample - loss: 1.4427e-05 - accuracy: 1.0000 - val_loss: 0.0995 - val_accuracy: 0.9722\n",
      "Epoch 60/3000\n",
      "1149/1149 [==============================] - 0s 55us/sample - loss: 1.3832e-05 - accuracy: 1.0000 - val_loss: 0.0996 - val_accuracy: 0.9722\n",
      "Epoch 61/3000\n",
      "1149/1149 [==============================] - 0s 64us/sample - loss: 1.3218e-05 - accuracy: 1.0000 - val_loss: 0.1008 - val_accuracy: 0.9722\n",
      "Epoch 62/3000\n",
      "1149/1149 [==============================] - 0s 64us/sample - loss: 1.2819e-05 - accuracy: 1.0000 - val_loss: 0.1006 - val_accuracy: 0.9722\n",
      "Epoch 63/3000\n",
      "1149/1149 [==============================] - 0s 63us/sample - loss: 1.2397e-05 - accuracy: 1.0000 - val_loss: 0.1012 - val_accuracy: 0.9722\n",
      "Epoch 64/3000\n",
      "1149/1149 [==============================] - 0s 63us/sample - loss: 1.1845e-05 - accuracy: 1.0000 - val_loss: 0.1021 - val_accuracy: 0.9722\n",
      "Epoch 65/3000\n",
      "1149/1149 [==============================] - 0s 56us/sample - loss: 1.1433e-05 - accuracy: 1.0000 - val_loss: 0.1023 - val_accuracy: 0.9722\n",
      "Epoch 66/3000\n",
      "1149/1149 [==============================] - 0s 49us/sample - loss: 1.0958e-05 - accuracy: 1.0000 - val_loss: 0.1028 - val_accuracy: 0.9722\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=3000, batch_size=25, validation_split=0.2, callbacks=[earlystopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360/360 [==============================] - 0s 30us/sample - loss: 0.0738 - accuracy: 0.9944\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.99444443"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_vloss =history.history['val_loss']\n",
    "y_acc = history.history['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_len = np.arange(len(y_acc))\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.ylim(0.0, 1.1)\n",
    "plt.plot(x_len, y_vloss, '-', color='red', markersize=2)\n",
    "plt.plot(x_len, y_acc, '-', color='blue', markersize=2)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
