{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris, fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_data = iris.data\n",
    "iris_label = iris.target\n",
    "iris_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_full, x_test, y_train_full, y_test = train_test_split(iris_data, iris_label, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((101, 4), (15, 4), (34, 4))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train_full, y_train_full)\n",
    "x_train.shape, x_test.shape, x_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_std = StandardScaler().fit_transform(x_train)\n",
    "x_test_std = StandardScaler().fit_transform(x_test)\n",
    "x_valid_std = StandardScaler().fit_transform(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(24, input_shape=(4, ), activation='relu'),\n",
    "    keras.layers.Dense(8, activation='relu'),\n",
    "    keras.layers.Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = keras.losses.sparse_categorical_crossentropy,\n",
    "             optimizer = keras.optimizers.Adam(lr=0.1),\n",
    "             metrics = [keras.metrics.sparse_categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 101 samples, validate on 34 samples\n",
      "Epoch 1/30\n",
      "101/101 [==============================] - 0s 3ms/sample - loss: 2.1431 - sparse_categorical_accuracy: 0.3564 - val_loss: 1.1459 - val_sparse_categorical_accuracy: 0.3235\n",
      "Epoch 2/30\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 1.1111 - sparse_categorical_accuracy: 0.3465 - val_loss: 1.0633 - val_sparse_categorical_accuracy: 0.5588\n",
      "Epoch 3/30\n",
      "101/101 [==============================] - 0s 118us/sample - loss: 1.0387 - sparse_categorical_accuracy: 0.5050 - val_loss: 1.0980 - val_sparse_categorical_accuracy: 0.2353\n",
      "Epoch 4/30\n",
      "101/101 [==============================] - 0s 104us/sample - loss: 0.9792 - sparse_categorical_accuracy: 0.3960 - val_loss: 0.9311 - val_sparse_categorical_accuracy: 0.5588\n",
      "Epoch 5/30\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 0.6771 - sparse_categorical_accuracy: 0.6931 - val_loss: 0.7343 - val_sparse_categorical_accuracy: 0.5588\n",
      "Epoch 6/30\n",
      "101/101 [==============================] - 0s 114us/sample - loss: 0.5424 - sparse_categorical_accuracy: 0.6931 - val_loss: 0.5470 - val_sparse_categorical_accuracy: 0.7353\n",
      "Epoch 7/30\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 0.3902 - sparse_categorical_accuracy: 0.7426 - val_loss: 0.4414 - val_sparse_categorical_accuracy: 0.8529\n",
      "Epoch 8/30\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 0.3439 - sparse_categorical_accuracy: 0.9406 - val_loss: 0.3671 - val_sparse_categorical_accuracy: 0.9412\n",
      "Epoch 9/30\n",
      "101/101 [==============================] - 0s 98us/sample - loss: 0.2917 - sparse_categorical_accuracy: 0.9604 - val_loss: 0.3026 - val_sparse_categorical_accuracy: 0.9706\n",
      "Epoch 10/30\n",
      "101/101 [==============================] - 0s 119us/sample - loss: 0.2601 - sparse_categorical_accuracy: 0.9505 - val_loss: 0.2744 - val_sparse_categorical_accuracy: 0.9412\n",
      "Epoch 11/30\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 0.1981 - sparse_categorical_accuracy: 0.9703 - val_loss: 0.2320 - val_sparse_categorical_accuracy: 0.9706\n",
      "Epoch 12/30\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 0.1830 - sparse_categorical_accuracy: 0.9604 - val_loss: 0.4060 - val_sparse_categorical_accuracy: 0.8235\n",
      "Epoch 13/30\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 0.2554 - sparse_categorical_accuracy: 0.8515 - val_loss: 0.4180 - val_sparse_categorical_accuracy: 0.7941\n",
      "Epoch 14/30\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 0.4073 - sparse_categorical_accuracy: 0.8119 - val_loss: 0.4550 - val_sparse_categorical_accuracy: 0.8235\n",
      "Epoch 15/30\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 0.3263 - sparse_categorical_accuracy: 0.8218 - val_loss: 0.2166 - val_sparse_categorical_accuracy: 0.9118\n",
      "Epoch 16/30\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 0.2614 - sparse_categorical_accuracy: 0.8515 - val_loss: 0.1744 - val_sparse_categorical_accuracy: 0.9412\n",
      "Epoch 17/30\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 0.2355 - sparse_categorical_accuracy: 0.8515 - val_loss: 0.2252 - val_sparse_categorical_accuracy: 0.9412\n",
      "Epoch 18/30\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 0.1914 - sparse_categorical_accuracy: 0.9604 - val_loss: 0.2464 - val_sparse_categorical_accuracy: 0.9118\n",
      "Epoch 19/30\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 0.1724 - sparse_categorical_accuracy: 0.9604 - val_loss: 0.1757 - val_sparse_categorical_accuracy: 0.9412\n",
      "Epoch 20/30\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 0.1418 - sparse_categorical_accuracy: 0.9703 - val_loss: 0.1053 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 0.1864 - sparse_categorical_accuracy: 0.9307 - val_loss: 0.1259 - val_sparse_categorical_accuracy: 0.9412\n",
      "Epoch 22/30\n",
      "101/101 [==============================] - 0s 105us/sample - loss: 0.1248 - sparse_categorical_accuracy: 0.9703 - val_loss: 0.1247 - val_sparse_categorical_accuracy: 0.9412\n",
      "Epoch 23/30\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 0.2345 - sparse_categorical_accuracy: 0.9010 - val_loss: 0.0922 - val_sparse_categorical_accuracy: 0.9706\n",
      "Epoch 24/30\n",
      "101/101 [==============================] - 0s 98us/sample - loss: 0.0777 - sparse_categorical_accuracy: 0.9802 - val_loss: 0.1157 - val_sparse_categorical_accuracy: 0.9412\n",
      "Epoch 25/30\n",
      "101/101 [==============================] - 0s 103us/sample - loss: 0.0870 - sparse_categorical_accuracy: 0.9802 - val_loss: 0.0906 - val_sparse_categorical_accuracy: 0.9706\n",
      "Epoch 26/30\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 0.0848 - sparse_categorical_accuracy: 0.9802 - val_loss: 0.0943 - val_sparse_categorical_accuracy: 0.9706\n",
      "Epoch 27/30\n",
      "101/101 [==============================] - 0s 98us/sample - loss: 0.0930 - sparse_categorical_accuracy: 0.9802 - val_loss: 0.0885 - val_sparse_categorical_accuracy: 0.9706\n",
      "Epoch 28/30\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 0.0867 - sparse_categorical_accuracy: 0.9703 - val_loss: 0.0839 - val_sparse_categorical_accuracy: 0.9706\n",
      "Epoch 29/30\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 0.0668 - sparse_categorical_accuracy: 0.9901 - val_loss: 0.1578 - val_sparse_categorical_accuracy: 0.9412\n",
      "Epoch 30/30\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 0.1124 - sparse_categorical_accuracy: 0.9703 - val_loss: 0.0782 - val_sparse_categorical_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs = 30, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 - 0s - loss: 0.0770 - sparse_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, verbose=2)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8415842"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(history.history['sparse_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, 1, 2, 2, 2, 0, 2, 2, 1, 0, 1, 2, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.  , 0.  , 0.  ],\n",
       "       [1.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 1.  ],\n",
       "       [0.01, 0.95, 0.03],\n",
       "       [0.  , 0.01, 0.99],\n",
       "       [0.  , 0.12, 0.88],\n",
       "       [0.  , 0.  , 1.  ],\n",
       "       [1.  , 0.  , 0.  ],\n",
       "       [0.  , 0.06, 0.94],\n",
       "       [0.  , 0.28, 0.72],\n",
       "       [0.02, 0.96, 0.03],\n",
       "       [1.  , 0.  , 0.  ],\n",
       "       [0.02, 0.96, 0.01],\n",
       "       [0.  , 0.01, 0.99],\n",
       "       [0.  , 0.62, 0.38]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_full, x_test, y_train_full, y_test = train_test_split(housing.data, housing.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_valid = scaler.transform(x_valid)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_valid.shape\n",
    "x_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=x_train.shape[1:]),\n",
    "    keras.layers.Dense(300, activation='elu', kernel_initializer='he_normal')\n",
    "    ,\n",
    "    keras.layers.Dense(100, activation='elu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = keras.losses.mean_squared_error,\n",
    "             optimizer = keras.optimizers.Adam(lr=0.001),\n",
    "             metrics = [keras.metrics.mean_squared_error])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "11610/11610 [==============================] - 1s 59us/sample - loss: 1.0282 - mean_squared_error: 1.0282 - val_loss: 0.9402 - val_mean_squared_error: 0.9402\n",
      "Epoch 2/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 6.6405 - mean_squared_error: 6.6405 - val_loss: 1.0155 - val_mean_squared_error: 1.0155\n",
      "Epoch 3/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 2.9825 - mean_squared_error: 2.9825 - val_loss: 1.5097 - val_mean_squared_error: 1.5097\n",
      "Epoch 4/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 6.9337 - mean_squared_error: 6.9337 - val_loss: 2.4444 - val_mean_squared_error: 2.4444\n",
      "Epoch 5/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 8.2034 - mean_squared_error: 8.2034 - val_loss: 3.3330 - val_mean_squared_error: 3.3330\n",
      "Epoch 6/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 23.3216 - mean_squared_error: 23.3216 - val_loss: 0.4654 - val_mean_squared_error: 0.4654\n",
      "Epoch 7/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.9344 - mean_squared_error: 0.9344 - val_loss: 0.6321 - val_mean_squared_error: 0.6321\n",
      "Epoch 8/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 2.4570 - mean_squared_error: 2.4570 - val_loss: 0.3534 - val_mean_squared_error: 0.3534\n",
      "Epoch 9/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.6071 - mean_squared_error: 0.6071 - val_loss: 0.6145 - val_mean_squared_error: 0.6145\n",
      "Epoch 10/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.6493 - mean_squared_error: 0.6493 - val_loss: 0.3544 - val_mean_squared_error: 0.3544\n",
      "Epoch 11/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.4100 - mean_squared_error: 0.4100 - val_loss: 0.3921 - val_mean_squared_error: 0.3921\n",
      "Epoch 12/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3436 - mean_squared_error: 0.3436 - val_loss: 0.3572 - val_mean_squared_error: 0.3572\n",
      "Epoch 13/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 1.5005 - mean_squared_error: 1.5005 - val_loss: 0.3809 - val_mean_squared_error: 0.3809\n",
      "Epoch 14/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 1.3386 - mean_squared_error: 1.3386 - val_loss: 0.3870 - val_mean_squared_error: 0.3870\n",
      "Epoch 15/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.5639 - mean_squared_error: 0.5639 - val_loss: 0.6163 - val_mean_squared_error: 0.6163\n",
      "Epoch 16/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 1.6931 - mean_squared_error: 1.6931 - val_loss: 1.3003 - val_mean_squared_error: 1.3003\n",
      "Epoch 17/100\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 13.5628 - mean_squared_error: 13.5628 - val_loss: 0.3611 - val_mean_squared_error: 0.3611\n",
      "Epoch 18/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 1.5856 - mean_squared_error: 1.5856 - val_loss: 0.3866 - val_mean_squared_error: 0.3866\n",
      "Epoch 19/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3509 - mean_squared_error: 0.3509 - val_loss: 0.3429 - val_mean_squared_error: 0.3429\n",
      "Epoch 20/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3106 - mean_squared_error: 0.3106 - val_loss: 0.3851 - val_mean_squared_error: 0.3851\n",
      "Epoch 21/100\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4281 - mean_squared_error: 0.4281 - val_loss: 0.3256 - val_mean_squared_error: 0.3256\n",
      "Epoch 22/100\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3409 - mean_squared_error: 0.3409 - val_loss: 0.3446 - val_mean_squared_error: 0.3446\n",
      "Epoch 23/100\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 1.6391 - mean_squared_error: 1.6391 - val_loss: 0.3515 - val_mean_squared_error: 0.3515\n",
      "Epoch 24/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3813 - mean_squared_error: 0.3813 - val_loss: 0.4018 - val_mean_squared_error: 0.4018\n",
      "Epoch 25/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.5857 - mean_squared_error: 0.5857 - val_loss: 0.5416 - val_mean_squared_error: 0.5416\n",
      "Epoch 26/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.8177 - mean_squared_error: 0.8177 - val_loss: 0.3257 - val_mean_squared_error: 0.3257\n",
      "Epoch 27/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3235 - mean_squared_error: 0.3235 - val_loss: 0.3420 - val_mean_squared_error: 0.3420\n",
      "Epoch 28/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.5913 - mean_squared_error: 0.5913 - val_loss: 0.4976 - val_mean_squared_error: 0.4976\n",
      "Epoch 29/100\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 4.1964 - mean_squared_error: 4.1964 - val_loss: 0.3600 - val_mean_squared_error: 0.3600\n",
      "Epoch 30/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.7228 - mean_squared_error: 0.7228 - val_loss: 0.4429 - val_mean_squared_error: 0.4429\n",
      "Epoch 31/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.5646 - mean_squared_error: 0.5646 - val_loss: 0.3221 - val_mean_squared_error: 0.3221\n",
      "Epoch 32/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3146 - mean_squared_error: 0.3146 - val_loss: 0.3235 - val_mean_squared_error: 0.3235\n",
      "Epoch 33/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3006 - mean_squared_error: 0.3006 - val_loss: 0.3337 - val_mean_squared_error: 0.3337\n",
      "Epoch 34/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.2920 - mean_squared_error: 0.2920 - val_loss: 0.3289 - val_mean_squared_error: 0.3289\n",
      "Epoch 35/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3275 - mean_squared_error: 0.3275 - val_loss: 0.3153 - val_mean_squared_error: 0.3153\n",
      "Epoch 36/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3349 - mean_squared_error: 0.3349 - val_loss: 0.3306 - val_mean_squared_error: 0.3306\n",
      "Epoch 37/100\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 1.1241 - mean_squared_error: 1.1241 - val_loss: 0.3176 - val_mean_squared_error: 0.3176\n",
      "Epoch 38/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3735 - mean_squared_error: 0.3735 - val_loss: 0.3342 - val_mean_squared_error: 0.3342\n",
      "Epoch 39/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.7987 - mean_squared_error: 0.7987 - val_loss: 0.3062 - val_mean_squared_error: 0.3062\n",
      "Epoch 40/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3543 - mean_squared_error: 0.3543 - val_loss: 0.3303 - val_mean_squared_error: 0.3303\n",
      "Epoch 41/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3727 - mean_squared_error: 0.3727 - val_loss: 0.3004 - val_mean_squared_error: 0.3004\n",
      "Epoch 42/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.2934 - mean_squared_error: 0.2934 - val_loss: 0.3019 - val_mean_squared_error: 0.3019\n",
      "Epoch 43/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.2868 - mean_squared_error: 0.2868 - val_loss: 0.3093 - val_mean_squared_error: 0.3093\n",
      "Epoch 44/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3192 - mean_squared_error: 0.3192 - val_loss: 0.3504 - val_mean_squared_error: 0.3504\n",
      "Epoch 45/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3677 - mean_squared_error: 0.3677 - val_loss: 0.3275 - val_mean_squared_error: 0.3275\n",
      "Epoch 46/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3526 - mean_squared_error: 0.3526 - val_loss: 0.3034 - val_mean_squared_error: 0.3034\n",
      "Epoch 47/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.6033 - mean_squared_error: 0.6033 - val_loss: 0.3218 - val_mean_squared_error: 0.3218\n",
      "Epoch 48/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3536 - mean_squared_error: 0.3536 - val_loss: 0.3106 - val_mean_squared_error: 0.3106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4530 - mean_squared_error: 0.4530 - val_loss: 0.3076 - val_mean_squared_error: 0.3076\n",
      "Epoch 50/100\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.3578 - mean_squared_error: 0.3578 - val_loss: 0.3128 - val_mean_squared_error: 0.3128\n",
      "Epoch 51/100\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3018 - mean_squared_error: 0.3018 - val_loss: 0.3095 - val_mean_squared_error: 0.3095\n",
      "Epoch 52/100\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.2824 - mean_squared_error: 0.2824 - val_loss: 0.3047 - val_mean_squared_error: 0.3047\n",
      "Epoch 53/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.2803 - mean_squared_error: 0.2803 - val_loss: 0.3025 - val_mean_squared_error: 0.3025\n",
      "Epoch 54/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.2776 - mean_squared_error: 0.2776 - val_loss: 0.3085 - val_mean_squared_error: 0.3085\n",
      "Epoch 55/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.2717 - mean_squared_error: 0.2717 - val_loss: 0.2978 - val_mean_squared_error: 0.2978\n",
      "Epoch 56/100\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.2729 - mean_squared_error: 0.2729 - val_loss: 0.2923 - val_mean_squared_error: 0.2923\n",
      "Epoch 57/100\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.2781 - mean_squared_error: 0.2781 - val_loss: 0.3004 - val_mean_squared_error: 0.3004\n",
      "Epoch 58/100\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.2840 - mean_squared_error: 0.2840 - val_loss: 0.2966 - val_mean_squared_error: 0.2966\n",
      "Epoch 59/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.2814 - mean_squared_error: 0.2814 - val_loss: 0.3285 - val_mean_squared_error: 0.3285\n",
      "Epoch 60/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.2871 - mean_squared_error: 0.2871 - val_loss: 0.3075 - val_mean_squared_error: 0.3075\n",
      "Epoch 61/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.2966 - mean_squared_error: 0.2966 - val_loss: 0.2961 - val_mean_squared_error: 0.2961\n",
      "Epoch 62/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.2918 - mean_squared_error: 0.2918 - val_loss: 0.3081 - val_mean_squared_error: 0.3081\n",
      "Epoch 63/100\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.2683 - mean_squared_error: 0.2683 - val_loss: 0.3041 - val_mean_squared_error: 0.3041\n",
      "Epoch 64/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.2650 - mean_squared_error: 0.2650 - val_loss: 0.2983 - val_mean_squared_error: 0.2983\n",
      "Epoch 65/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.2697 - mean_squared_error: 0.2697 - val_loss: 0.2975 - val_mean_squared_error: 0.2975\n",
      "Epoch 66/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.2654 - mean_squared_error: 0.2654 - val_loss: 0.2939 - val_mean_squared_error: 0.2939\n",
      "Epoch 67/100\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.2600 - mean_squared_error: 0.2600 - val_loss: 0.2976 - val_mean_squared_error: 0.2976\n",
      "Epoch 68/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.2613 - mean_squared_error: 0.2613 - val_loss: 0.2969 - val_mean_squared_error: 0.2969\n",
      "Epoch 69/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.2603 - mean_squared_error: 0.2603 - val_loss: 0.3266 - val_mean_squared_error: 0.3266\n",
      "Epoch 70/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.2598 - mean_squared_error: 0.2598 - val_loss: 0.3049 - val_mean_squared_error: 0.3049\n",
      "Epoch 71/100\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.2579 - mean_squared_error: 0.2579 - val_loss: 0.3006 - val_mean_squared_error: 0.3006\n",
      "Epoch 72/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.2603 - mean_squared_error: 0.2603 - val_loss: 0.3153 - val_mean_squared_error: 0.3153\n",
      "Epoch 73/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.2565 - mean_squared_error: 0.2565 - val_loss: 0.2903 - val_mean_squared_error: 0.2903\n",
      "Epoch 74/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.2572 - mean_squared_error: 0.2572 - val_loss: 0.2938 - val_mean_squared_error: 0.2938\n",
      "Epoch 75/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.2583 - mean_squared_error: 0.2583 - val_loss: 0.2909 - val_mean_squared_error: 0.2909\n",
      "Epoch 76/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.2591 - mean_squared_error: 0.2591 - val_loss: 0.2873 - val_mean_squared_error: 0.2873\n",
      "Epoch 77/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.2546 - mean_squared_error: 0.2546 - val_loss: 0.2857 - val_mean_squared_error: 0.2857\n",
      "Epoch 78/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.2540 - mean_squared_error: 0.2540 - val_loss: 0.2909 - val_mean_squared_error: 0.2909\n",
      "Epoch 79/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.2525 - mean_squared_error: 0.2525 - val_loss: 0.2998 - val_mean_squared_error: 0.2998\n",
      "Epoch 80/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.2517 - mean_squared_error: 0.2517 - val_loss: 0.2970 - val_mean_squared_error: 0.2970\n",
      "Epoch 81/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.2483 - mean_squared_error: 0.2483 - val_loss: 0.3010 - val_mean_squared_error: 0.3010\n",
      "Epoch 82/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.2512 - mean_squared_error: 0.2512 - val_loss: 0.2903 - val_mean_squared_error: 0.2903\n",
      "Epoch 83/100\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.2515 - mean_squared_error: 0.2515 - val_loss: 0.3062 - val_mean_squared_error: 0.3062\n",
      "Epoch 84/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.2487 - mean_squared_error: 0.2487 - val_loss: 0.3016 - val_mean_squared_error: 0.3016\n",
      "Epoch 85/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.2460 - mean_squared_error: 0.2460 - val_loss: 0.3189 - val_mean_squared_error: 0.3189\n",
      "Epoch 86/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.2484 - mean_squared_error: 0.2484 - val_loss: 0.3108 - val_mean_squared_error: 0.3108\n",
      "Epoch 87/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.2516 - mean_squared_error: 0.2516 - val_loss: 0.2985 - val_mean_squared_error: 0.2985\n",
      "Epoch 88/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.2474 - mean_squared_error: 0.2474 - val_loss: 0.2883 - val_mean_squared_error: 0.2883\n",
      "Epoch 89/100\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.2485 - mean_squared_error: 0.2485 - val_loss: 0.2900 - val_mean_squared_error: 0.2900\n",
      "Epoch 90/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.2434 - mean_squared_error: 0.2434 - val_loss: 0.2939 - val_mean_squared_error: 0.2939\n",
      "Epoch 91/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.2429 - mean_squared_error: 0.2429 - val_loss: 0.2988 - val_mean_squared_error: 0.2988\n",
      "Epoch 92/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.2436 - mean_squared_error: 0.2436 - val_loss: 0.2936 - val_mean_squared_error: 0.2936\n",
      "Epoch 93/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.2416 - mean_squared_error: 0.2416 - val_loss: 0.2962 - val_mean_squared_error: 0.2962\n",
      "Epoch 94/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.2407 - mean_squared_error: 0.2407 - val_loss: 0.3034 - val_mean_squared_error: 0.3034\n",
      "Epoch 95/100\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.2428 - mean_squared_error: 0.2428 - val_loss: 0.2947 - val_mean_squared_error: 0.2947\n",
      "Epoch 96/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.2426 - mean_squared_error: 0.2426 - val_loss: 0.3018 - val_mean_squared_error: 0.3018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.2385 - mean_squared_error: 0.2385 - val_loss: 0.2914 - val_mean_squared_error: 0.2914\n",
      "Epoch 98/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.2395 - mean_squared_error: 0.2395 - val_loss: 0.2944 - val_mean_squared_error: 0.2944\n",
      "Epoch 99/100\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.2368 - mean_squared_error: 0.2368 - val_loss: 0.3151 - val_mean_squared_error: 0.3151\n",
      "Epoch 100/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.2349 - mean_squared_error: 0.2349 - val_loss: 0.2984 - val_mean_squared_error: 0.2984\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=100, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 - 0s - loss: 0.3063 - mean_squared_error: 0.3063\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3063493803374527, 0.30634937]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new = x_test[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.59734788, -1.48477161,  0.10979906, -0.14955127,  0.37476284,\n",
       "        -0.03764575, -0.63813809,  0.45515502],\n",
       "       [ 2.79715446, -0.29129361,  0.16122114, -0.31663213, -1.00571187,\n",
       "        -0.00476541,  0.98293457, -1.09361542],\n",
       "       [-0.54976781, -0.76868481, -0.44164838, -0.25005976,  0.30853445,\n",
       "        -0.08106309,  1.26323532, -1.55824655]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.7 ],\n",
       "       [3.9 ],\n",
       "       [1.66]], dtype=float32)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
