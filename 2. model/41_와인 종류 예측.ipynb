{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using plaidml.keras.backend backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2020\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../dataset/wine.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2    3      4     5     6       7     8     9    10  11  12\n",
       "0   7.4  0.70  0.00  1.9  0.076  11.0  34.0  0.9978  3.51  0.56  9.4   5   1\n",
       "1   7.8  0.88  0.00  2.6  0.098  25.0  67.0  0.9968  3.20  0.68  9.8   5   1\n",
       "2   7.8  0.76  0.04  2.3  0.092  15.0  54.0  0.9970  3.26  0.65  9.8   5   1\n",
       "3  11.2  0.28  0.56  1.9  0.075  17.0  60.0  0.9980  3.16  0.58  9.8   6   1\n",
       "4   7.4  0.70  0.00  1.9  0.076  11.0  34.0  0.9978  3.51  0.56  9.4   5   1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pre = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>9.8</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.39</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.079</td>\n",
       "      <td>28.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.99729</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.59</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2948</th>\n",
       "      <td>9.2</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.042</td>\n",
       "      <td>15.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.99240</td>\n",
       "      <td>2.96</td>\n",
       "      <td>0.28</td>\n",
       "      <td>10.4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.07</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.090</td>\n",
       "      <td>11.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.99790</td>\n",
       "      <td>3.43</td>\n",
       "      <td>0.76</td>\n",
       "      <td>9.7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4610</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.36</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.029</td>\n",
       "      <td>30.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.99206</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.47</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5415</th>\n",
       "      <td>6.8</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.30</td>\n",
       "      <td>8.8</td>\n",
       "      <td>0.045</td>\n",
       "      <td>28.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.99530</td>\n",
       "      <td>3.12</td>\n",
       "      <td>0.59</td>\n",
       "      <td>9.9</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1     2    3      4     5      6        7     8     9     10  11  \\\n",
       "1241  9.8  0.37  0.39  2.5  0.079  28.0   65.0  0.99729  3.16  0.59   9.8   5   \n",
       "2948  9.2  0.35  0.39  0.9  0.042  15.0   61.0  0.99240  2.96  0.28  10.4   4   \n",
       "385   7.4  0.63  0.07  2.4  0.090  11.0   37.0  0.99790  3.43  0.76   9.7   6   \n",
       "4610  6.6  0.22  0.36  5.5  0.029  30.0  105.0  0.99206  3.20  0.47  11.8   6   \n",
       "5415  6.8  0.41  0.30  8.8  0.045  28.0  131.0  0.99530  3.12  0.59   9.9   5   \n",
       "\n",
       "      12  \n",
       "1241   1  \n",
       "2948   0  \n",
       "385    1  \n",
       "4610   0  \n",
       "5415   0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pre.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(df.iloc[:, :-1]).astype(np.float32)\n",
    "y = np.array(df.iloc[:, -1]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6497, 12)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold =5\n",
    "skf = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4157 samples, validate on 1040 samples\n",
      "Epoch 1/100\n",
      "4157/4157 [==============================] - 1s 294us/sample - loss: 0.3347 - accuracy: 0.9009 - val_loss: 0.0727 - val_accuracy: 0.9865\n",
      "Epoch 2/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.1992 - accuracy: 0.9310 - val_loss: 0.1048 - val_accuracy: 0.9683\n",
      "Epoch 3/100\n",
      "4157/4157 [==============================] - 0s 110us/sample - loss: 0.1638 - accuracy: 0.9435 - val_loss: 0.1184 - val_accuracy: 0.9692\n",
      "Epoch 4/100\n",
      "4157/4157 [==============================] - 0s 107us/sample - loss: 0.1417 - accuracy: 0.9507 - val_loss: 0.0834 - val_accuracy: 0.9798\n",
      "Epoch 5/100\n",
      "4157/4157 [==============================] - 0s 109us/sample - loss: 0.1294 - accuracy: 0.9529 - val_loss: 0.1438 - val_accuracy: 0.9606\n",
      "Epoch 6/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.1187 - accuracy: 0.9601 - val_loss: 0.0181 - val_accuracy: 0.9962\n",
      "Epoch 7/100\n",
      "4157/4157 [==============================] - 0s 114us/sample - loss: 0.1104 - accuracy: 0.9627 - val_loss: 0.0723 - val_accuracy: 0.9798\n",
      "Epoch 8/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.1008 - accuracy: 0.9649 - val_loss: 0.0378 - val_accuracy: 0.9885\n",
      "Epoch 9/100\n",
      "4157/4157 [==============================] - 0s 106us/sample - loss: 0.0977 - accuracy: 0.9673 - val_loss: 0.0288 - val_accuracy: 0.9923\n",
      "Epoch 10/100\n",
      "4157/4157 [==============================] - 0s 106us/sample - loss: 0.0970 - accuracy: 0.9699 - val_loss: 0.0256 - val_accuracy: 0.9933\n",
      "Epoch 11/100\n",
      "4157/4157 [==============================] - 0s 104us/sample - loss: 0.0917 - accuracy: 0.9731 - val_loss: 0.0567 - val_accuracy: 0.9846\n",
      "Epoch 12/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0845 - accuracy: 0.9719 - val_loss: 0.0420 - val_accuracy: 0.9865\n",
      "Epoch 13/100\n",
      "4157/4157 [==============================] - 0s 104us/sample - loss: 0.0833 - accuracy: 0.9719 - val_loss: 0.0205 - val_accuracy: 0.9942\n",
      "Epoch 14/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0817 - accuracy: 0.9735 - val_loss: 0.0879 - val_accuracy: 0.9702\n",
      "Epoch 15/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0819 - accuracy: 0.9726 - val_loss: 0.0472 - val_accuracy: 0.9856\n",
      "Epoch 16/100\n",
      "4157/4157 [==============================] - 0s 109us/sample - loss: 0.0826 - accuracy: 0.9740 - val_loss: 0.0354 - val_accuracy: 0.9904\n",
      "Epoch 17/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0800 - accuracy: 0.9759 - val_loss: 0.0574 - val_accuracy: 0.9846\n",
      "Epoch 18/100\n",
      "4157/4157 [==============================] - 0s 106us/sample - loss: 0.0754 - accuracy: 0.9750 - val_loss: 0.0166 - val_accuracy: 0.9952\n",
      "Epoch 19/100\n",
      "4157/4157 [==============================] - 0s 106us/sample - loss: 0.0752 - accuracy: 0.9783 - val_loss: 0.0429 - val_accuracy: 0.9875\n",
      "Epoch 20/100\n",
      "4157/4157 [==============================] - 0s 106us/sample - loss: 0.0716 - accuracy: 0.9783 - val_loss: 0.0351 - val_accuracy: 0.9913\n",
      "Epoch 21/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0723 - accuracy: 0.9786 - val_loss: 0.0137 - val_accuracy: 0.9971\n",
      "Epoch 22/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0725 - accuracy: 0.9779 - val_loss: 0.0426 - val_accuracy: 0.9885\n",
      "Epoch 23/100\n",
      "4157/4157 [==============================] - 0s 107us/sample - loss: 0.0725 - accuracy: 0.9800 - val_loss: 0.0367 - val_accuracy: 0.9885\n",
      "Epoch 24/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0700 - accuracy: 0.9800 - val_loss: 0.0442 - val_accuracy: 0.9875\n",
      "Epoch 25/100\n",
      "4157/4157 [==============================] - 0s 109us/sample - loss: 0.0656 - accuracy: 0.9817 - val_loss: 0.0533 - val_accuracy: 0.9856\n",
      "Epoch 26/100\n",
      "4157/4157 [==============================] - 0s 115us/sample - loss: 0.0686 - accuracy: 0.9791 - val_loss: 0.2246 - val_accuracy: 0.9106\n",
      "Epoch 27/100\n",
      "4157/4157 [==============================] - 0s 106us/sample - loss: 0.0694 - accuracy: 0.9810 - val_loss: 0.0211 - val_accuracy: 0.9952\n",
      "Epoch 28/100\n",
      "4157/4157 [==============================] - 0s 109us/sample - loss: 0.0711 - accuracy: 0.9791 - val_loss: 0.0305 - val_accuracy: 0.9923\n",
      "Epoch 29/100\n",
      "4157/4157 [==============================] - 0s 108us/sample - loss: 0.0700 - accuracy: 0.9805 - val_loss: 0.0598 - val_accuracy: 0.9856\n",
      "Epoch 30/100\n",
      "4157/4157 [==============================] - 0s 111us/sample - loss: 0.0696 - accuracy: 0.9805 - val_loss: 0.0392 - val_accuracy: 0.9885\n",
      "Epoch 31/100\n",
      "4157/4157 [==============================] - 0s 108us/sample - loss: 0.0668 - accuracy: 0.9779 - val_loss: 0.0406 - val_accuracy: 0.9885\n",
      "Epoch 32/100\n",
      "4157/4157 [==============================] - 0s 107us/sample - loss: 0.0608 - accuracy: 0.9824 - val_loss: 0.0366 - val_accuracy: 0.9913\n",
      "Epoch 33/100\n",
      "4157/4157 [==============================] - 0s 108us/sample - loss: 0.0644 - accuracy: 0.9800 - val_loss: 0.0509 - val_accuracy: 0.9875\n",
      "Epoch 34/100\n",
      "4157/4157 [==============================] - 0s 109us/sample - loss: 0.0678 - accuracy: 0.9822 - val_loss: 0.0455 - val_accuracy: 0.9875\n",
      "Epoch 35/100\n",
      "4157/4157 [==============================] - 0s 106us/sample - loss: 0.0636 - accuracy: 0.9808 - val_loss: 0.0204 - val_accuracy: 0.9962\n",
      "Epoch 36/100\n",
      "4157/4157 [==============================] - 0s 111us/sample - loss: 0.0671 - accuracy: 0.9808 - val_loss: 0.0397 - val_accuracy: 0.9885\n",
      "Epoch 37/100\n",
      "4157/4157 [==============================] - 0s 107us/sample - loss: 0.0657 - accuracy: 0.9808 - val_loss: 0.0394 - val_accuracy: 0.9894\n",
      "Epoch 38/100\n",
      "4157/4157 [==============================] - 0s 106us/sample - loss: 0.0642 - accuracy: 0.9798 - val_loss: 0.0610 - val_accuracy: 0.9827\n",
      "Epoch 39/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0620 - accuracy: 0.9832 - val_loss: 0.0415 - val_accuracy: 0.9894\n",
      "Epoch 40/100\n",
      "4157/4157 [==============================] - 0s 106us/sample - loss: 0.0625 - accuracy: 0.9824 - val_loss: 0.0436 - val_accuracy: 0.9875\n",
      "Epoch 41/100\n",
      "4157/4157 [==============================] - 0s 110us/sample - loss: 0.0635 - accuracy: 0.9829 - val_loss: 0.0421 - val_accuracy: 0.9904\n",
      "Epoch 42/100\n",
      "4157/4157 [==============================] - 0s 104us/sample - loss: 0.0617 - accuracy: 0.9815 - val_loss: 0.0745 - val_accuracy: 0.9788\n",
      "Epoch 43/100\n",
      "4157/4157 [==============================] - 0s 107us/sample - loss: 0.0577 - accuracy: 0.9834 - val_loss: 0.0907 - val_accuracy: 0.9750\n",
      "Epoch 44/100\n",
      "4157/4157 [==============================] - 0s 107us/sample - loss: 0.0573 - accuracy: 0.9836 - val_loss: 0.0729 - val_accuracy: 0.9808\n",
      "Epoch 45/100\n",
      "4157/4157 [==============================] - 0s 106us/sample - loss: 0.0560 - accuracy: 0.9834 - val_loss: 0.0357 - val_accuracy: 0.9904\n",
      "Epoch 46/100\n",
      "4157/4157 [==============================] - 0s 107us/sample - loss: 0.0581 - accuracy: 0.9820 - val_loss: 0.0455 - val_accuracy: 0.9894\n",
      "Epoch 47/100\n",
      "4157/4157 [==============================] - 0s 106us/sample - loss: 0.0570 - accuracy: 0.9834 - val_loss: 0.0254 - val_accuracy: 0.9952\n",
      "Epoch 48/100\n",
      "4157/4157 [==============================] - 0s 106us/sample - loss: 0.0619 - accuracy: 0.9817 - val_loss: 0.0441 - val_accuracy: 0.9933\n",
      "Epoch 49/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0593 - accuracy: 0.9810 - val_loss: 0.0411 - val_accuracy: 0.9885\n",
      "Epoch 50/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0583 - accuracy: 0.9832 - val_loss: 0.0434 - val_accuracy: 0.9904\n",
      "Epoch 51/100\n",
      "4157/4157 [==============================] - 0s 106us/sample - loss: 0.0562 - accuracy: 0.9839 - val_loss: 0.0306 - val_accuracy: 0.9913\n",
      "Epoch 52/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0526 - accuracy: 0.9853 - val_loss: 0.0437 - val_accuracy: 0.9913\n",
      "Epoch 53/100\n",
      "4157/4157 [==============================] - 0s 104us/sample - loss: 0.0538 - accuracy: 0.9863 - val_loss: 0.0793 - val_accuracy: 0.9740\n",
      "Epoch 54/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0544 - accuracy: 0.9834 - val_loss: 0.0397 - val_accuracy: 0.9894\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4157/4157 [==============================] - 0s 110us/sample - loss: 0.0584 - accuracy: 0.9820 - val_loss: 0.1211 - val_accuracy: 0.9587\n",
      "Epoch 56/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0547 - accuracy: 0.9846 - val_loss: 0.0608 - val_accuracy: 0.9846\n",
      "Epoch 57/100\n",
      "4157/4157 [==============================] - 0s 106us/sample - loss: 0.0605 - accuracy: 0.9808 - val_loss: 0.0548 - val_accuracy: 0.9865\n",
      "Epoch 58/100\n",
      "4157/4157 [==============================] - 0s 106us/sample - loss: 0.0551 - accuracy: 0.9832 - val_loss: 0.0324 - val_accuracy: 0.9913\n",
      "Epoch 59/100\n",
      "4157/4157 [==============================] - 0s 104us/sample - loss: 0.0550 - accuracy: 0.9824 - val_loss: 0.0694 - val_accuracy: 0.9817\n",
      "Epoch 60/100\n",
      "4157/4157 [==============================] - 0s 107us/sample - loss: 0.0517 - accuracy: 0.9822 - val_loss: 0.0599 - val_accuracy: 0.9846\n",
      "Epoch 61/100\n",
      "4157/4157 [==============================] - 0s 104us/sample - loss: 0.0520 - accuracy: 0.9863 - val_loss: 0.0211 - val_accuracy: 0.9971\n",
      "Epoch 62/100\n",
      "4157/4157 [==============================] - 0s 103us/sample - loss: 0.0512 - accuracy: 0.9846 - val_loss: 0.0829 - val_accuracy: 0.9779\n",
      "Epoch 63/100\n",
      "4157/4157 [==============================] - 0s 106us/sample - loss: 0.0494 - accuracy: 0.9858 - val_loss: 0.0290 - val_accuracy: 0.9933\n",
      "Epoch 64/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0513 - accuracy: 0.9863 - val_loss: 0.0307 - val_accuracy: 0.9913\n",
      "Epoch 65/100\n",
      "4157/4157 [==============================] - 0s 106us/sample - loss: 0.0538 - accuracy: 0.9832 - val_loss: 0.0308 - val_accuracy: 0.9933\n",
      "Epoch 66/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0527 - accuracy: 0.9836 - val_loss: 0.0604 - val_accuracy: 0.9875\n",
      "Epoch 67/100\n",
      "4157/4157 [==============================] - 0s 104us/sample - loss: 0.0500 - accuracy: 0.9846 - val_loss: 0.0242 - val_accuracy: 0.9971\n",
      "Epoch 68/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0535 - accuracy: 0.9829 - val_loss: 0.0282 - val_accuracy: 0.9933\n",
      "Epoch 69/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0574 - accuracy: 0.9841 - val_loss: 0.0523 - val_accuracy: 0.9875\n",
      "Epoch 70/100\n",
      "4157/4157 [==============================] - 0s 107us/sample - loss: 0.0534 - accuracy: 0.9839 - val_loss: 0.0887 - val_accuracy: 0.9740\n",
      "Epoch 71/100\n",
      "4157/4157 [==============================] - 0s 111us/sample - loss: 0.0508 - accuracy: 0.9848 - val_loss: 0.0426 - val_accuracy: 0.9885\n",
      "Epoch 72/100\n",
      "4157/4157 [==============================] - 0s 106us/sample - loss: 0.0488 - accuracy: 0.9856 - val_loss: 0.0790 - val_accuracy: 0.9750\n",
      "Epoch 73/100\n",
      "4157/4157 [==============================] - 0s 104us/sample - loss: 0.0483 - accuracy: 0.9858 - val_loss: 0.0392 - val_accuracy: 0.9913\n",
      "Epoch 74/100\n",
      "4157/4157 [==============================] - 0s 106us/sample - loss: 0.0508 - accuracy: 0.9848 - val_loss: 0.0873 - val_accuracy: 0.9673\n",
      "Epoch 75/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0512 - accuracy: 0.9846 - val_loss: 0.0719 - val_accuracy: 0.9788\n",
      "Epoch 76/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0493 - accuracy: 0.9858 - val_loss: 0.0506 - val_accuracy: 0.9904\n",
      "Epoch 77/100\n",
      "4157/4157 [==============================] - 0s 111us/sample - loss: 0.0566 - accuracy: 0.9827 - val_loss: 0.0349 - val_accuracy: 0.9952\n",
      "Epoch 78/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0485 - accuracy: 0.9856 - val_loss: 0.0843 - val_accuracy: 0.9788\n",
      "Epoch 79/100\n",
      "4157/4157 [==============================] - 0s 108us/sample - loss: 0.0480 - accuracy: 0.9848 - val_loss: 0.0293 - val_accuracy: 0.9962\n",
      "Epoch 80/100\n",
      "4157/4157 [==============================] - 0s 106us/sample - loss: 0.0494 - accuracy: 0.9856 - val_loss: 0.0490 - val_accuracy: 0.9865\n",
      "Epoch 81/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0518 - accuracy: 0.9839 - val_loss: 0.0444 - val_accuracy: 0.9894\n",
      "Epoch 82/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0473 - accuracy: 0.9853 - val_loss: 0.0445 - val_accuracy: 0.9894\n",
      "Epoch 83/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0441 - accuracy: 0.9875 - val_loss: 0.0613 - val_accuracy: 0.9875\n",
      "Epoch 84/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0447 - accuracy: 0.9865 - val_loss: 0.0338 - val_accuracy: 0.9904\n",
      "Epoch 85/100\n",
      "4157/4157 [==============================] - 0s 106us/sample - loss: 0.0424 - accuracy: 0.9882 - val_loss: 0.0527 - val_accuracy: 0.9913\n",
      "Epoch 86/100\n",
      "4157/4157 [==============================] - 0s 107us/sample - loss: 0.0488 - accuracy: 0.9851 - val_loss: 0.0423 - val_accuracy: 0.9923\n",
      "Epoch 87/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0435 - accuracy: 0.9868 - val_loss: 0.0648 - val_accuracy: 0.9837\n",
      "Epoch 88/100\n",
      "4157/4157 [==============================] - 0s 104us/sample - loss: 0.0442 - accuracy: 0.9860 - val_loss: 0.0812 - val_accuracy: 0.9750\n",
      "Epoch 89/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0405 - accuracy: 0.9877 - val_loss: 0.0845 - val_accuracy: 0.9750\n",
      "Epoch 90/100\n",
      "4157/4157 [==============================] - 0s 106us/sample - loss: 0.0436 - accuracy: 0.9865 - val_loss: 0.0429 - val_accuracy: 0.9923\n",
      "Epoch 91/100\n",
      "4157/4157 [==============================] - 0s 106us/sample - loss: 0.0421 - accuracy: 0.9877 - val_loss: 0.0382 - val_accuracy: 0.9933\n",
      "Epoch 92/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0452 - accuracy: 0.9856 - val_loss: 0.0595 - val_accuracy: 0.9875\n",
      "Epoch 93/100\n",
      "4157/4157 [==============================] - 0s 106us/sample - loss: 0.0426 - accuracy: 0.9877 - val_loss: 0.0442 - val_accuracy: 0.9923\n",
      "Epoch 94/100\n",
      "4157/4157 [==============================] - 0s 106us/sample - loss: 0.0405 - accuracy: 0.9873 - val_loss: 0.0646 - val_accuracy: 0.9856\n",
      "Epoch 95/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0458 - accuracy: 0.9870 - val_loss: 0.0425 - val_accuracy: 0.9885\n",
      "Epoch 96/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0448 - accuracy: 0.9865 - val_loss: 0.0421 - val_accuracy: 0.9913\n",
      "Epoch 97/100\n",
      "4157/4157 [==============================] - 0s 106us/sample - loss: 0.0442 - accuracy: 0.9863 - val_loss: 0.0747 - val_accuracy: 0.9798\n",
      "Epoch 98/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0437 - accuracy: 0.9877 - val_loss: 0.0309 - val_accuracy: 0.9952\n",
      "Epoch 99/100\n",
      "4157/4157 [==============================] - 0s 104us/sample - loss: 0.0439 - accuracy: 0.9853 - val_loss: 0.0753 - val_accuracy: 0.9769\n",
      "Epoch 100/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0400 - accuracy: 0.9882 - val_loss: 0.0430 - val_accuracy: 0.9904\n",
      "1300/1300 - 0s - loss: 0.0631 - accuracy: 0.9885\n",
      "Train on 4157 samples, validate on 1040 samples\n",
      "Epoch 1/100\n",
      "4157/4157 [==============================] - 1s 254us/sample - loss: 0.2463 - accuracy: 0.9088 - val_loss: 0.1437 - val_accuracy: 0.9615\n",
      "Epoch 2/100\n",
      "4157/4157 [==============================] - 0s 107us/sample - loss: 0.1872 - accuracy: 0.9314 - val_loss: 0.0917 - val_accuracy: 0.9788\n",
      "Epoch 3/100\n",
      "4157/4157 [==============================] - 0s 110us/sample - loss: 0.1600 - accuracy: 0.9427 - val_loss: 0.0696 - val_accuracy: 0.9779\n",
      "Epoch 4/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.1365 - accuracy: 0.9480 - val_loss: 0.0722 - val_accuracy: 0.9779\n",
      "Epoch 5/100\n",
      "4157/4157 [==============================] - 0s 106us/sample - loss: 0.1253 - accuracy: 0.9548 - val_loss: 0.0490 - val_accuracy: 0.9837\n",
      "Epoch 6/100\n",
      "4157/4157 [==============================] - 0s 106us/sample - loss: 0.1141 - accuracy: 0.9634 - val_loss: 0.0348 - val_accuracy: 0.9894\n",
      "Epoch 7/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.1061 - accuracy: 0.9646 - val_loss: 0.0293 - val_accuracy: 0.9933\n",
      "Epoch 8/100\n",
      "4157/4157 [==============================] - 0s 106us/sample - loss: 0.0989 - accuracy: 0.9673 - val_loss: 0.0354 - val_accuracy: 0.9885\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4157/4157 [==============================] - 0s 106us/sample - loss: 0.0992 - accuracy: 0.9687 - val_loss: 0.0297 - val_accuracy: 0.9904\n",
      "Epoch 10/100\n",
      "4157/4157 [==============================] - 0s 107us/sample - loss: 0.0934 - accuracy: 0.9694 - val_loss: 0.0479 - val_accuracy: 0.9846\n",
      "Epoch 11/100\n",
      "4157/4157 [==============================] - 0s 104us/sample - loss: 0.0864 - accuracy: 0.9723 - val_loss: 0.0211 - val_accuracy: 0.9971\n",
      "Epoch 12/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0857 - accuracy: 0.9752 - val_loss: 0.0360 - val_accuracy: 0.9913\n",
      "Epoch 13/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0826 - accuracy: 0.9728 - val_loss: 0.0255 - val_accuracy: 0.9952\n",
      "Epoch 14/100\n",
      "4157/4157 [==============================] - 0s 104us/sample - loss: 0.0822 - accuracy: 0.9774 - val_loss: 0.0512 - val_accuracy: 0.9817\n",
      "Epoch 15/100\n",
      "4157/4157 [==============================] - 0s 106us/sample - loss: 0.0809 - accuracy: 0.9745 - val_loss: 0.0807 - val_accuracy: 0.9721\n",
      "Epoch 16/100\n",
      "4157/4157 [==============================] - 0s 106us/sample - loss: 0.0765 - accuracy: 0.9757 - val_loss: 0.0676 - val_accuracy: 0.9817\n",
      "Epoch 17/100\n",
      "4157/4157 [==============================] - 0s 109us/sample - loss: 0.0794 - accuracy: 0.9750 - val_loss: 0.0167 - val_accuracy: 0.9981\n",
      "Epoch 18/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0793 - accuracy: 0.9757 - val_loss: 0.0405 - val_accuracy: 0.9875\n",
      "Epoch 19/100\n",
      "4157/4157 [==============================] - 0s 101us/sample - loss: 0.0787 - accuracy: 0.9743 - val_loss: 0.0554 - val_accuracy: 0.9827\n",
      "Epoch 20/100\n",
      "4157/4157 [==============================] - 0s 106us/sample - loss: 0.0718 - accuracy: 0.9779 - val_loss: 0.1067 - val_accuracy: 0.9606\n",
      "Epoch 21/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0752 - accuracy: 0.9774 - val_loss: 0.0358 - val_accuracy: 0.9933\n",
      "Epoch 22/100\n",
      "4157/4157 [==============================] - 0s 104us/sample - loss: 0.0751 - accuracy: 0.9767 - val_loss: 0.0454 - val_accuracy: 0.9894\n",
      "Epoch 23/100\n",
      "4157/4157 [==============================] - 0s 106us/sample - loss: 0.0712 - accuracy: 0.9779 - val_loss: 0.0404 - val_accuracy: 0.9856\n",
      "Epoch 24/100\n",
      "4157/4157 [==============================] - 0s 106us/sample - loss: 0.0729 - accuracy: 0.9771 - val_loss: 0.0277 - val_accuracy: 0.9962\n",
      "Epoch 25/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0729 - accuracy: 0.9769 - val_loss: 0.0373 - val_accuracy: 0.9933\n",
      "Epoch 26/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0687 - accuracy: 0.9798 - val_loss: 0.0258 - val_accuracy: 0.9952\n",
      "Epoch 27/100\n",
      "4157/4157 [==============================] - 0s 107us/sample - loss: 0.0694 - accuracy: 0.9793 - val_loss: 0.0326 - val_accuracy: 0.9933\n",
      "Epoch 28/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0644 - accuracy: 0.9788 - val_loss: 0.0625 - val_accuracy: 0.9827\n",
      "Epoch 29/100\n",
      "4157/4157 [==============================] - 0s 106us/sample - loss: 0.0693 - accuracy: 0.9781 - val_loss: 0.0460 - val_accuracy: 0.9913\n",
      "Epoch 30/100\n",
      "4157/4157 [==============================] - 0s 106us/sample - loss: 0.0661 - accuracy: 0.9798 - val_loss: 0.0242 - val_accuracy: 0.9971\n",
      "Epoch 31/100\n",
      "4157/4157 [==============================] - 0s 107us/sample - loss: 0.0722 - accuracy: 0.9757 - val_loss: 0.0554 - val_accuracy: 0.9827\n",
      "Epoch 32/100\n",
      "4157/4157 [==============================] - 0s 108us/sample - loss: 0.0647 - accuracy: 0.9793 - val_loss: 0.0494 - val_accuracy: 0.9894\n",
      "Epoch 33/100\n",
      "4157/4157 [==============================] - 0s 111us/sample - loss: 0.0667 - accuracy: 0.9776 - val_loss: 0.0270 - val_accuracy: 0.9962\n",
      "Epoch 34/100\n",
      "4157/4157 [==============================] - 0s 108us/sample - loss: 0.0697 - accuracy: 0.9767 - val_loss: 0.0468 - val_accuracy: 0.9875\n",
      "Epoch 35/100\n",
      "4157/4157 [==============================] - 0s 109us/sample - loss: 0.0671 - accuracy: 0.9779 - val_loss: 0.0515 - val_accuracy: 0.9846\n",
      "Epoch 36/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0672 - accuracy: 0.9810 - val_loss: 0.0433 - val_accuracy: 0.9933\n",
      "Epoch 37/100\n",
      "4157/4157 [==============================] - 0s 108us/sample - loss: 0.0627 - accuracy: 0.9812 - val_loss: 0.0775 - val_accuracy: 0.9750\n",
      "Epoch 38/100\n",
      "4157/4157 [==============================] - 0s 103us/sample - loss: 0.0640 - accuracy: 0.9796 - val_loss: 0.0416 - val_accuracy: 0.9904\n",
      "Epoch 39/100\n",
      "4157/4157 [==============================] - 0s 111us/sample - loss: 0.0636 - accuracy: 0.9781 - val_loss: 0.0274 - val_accuracy: 0.9952\n",
      "Epoch 40/100\n",
      "4157/4157 [==============================] - 0s 104us/sample - loss: 0.0645 - accuracy: 0.9810 - val_loss: 0.0379 - val_accuracy: 0.9913\n",
      "Epoch 41/100\n",
      "4157/4157 [==============================] - 0s 108us/sample - loss: 0.0672 - accuracy: 0.9791 - val_loss: 0.0489 - val_accuracy: 0.9885\n",
      "Epoch 42/100\n",
      "4157/4157 [==============================] - 0s 108us/sample - loss: 0.0662 - accuracy: 0.9803 - val_loss: 0.0449 - val_accuracy: 0.9875\n",
      "Epoch 43/100\n",
      "4157/4157 [==============================] - 0s 114us/sample - loss: 0.0654 - accuracy: 0.9783 - val_loss: 0.0560 - val_accuracy: 0.9846\n",
      "Epoch 44/100\n",
      "4157/4157 [==============================] - 0s 111us/sample - loss: 0.0639 - accuracy: 0.9767 - val_loss: 0.0449 - val_accuracy: 0.9894\n",
      "Epoch 45/100\n",
      "4157/4157 [==============================] - 0s 104us/sample - loss: 0.0604 - accuracy: 0.9820 - val_loss: 0.0309 - val_accuracy: 0.9942\n",
      "Epoch 46/100\n",
      "4157/4157 [==============================] - 0s 103us/sample - loss: 0.0600 - accuracy: 0.9803 - val_loss: 0.0497 - val_accuracy: 0.9875\n",
      "Epoch 47/100\n",
      "4157/4157 [==============================] - 0s 97us/sample - loss: 0.0595 - accuracy: 0.9824 - val_loss: 0.0474 - val_accuracy: 0.9875\n",
      "Epoch 48/100\n",
      "4157/4157 [==============================] - 0s 103us/sample - loss: 0.0566 - accuracy: 0.9844 - val_loss: 0.0488 - val_accuracy: 0.9904\n",
      "Epoch 49/100\n",
      "4157/4157 [==============================] - 0s 100us/sample - loss: 0.0620 - accuracy: 0.9815 - val_loss: 0.0283 - val_accuracy: 0.9981\n",
      "Epoch 50/100\n",
      "4157/4157 [==============================] - 0s 106us/sample - loss: 0.0589 - accuracy: 0.9829 - val_loss: 0.0602 - val_accuracy: 0.9837\n",
      "Epoch 51/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0623 - accuracy: 0.9817 - val_loss: 0.0925 - val_accuracy: 0.9721\n",
      "Epoch 52/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0597 - accuracy: 0.9820 - val_loss: 0.0357 - val_accuracy: 0.9933\n",
      "Epoch 53/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0604 - accuracy: 0.9817 - val_loss: 0.0412 - val_accuracy: 0.9885\n",
      "Epoch 54/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0592 - accuracy: 0.9832 - val_loss: 0.0548 - val_accuracy: 0.9865\n",
      "Epoch 55/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0612 - accuracy: 0.9803 - val_loss: 0.0584 - val_accuracy: 0.9837\n",
      "Epoch 56/100\n",
      "4157/4157 [==============================] - 0s 107us/sample - loss: 0.0584 - accuracy: 0.9827 - val_loss: 0.0651 - val_accuracy: 0.9846\n",
      "Epoch 57/100\n",
      "4157/4157 [==============================] - 0s 106us/sample - loss: 0.0590 - accuracy: 0.9800 - val_loss: 0.0660 - val_accuracy: 0.9798\n",
      "Epoch 58/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0557 - accuracy: 0.9817 - val_loss: 0.0572 - val_accuracy: 0.9846\n",
      "Epoch 59/100\n",
      "4157/4157 [==============================] - 0s 104us/sample - loss: 0.0573 - accuracy: 0.9827 - val_loss: 0.0433 - val_accuracy: 0.9904\n",
      "Epoch 60/100\n",
      "4157/4157 [==============================] - 0s 104us/sample - loss: 0.0578 - accuracy: 0.9817 - val_loss: 0.1373 - val_accuracy: 0.9558\n",
      "Epoch 61/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0542 - accuracy: 0.9836 - val_loss: 0.0821 - val_accuracy: 0.9760\n",
      "Epoch 62/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0528 - accuracy: 0.9844 - val_loss: 0.0894 - val_accuracy: 0.9712\n",
      "Epoch 63/100\n",
      "4157/4157 [==============================] - 0s 106us/sample - loss: 0.0575 - accuracy: 0.9832 - val_loss: 0.0696 - val_accuracy: 0.9817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0556 - accuracy: 0.9851 - val_loss: 0.0387 - val_accuracy: 0.9913\n",
      "Epoch 65/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0524 - accuracy: 0.9844 - val_loss: 0.0501 - val_accuracy: 0.9904\n",
      "Epoch 66/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0548 - accuracy: 0.9848 - val_loss: 0.0590 - val_accuracy: 0.9856\n",
      "Epoch 67/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0542 - accuracy: 0.9817 - val_loss: 0.0518 - val_accuracy: 0.9904\n",
      "Epoch 68/100\n",
      "4157/4157 [==============================] - 0s 104us/sample - loss: 0.0553 - accuracy: 0.9832 - val_loss: 0.0594 - val_accuracy: 0.9837\n",
      "Epoch 69/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0520 - accuracy: 0.9853 - val_loss: 0.1126 - val_accuracy: 0.9625\n",
      "Epoch 70/100\n",
      "4157/4157 [==============================] - 0s 106us/sample - loss: 0.0516 - accuracy: 0.9846 - val_loss: 0.0451 - val_accuracy: 0.9933\n",
      "Epoch 71/100\n",
      "4157/4157 [==============================] - 0s 106us/sample - loss: 0.0519 - accuracy: 0.9860 - val_loss: 0.0512 - val_accuracy: 0.9894\n",
      "Epoch 72/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0537 - accuracy: 0.9853 - val_loss: 0.0932 - val_accuracy: 0.9692\n",
      "Epoch 73/100\n",
      "4157/4157 [==============================] - 0s 106us/sample - loss: 0.0518 - accuracy: 0.9858 - val_loss: 0.0775 - val_accuracy: 0.9798\n",
      "Epoch 74/100\n",
      "4157/4157 [==============================] - 0s 104us/sample - loss: 0.0522 - accuracy: 0.9848 - val_loss: 0.1381 - val_accuracy: 0.9596\n",
      "Epoch 75/100\n",
      "4157/4157 [==============================] - 0s 104us/sample - loss: 0.0586 - accuracy: 0.9820 - val_loss: 0.1231 - val_accuracy: 0.9654\n",
      "Epoch 76/100\n",
      "4157/4157 [==============================] - 0s 113us/sample - loss: 0.0534 - accuracy: 0.9829 - val_loss: 0.0394 - val_accuracy: 0.9952\n",
      "Epoch 77/100\n",
      "4157/4157 [==============================] - 0s 106us/sample - loss: 0.0499 - accuracy: 0.9853 - val_loss: 0.0516 - val_accuracy: 0.9913\n",
      "Epoch 78/100\n",
      "4157/4157 [==============================] - 0s 106us/sample - loss: 0.0508 - accuracy: 0.9848 - val_loss: 0.0502 - val_accuracy: 0.9894\n",
      "Epoch 79/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0458 - accuracy: 0.9848 - val_loss: 0.0758 - val_accuracy: 0.9827\n",
      "Epoch 80/100\n",
      "4157/4157 [==============================] - 0s 110us/sample - loss: 0.0547 - accuracy: 0.9841 - val_loss: 0.0809 - val_accuracy: 0.9827\n",
      "Epoch 81/100\n",
      "4157/4157 [==============================] - 0s 106us/sample - loss: 0.0576 - accuracy: 0.9815 - val_loss: 0.0845 - val_accuracy: 0.9769\n",
      "Epoch 82/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0487 - accuracy: 0.9848 - val_loss: 0.1044 - val_accuracy: 0.9702\n",
      "Epoch 83/100\n",
      "4157/4157 [==============================] - 0s 106us/sample - loss: 0.0508 - accuracy: 0.9856 - val_loss: 0.0760 - val_accuracy: 0.9846\n",
      "Epoch 84/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0510 - accuracy: 0.9834 - val_loss: 0.0489 - val_accuracy: 0.9923\n",
      "Epoch 85/100\n",
      "4157/4157 [==============================] - 0s 106us/sample - loss: 0.0489 - accuracy: 0.9848 - val_loss: 0.0423 - val_accuracy: 0.9942\n",
      "Epoch 86/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0528 - accuracy: 0.9848 - val_loss: 0.0602 - val_accuracy: 0.9923\n",
      "Epoch 87/100\n",
      "4157/4157 [==============================] - 0s 106us/sample - loss: 0.0518 - accuracy: 0.9851 - val_loss: 0.0953 - val_accuracy: 0.9788\n",
      "Epoch 88/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0511 - accuracy: 0.9860 - val_loss: 0.0524 - val_accuracy: 0.9942\n",
      "Epoch 89/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0499 - accuracy: 0.9844 - val_loss: 0.0609 - val_accuracy: 0.9942\n",
      "Epoch 90/100\n",
      "4157/4157 [==============================] - 0s 104us/sample - loss: 0.0463 - accuracy: 0.9882 - val_loss: 0.0603 - val_accuracy: 0.9923\n",
      "Epoch 91/100\n",
      "4157/4157 [==============================] - 0s 106us/sample - loss: 0.0498 - accuracy: 0.9851 - val_loss: 0.1443 - val_accuracy: 0.9567\n",
      "Epoch 92/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0548 - accuracy: 0.9822 - val_loss: 0.1070 - val_accuracy: 0.9798\n",
      "Epoch 93/100\n",
      "4157/4157 [==============================] - 0s 107us/sample - loss: 0.0475 - accuracy: 0.9880 - val_loss: 0.0630 - val_accuracy: 0.9904\n",
      "Epoch 94/100\n",
      "4157/4157 [==============================] - 0s 106us/sample - loss: 0.0461 - accuracy: 0.9882 - val_loss: 0.0590 - val_accuracy: 0.9894\n",
      "Epoch 95/100\n",
      "4157/4157 [==============================] - 0s 106us/sample - loss: 0.0538 - accuracy: 0.9844 - val_loss: 0.0429 - val_accuracy: 0.9971\n",
      "Epoch 96/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0502 - accuracy: 0.9851 - val_loss: 0.1075 - val_accuracy: 0.9683\n",
      "Epoch 97/100\n",
      "4157/4157 [==============================] - 0s 105us/sample - loss: 0.0502 - accuracy: 0.9844 - val_loss: 0.0924 - val_accuracy: 0.9779\n",
      "Epoch 98/100\n",
      "4157/4157 [==============================] - 0s 107us/sample - loss: 0.0477 - accuracy: 0.9853 - val_loss: 0.0682 - val_accuracy: 0.9904\n",
      "Epoch 99/100\n",
      "4157/4157 [==============================] - 0s 110us/sample - loss: 0.0446 - accuracy: 0.9873 - val_loss: 0.0477 - val_accuracy: 0.9962\n",
      "Epoch 100/100\n",
      "4157/4157 [==============================] - 0s 104us/sample - loss: 0.0477 - accuracy: 0.9870 - val_loss: 0.0839 - val_accuracy: 0.9837\n",
      "1300/1300 - 0s - loss: 0.0551 - accuracy: 0.9854\n",
      "Train on 4158 samples, validate on 1040 samples\n",
      "Epoch 1/100\n",
      "4158/4158 [==============================] - 1s 250us/sample - loss: 0.3302 - accuracy: 0.8899 - val_loss: 0.1187 - val_accuracy: 0.9808\n",
      "Epoch 2/100\n",
      "4158/4158 [==============================] - 0s 108us/sample - loss: 0.2154 - accuracy: 0.9187 - val_loss: 0.1091 - val_accuracy: 0.9798\n",
      "Epoch 3/100\n",
      "4158/4158 [==============================] - 0s 109us/sample - loss: 0.1873 - accuracy: 0.9315 - val_loss: 0.0798 - val_accuracy: 0.9788\n",
      "Epoch 4/100\n",
      "4158/4158 [==============================] - 0s 110us/sample - loss: 0.1661 - accuracy: 0.9367 - val_loss: 0.0904 - val_accuracy: 0.9846\n",
      "Epoch 5/100\n",
      "4158/4158 [==============================] - 0s 108us/sample - loss: 0.1480 - accuracy: 0.9442 - val_loss: 0.1262 - val_accuracy: 0.9663\n",
      "Epoch 6/100\n",
      "4158/4158 [==============================] - 0s 109us/sample - loss: 0.1335 - accuracy: 0.9545 - val_loss: 0.1462 - val_accuracy: 0.9615\n",
      "Epoch 7/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.1238 - accuracy: 0.9601 - val_loss: 0.0242 - val_accuracy: 0.9933\n",
      "Epoch 8/100\n",
      "4158/4158 [==============================] - 0s 109us/sample - loss: 0.1129 - accuracy: 0.9613 - val_loss: 0.0882 - val_accuracy: 0.9788\n",
      "Epoch 9/100\n",
      "4158/4158 [==============================] - 0s 114us/sample - loss: 0.1068 - accuracy: 0.9654 - val_loss: 0.1275 - val_accuracy: 0.9625\n",
      "Epoch 10/100\n",
      "4158/4158 [==============================] - 0s 107us/sample - loss: 0.1019 - accuracy: 0.9678 - val_loss: 0.1103 - val_accuracy: 0.9731\n",
      "Epoch 11/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0935 - accuracy: 0.9711 - val_loss: 0.0635 - val_accuracy: 0.9885\n",
      "Epoch 12/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0968 - accuracy: 0.9719 - val_loss: 0.1450 - val_accuracy: 0.9567\n",
      "Epoch 13/100\n",
      "4158/4158 [==============================] - 0s 104us/sample - loss: 0.0879 - accuracy: 0.9721 - val_loss: 0.0274 - val_accuracy: 0.9952\n",
      "Epoch 14/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0841 - accuracy: 0.9745 - val_loss: 0.0503 - val_accuracy: 0.9865\n",
      "Epoch 15/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0814 - accuracy: 0.9774 - val_loss: 0.0397 - val_accuracy: 0.9904\n",
      "Epoch 16/100\n",
      "4158/4158 [==============================] - 0s 109us/sample - loss: 0.0840 - accuracy: 0.9745 - val_loss: 0.0294 - val_accuracy: 0.9933\n",
      "Epoch 17/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0805 - accuracy: 0.9781 - val_loss: 0.0335 - val_accuracy: 0.9913\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0824 - accuracy: 0.9764 - val_loss: 0.0637 - val_accuracy: 0.9808\n",
      "Epoch 19/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0785 - accuracy: 0.9755 - val_loss: 0.0238 - val_accuracy: 0.9942\n",
      "Epoch 20/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0770 - accuracy: 0.9776 - val_loss: 0.1216 - val_accuracy: 0.9712\n",
      "Epoch 21/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0767 - accuracy: 0.9769 - val_loss: 0.0685 - val_accuracy: 0.9779\n",
      "Epoch 22/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0723 - accuracy: 0.9776 - val_loss: 0.0438 - val_accuracy: 0.9894\n",
      "Epoch 23/100\n",
      "4158/4158 [==============================] - 0s 107us/sample - loss: 0.0701 - accuracy: 0.9800 - val_loss: 0.0547 - val_accuracy: 0.9846\n",
      "Epoch 24/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0708 - accuracy: 0.9791 - val_loss: 0.0327 - val_accuracy: 0.9933\n",
      "Epoch 25/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0747 - accuracy: 0.9764 - val_loss: 0.0607 - val_accuracy: 0.9837\n",
      "Epoch 26/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0716 - accuracy: 0.9767 - val_loss: 0.0190 - val_accuracy: 0.9971\n",
      "Epoch 27/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0697 - accuracy: 0.9786 - val_loss: 0.0459 - val_accuracy: 0.9894\n",
      "Epoch 28/100\n",
      "4158/4158 [==============================] - 0s 109us/sample - loss: 0.0692 - accuracy: 0.9796 - val_loss: 0.0589 - val_accuracy: 0.9865\n",
      "Epoch 29/100\n",
      "4158/4158 [==============================] - 0s 109us/sample - loss: 0.0659 - accuracy: 0.9808 - val_loss: 0.0298 - val_accuracy: 0.9933\n",
      "Epoch 30/100\n",
      "4158/4158 [==============================] - 0s 113us/sample - loss: 0.0649 - accuracy: 0.9824 - val_loss: 0.0724 - val_accuracy: 0.9760\n",
      "Epoch 31/100\n",
      "4158/4158 [==============================] - 0s 111us/sample - loss: 0.0677 - accuracy: 0.9803 - val_loss: 0.0339 - val_accuracy: 0.9923\n",
      "Epoch 32/100\n",
      "4158/4158 [==============================] - 0s 110us/sample - loss: 0.0657 - accuracy: 0.9781 - val_loss: 0.0565 - val_accuracy: 0.9894\n",
      "Epoch 33/100\n",
      "4158/4158 [==============================] - 0s 108us/sample - loss: 0.0682 - accuracy: 0.9798 - val_loss: 0.0342 - val_accuracy: 0.9904\n",
      "Epoch 34/100\n",
      "4158/4158 [==============================] - 0s 108us/sample - loss: 0.0668 - accuracy: 0.9796 - val_loss: 0.1614 - val_accuracy: 0.9471\n",
      "Epoch 35/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0650 - accuracy: 0.9788 - val_loss: 0.0459 - val_accuracy: 0.9875\n",
      "Epoch 36/100\n",
      "4158/4158 [==============================] - 0s 108us/sample - loss: 0.0659 - accuracy: 0.9810 - val_loss: 0.1205 - val_accuracy: 0.9750\n",
      "Epoch 37/100\n",
      "4158/4158 [==============================] - 0s 107us/sample - loss: 0.0671 - accuracy: 0.9781 - val_loss: 0.0761 - val_accuracy: 0.9856\n",
      "Epoch 38/100\n",
      "4158/4158 [==============================] - 0s 107us/sample - loss: 0.0639 - accuracy: 0.9803 - val_loss: 0.0454 - val_accuracy: 0.9933\n",
      "Epoch 39/100\n",
      "4158/4158 [==============================] - 0s 108us/sample - loss: 0.0634 - accuracy: 0.9829 - val_loss: 0.2003 - val_accuracy: 0.9413\n",
      "Epoch 40/100\n",
      "4158/4158 [==============================] - 0s 108us/sample - loss: 0.0653 - accuracy: 0.9817 - val_loss: 0.0585 - val_accuracy: 0.9885\n",
      "Epoch 41/100\n",
      "4158/4158 [==============================] - 0s 107us/sample - loss: 0.0653 - accuracy: 0.9796 - val_loss: 0.0310 - val_accuracy: 0.9952\n",
      "Epoch 42/100\n",
      "4158/4158 [==============================] - 0s 117us/sample - loss: 0.0623 - accuracy: 0.9798 - val_loss: 0.0360 - val_accuracy: 0.9933\n",
      "Epoch 43/100\n",
      "4158/4158 [==============================] - 0s 104us/sample - loss: 0.0643 - accuracy: 0.9803 - val_loss: 0.0745 - val_accuracy: 0.9808\n",
      "Epoch 44/100\n",
      "4158/4158 [==============================] - 0s 107us/sample - loss: 0.0618 - accuracy: 0.9810 - val_loss: 0.0225 - val_accuracy: 0.9981\n",
      "Epoch 45/100\n",
      "4158/4158 [==============================] - 0s 108us/sample - loss: 0.0632 - accuracy: 0.9810 - val_loss: 0.0536 - val_accuracy: 0.9904\n",
      "Epoch 46/100\n",
      "4158/4158 [==============================] - 0s 108us/sample - loss: 0.0641 - accuracy: 0.9815 - val_loss: 0.0914 - val_accuracy: 0.9769\n",
      "Epoch 47/100\n",
      "4158/4158 [==============================] - 0s 109us/sample - loss: 0.0677 - accuracy: 0.9798 - val_loss: 0.0819 - val_accuracy: 0.9788\n",
      "Epoch 48/100\n",
      "4158/4158 [==============================] - 0s 108us/sample - loss: 0.0618 - accuracy: 0.9815 - val_loss: 0.0427 - val_accuracy: 0.9933\n",
      "Epoch 49/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0614 - accuracy: 0.9822 - val_loss: 0.0254 - val_accuracy: 0.9981\n",
      "Epoch 50/100\n",
      "4158/4158 [==============================] - 0s 108us/sample - loss: 0.0615 - accuracy: 0.9812 - val_loss: 0.1128 - val_accuracy: 0.9577\n",
      "Epoch 51/100\n",
      "4158/4158 [==============================] - 0s 107us/sample - loss: 0.0588 - accuracy: 0.9810 - val_loss: 0.1456 - val_accuracy: 0.9596\n",
      "Epoch 52/100\n",
      "4158/4158 [==============================] - 0s 108us/sample - loss: 0.0617 - accuracy: 0.9824 - val_loss: 0.0561 - val_accuracy: 0.9913\n",
      "Epoch 53/100\n",
      "4158/4158 [==============================] - 0s 108us/sample - loss: 0.0617 - accuracy: 0.9822 - val_loss: 0.0487 - val_accuracy: 0.9933\n",
      "Epoch 54/100\n",
      "4158/4158 [==============================] - 0s 108us/sample - loss: 0.0604 - accuracy: 0.9812 - val_loss: 0.0446 - val_accuracy: 0.9923\n",
      "Epoch 55/100\n",
      "4158/4158 [==============================] - 0s 108us/sample - loss: 0.0598 - accuracy: 0.9817 - val_loss: 0.0975 - val_accuracy: 0.9731\n",
      "Epoch 56/100\n",
      "4158/4158 [==============================] - 0s 108us/sample - loss: 0.0605 - accuracy: 0.9824 - val_loss: 0.0677 - val_accuracy: 0.9817\n",
      "Epoch 57/100\n",
      "4158/4158 [==============================] - 0s 108us/sample - loss: 0.0645 - accuracy: 0.9812 - val_loss: 0.0781 - val_accuracy: 0.9817\n",
      "Epoch 58/100\n",
      "4158/4158 [==============================] - 0s 108us/sample - loss: 0.0608 - accuracy: 0.9817 - val_loss: 0.0756 - val_accuracy: 0.9817\n",
      "Epoch 59/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0597 - accuracy: 0.9810 - val_loss: 0.0428 - val_accuracy: 0.9981\n",
      "Epoch 60/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0611 - accuracy: 0.9817 - val_loss: 0.0702 - val_accuracy: 0.9827\n",
      "Epoch 61/100\n",
      "4158/4158 [==============================] - 0s 108us/sample - loss: 0.0567 - accuracy: 0.9834 - val_loss: 0.0399 - val_accuracy: 0.9952\n",
      "Epoch 62/100\n",
      "4158/4158 [==============================] - 0s 108us/sample - loss: 0.0570 - accuracy: 0.9839 - val_loss: 0.0841 - val_accuracy: 0.9827\n",
      "Epoch 63/100\n",
      "4158/4158 [==============================] - 0s 108us/sample - loss: 0.0590 - accuracy: 0.9827 - val_loss: 0.0809 - val_accuracy: 0.9779\n",
      "Epoch 64/100\n",
      "4158/4158 [==============================] - 0s 108us/sample - loss: 0.0610 - accuracy: 0.9832 - val_loss: 0.0827 - val_accuracy: 0.9788\n",
      "Epoch 65/100\n",
      "4158/4158 [==============================] - 0s 108us/sample - loss: 0.0547 - accuracy: 0.9841 - val_loss: 0.0389 - val_accuracy: 0.9952\n",
      "Epoch 66/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0562 - accuracy: 0.9832 - val_loss: 0.0845 - val_accuracy: 0.9827\n",
      "Epoch 67/100\n",
      "4158/4158 [==============================] - 0s 109us/sample - loss: 0.0557 - accuracy: 0.9848 - val_loss: 0.2016 - val_accuracy: 0.9327\n",
      "Epoch 68/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0613 - accuracy: 0.9805 - val_loss: 0.0716 - val_accuracy: 0.9904\n",
      "Epoch 69/100\n",
      "4158/4158 [==============================] - 0s 108us/sample - loss: 0.0581 - accuracy: 0.9822 - val_loss: 0.0535 - val_accuracy: 0.9923\n",
      "Epoch 70/100\n",
      "4158/4158 [==============================] - 0s 109us/sample - loss: 0.0562 - accuracy: 0.9834 - val_loss: 0.0583 - val_accuracy: 0.9913\n",
      "Epoch 71/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0538 - accuracy: 0.9839 - val_loss: 0.0617 - val_accuracy: 0.9894\n",
      "Epoch 72/100\n",
      "4158/4158 [==============================] - 0s 108us/sample - loss: 0.0596 - accuracy: 0.9800 - val_loss: 0.0553 - val_accuracy: 0.9894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100\n",
      "4158/4158 [==============================] - 0s 108us/sample - loss: 0.0563 - accuracy: 0.9824 - val_loss: 0.0553 - val_accuracy: 0.9942\n",
      "Epoch 74/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0550 - accuracy: 0.9844 - val_loss: 0.0695 - val_accuracy: 0.9885\n",
      "Epoch 75/100\n",
      "4158/4158 [==============================] - 0s 107us/sample - loss: 0.0534 - accuracy: 0.9836 - val_loss: 0.1172 - val_accuracy: 0.9663\n",
      "Epoch 76/100\n",
      "4158/4158 [==============================] - 0s 108us/sample - loss: 0.0535 - accuracy: 0.9836 - val_loss: 0.2202 - val_accuracy: 0.9269\n",
      "Epoch 77/100\n",
      "4158/4158 [==============================] - 0s 108us/sample - loss: 0.0565 - accuracy: 0.9832 - val_loss: 0.1010 - val_accuracy: 0.9769\n",
      "Epoch 78/100\n",
      "4158/4158 [==============================] - 0s 107us/sample - loss: 0.0559 - accuracy: 0.9829 - val_loss: 0.0439 - val_accuracy: 0.9952\n",
      "Epoch 79/100\n",
      "4158/4158 [==============================] - 0s 111us/sample - loss: 0.0525 - accuracy: 0.9853 - val_loss: 0.0612 - val_accuracy: 0.9885\n",
      "Epoch 80/100\n",
      "4158/4158 [==============================] - 0s 107us/sample - loss: 0.0561 - accuracy: 0.9824 - val_loss: 0.0968 - val_accuracy: 0.9712\n",
      "Epoch 81/100\n",
      "4158/4158 [==============================] - 0s 107us/sample - loss: 0.0529 - accuracy: 0.9839 - val_loss: 0.0514 - val_accuracy: 0.9962\n",
      "Epoch 82/100\n",
      "4158/4158 [==============================] - 0s 107us/sample - loss: 0.0553 - accuracy: 0.9844 - val_loss: 0.1009 - val_accuracy: 0.9760\n",
      "Epoch 83/100\n",
      "4158/4158 [==============================] - 0s 107us/sample - loss: 0.0547 - accuracy: 0.9846 - val_loss: 0.0393 - val_accuracy: 0.9933\n",
      "Epoch 84/100\n",
      "4158/4158 [==============================] - 0s 108us/sample - loss: 0.0529 - accuracy: 0.9824 - val_loss: 0.0516 - val_accuracy: 0.9952\n",
      "Epoch 85/100\n",
      "4158/4158 [==============================] - 0s 108us/sample - loss: 0.0510 - accuracy: 0.9853 - val_loss: 0.0763 - val_accuracy: 0.9894\n",
      "Epoch 86/100\n",
      "4158/4158 [==============================] - 0s 107us/sample - loss: 0.0520 - accuracy: 0.9846 - val_loss: 0.0498 - val_accuracy: 0.9952\n",
      "Epoch 87/100\n",
      "4158/4158 [==============================] - 0s 109us/sample - loss: 0.0514 - accuracy: 0.9844 - val_loss: 0.0731 - val_accuracy: 0.9846\n",
      "Epoch 88/100\n",
      "4158/4158 [==============================] - 0s 108us/sample - loss: 0.0535 - accuracy: 0.9853 - val_loss: 0.0916 - val_accuracy: 0.9788\n",
      "Epoch 89/100\n",
      "4158/4158 [==============================] - 0s 109us/sample - loss: 0.0524 - accuracy: 0.9839 - val_loss: 0.0710 - val_accuracy: 0.9913\n",
      "Epoch 90/100\n",
      "4158/4158 [==============================] - 0s 108us/sample - loss: 0.0521 - accuracy: 0.9846 - val_loss: 0.1297 - val_accuracy: 0.9837\n",
      "Epoch 91/100\n",
      "4158/4158 [==============================] - 0s 104us/sample - loss: 0.0516 - accuracy: 0.9832 - val_loss: 0.1560 - val_accuracy: 0.9423\n",
      "Epoch 92/100\n",
      "4158/4158 [==============================] - 0s 108us/sample - loss: 0.0533 - accuracy: 0.9844 - val_loss: 0.0335 - val_accuracy: 0.9962\n",
      "Epoch 93/100\n",
      "4158/4158 [==============================] - 0s 108us/sample - loss: 0.0550 - accuracy: 0.9839 - val_loss: 0.2063 - val_accuracy: 0.9788\n",
      "Epoch 94/100\n",
      "4158/4158 [==============================] - 0s 108us/sample - loss: 0.0581 - accuracy: 0.9832 - val_loss: 0.1537 - val_accuracy: 0.9817\n",
      "Epoch 95/100\n",
      "4158/4158 [==============================] - 0s 107us/sample - loss: 0.0509 - accuracy: 0.9836 - val_loss: 0.0689 - val_accuracy: 0.9933\n",
      "Epoch 96/100\n",
      "4158/4158 [==============================] - 0s 107us/sample - loss: 0.0520 - accuracy: 0.9834 - val_loss: 0.0386 - val_accuracy: 0.9962\n",
      "Epoch 97/100\n",
      "4158/4158 [==============================] - 0s 108us/sample - loss: 0.0506 - accuracy: 0.9863 - val_loss: 0.0483 - val_accuracy: 0.9942\n",
      "Epoch 98/100\n",
      "4158/4158 [==============================] - 0s 107us/sample - loss: 0.0496 - accuracy: 0.9832 - val_loss: 0.0459 - val_accuracy: 0.9933\n",
      "Epoch 99/100\n",
      "4158/4158 [==============================] - 0s 108us/sample - loss: 0.0542 - accuracy: 0.9808 - val_loss: 0.0453 - val_accuracy: 0.9962\n",
      "Epoch 100/100\n",
      "4158/4158 [==============================] - 0s 108us/sample - loss: 0.0524 - accuracy: 0.9839 - val_loss: 0.0713 - val_accuracy: 0.9865\n",
      "1299/1299 - 0s - loss: 0.0402 - accuracy: 0.9861\n",
      "Train on 4158 samples, validate on 1040 samples\n",
      "Epoch 1/100\n",
      "4158/4158 [==============================] - 1s 255us/sample - loss: 0.3687 - accuracy: 0.8807 - val_loss: 0.0828 - val_accuracy: 0.9885\n",
      "Epoch 2/100\n",
      "4158/4158 [==============================] - 0s 99us/sample - loss: 0.1990 - accuracy: 0.9312 - val_loss: 0.1104 - val_accuracy: 0.9750\n",
      "Epoch 3/100\n",
      "4158/4158 [==============================] - 0s 104us/sample - loss: 0.1846 - accuracy: 0.9336 - val_loss: 0.0730 - val_accuracy: 0.9875\n",
      "Epoch 4/100\n",
      "4158/4158 [==============================] - 0s 104us/sample - loss: 0.1530 - accuracy: 0.9459 - val_loss: 0.0647 - val_accuracy: 0.9885\n",
      "Epoch 5/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.1308 - accuracy: 0.9545 - val_loss: 0.0487 - val_accuracy: 0.9942\n",
      "Epoch 6/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.1112 - accuracy: 0.9639 - val_loss: 0.0407 - val_accuracy: 0.9933\n",
      "Epoch 7/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.1028 - accuracy: 0.9649 - val_loss: 0.0220 - val_accuracy: 0.9942\n",
      "Epoch 8/100\n",
      "4158/4158 [==============================] - 0s 104us/sample - loss: 0.0935 - accuracy: 0.9707 - val_loss: 0.0228 - val_accuracy: 0.9933\n",
      "Epoch 9/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0896 - accuracy: 0.9719 - val_loss: 0.0310 - val_accuracy: 0.9894\n",
      "Epoch 10/100\n",
      "4158/4158 [==============================] - 0s 104us/sample - loss: 0.0846 - accuracy: 0.9721 - val_loss: 0.0357 - val_accuracy: 0.9904\n",
      "Epoch 11/100\n",
      "4158/4158 [==============================] - 0s 110us/sample - loss: 0.0811 - accuracy: 0.9752 - val_loss: 0.0472 - val_accuracy: 0.9846\n",
      "Epoch 12/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0797 - accuracy: 0.9728 - val_loss: 0.0105 - val_accuracy: 0.9971\n",
      "Epoch 13/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0737 - accuracy: 0.9762 - val_loss: 0.0246 - val_accuracy: 0.9904\n",
      "Epoch 14/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0721 - accuracy: 0.9776 - val_loss: 0.0522 - val_accuracy: 0.9808\n",
      "Epoch 15/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0748 - accuracy: 0.9745 - val_loss: 0.0171 - val_accuracy: 0.9933\n",
      "Epoch 16/100\n",
      "4158/4158 [==============================] - 0s 104us/sample - loss: 0.0713 - accuracy: 0.9791 - val_loss: 0.0301 - val_accuracy: 0.9894\n",
      "Epoch 17/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0674 - accuracy: 0.9805 - val_loss: 0.0064 - val_accuracy: 0.9990\n",
      "Epoch 18/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0682 - accuracy: 0.9784 - val_loss: 0.0105 - val_accuracy: 0.9981\n",
      "Epoch 19/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0638 - accuracy: 0.9788 - val_loss: 0.0378 - val_accuracy: 0.9885\n",
      "Epoch 20/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0634 - accuracy: 0.9788 - val_loss: 0.0280 - val_accuracy: 0.9894\n",
      "Epoch 21/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0660 - accuracy: 0.9788 - val_loss: 0.0240 - val_accuracy: 0.9923\n",
      "Epoch 22/100\n",
      "4158/4158 [==============================] - 0s 108us/sample - loss: 0.0624 - accuracy: 0.9800 - val_loss: 0.0329 - val_accuracy: 0.9865\n",
      "Epoch 23/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0637 - accuracy: 0.9793 - val_loss: 0.0183 - val_accuracy: 0.9952\n",
      "Epoch 24/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0618 - accuracy: 0.9815 - val_loss: 0.0740 - val_accuracy: 0.9760\n",
      "Epoch 25/100\n",
      "4158/4158 [==============================] - 0s 107us/sample - loss: 0.0584 - accuracy: 0.9836 - val_loss: 0.0356 - val_accuracy: 0.9894\n",
      "Epoch 26/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0621 - accuracy: 0.9800 - val_loss: 0.0098 - val_accuracy: 0.9971\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0643 - accuracy: 0.9803 - val_loss: 0.0323 - val_accuracy: 0.9933\n",
      "Epoch 28/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0590 - accuracy: 0.9812 - val_loss: 0.0234 - val_accuracy: 0.9923\n",
      "Epoch 29/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0604 - accuracy: 0.9810 - val_loss: 0.0194 - val_accuracy: 0.9913\n",
      "Epoch 30/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0576 - accuracy: 0.9810 - val_loss: 0.0506 - val_accuracy: 0.9846\n",
      "Epoch 31/100\n",
      "4158/4158 [==============================] - 0s 104us/sample - loss: 0.0558 - accuracy: 0.9810 - val_loss: 0.0293 - val_accuracy: 0.9913\n",
      "Epoch 32/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0549 - accuracy: 0.9827 - val_loss: 0.0304 - val_accuracy: 0.9904\n",
      "Epoch 33/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0552 - accuracy: 0.9832 - val_loss: 0.0689 - val_accuracy: 0.9779\n",
      "Epoch 34/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0579 - accuracy: 0.9832 - val_loss: 0.0420 - val_accuracy: 0.9913\n",
      "Epoch 35/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0528 - accuracy: 0.9827 - val_loss: 0.0636 - val_accuracy: 0.9731\n",
      "Epoch 36/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0552 - accuracy: 0.9827 - val_loss: 0.0271 - val_accuracy: 0.9923\n",
      "Epoch 37/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0510 - accuracy: 0.9834 - val_loss: 0.0321 - val_accuracy: 0.9913\n",
      "Epoch 38/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0525 - accuracy: 0.9822 - val_loss: 0.0086 - val_accuracy: 0.9981\n",
      "Epoch 39/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0525 - accuracy: 0.9841 - val_loss: 0.0435 - val_accuracy: 0.9856\n",
      "Epoch 40/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0505 - accuracy: 0.9827 - val_loss: 0.0293 - val_accuracy: 0.9923\n",
      "Epoch 41/100\n",
      "4158/4158 [==============================] - 0s 110us/sample - loss: 0.0503 - accuracy: 0.9841 - val_loss: 0.0164 - val_accuracy: 0.9952\n",
      "Epoch 42/100\n",
      "4158/4158 [==============================] - 0s 103us/sample - loss: 0.0508 - accuracy: 0.9829 - val_loss: 0.0142 - val_accuracy: 0.9933\n",
      "Epoch 43/100\n",
      "4158/4158 [==============================] - 0s 107us/sample - loss: 0.0487 - accuracy: 0.9848 - val_loss: 0.0893 - val_accuracy: 0.9712\n",
      "Epoch 44/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0522 - accuracy: 0.9827 - val_loss: 0.0163 - val_accuracy: 0.9952\n",
      "Epoch 45/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0504 - accuracy: 0.9839 - val_loss: 0.0114 - val_accuracy: 0.9952\n",
      "Epoch 46/100\n",
      "4158/4158 [==============================] - 0s 111us/sample - loss: 0.0497 - accuracy: 0.9856 - val_loss: 0.0199 - val_accuracy: 0.9942\n",
      "Epoch 47/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0478 - accuracy: 0.9858 - val_loss: 0.0118 - val_accuracy: 0.9952\n",
      "Epoch 48/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0495 - accuracy: 0.9846 - val_loss: 0.0408 - val_accuracy: 0.9885\n",
      "Epoch 49/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0487 - accuracy: 0.9846 - val_loss: 0.0242 - val_accuracy: 0.9913\n",
      "Epoch 50/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0466 - accuracy: 0.9853 - val_loss: 0.0370 - val_accuracy: 0.9913\n",
      "Epoch 51/100\n",
      "4158/4158 [==============================] - 0s 104us/sample - loss: 0.0469 - accuracy: 0.9868 - val_loss: 0.0871 - val_accuracy: 0.9721\n",
      "Epoch 52/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0504 - accuracy: 0.9827 - val_loss: 0.0399 - val_accuracy: 0.9875\n",
      "Epoch 53/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0484 - accuracy: 0.9841 - val_loss: 0.0351 - val_accuracy: 0.9894\n",
      "Epoch 54/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0472 - accuracy: 0.9844 - val_loss: 0.0223 - val_accuracy: 0.9942\n",
      "Epoch 55/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0469 - accuracy: 0.9856 - val_loss: 0.0516 - val_accuracy: 0.9856\n",
      "Epoch 56/100\n",
      "4158/4158 [==============================] - 0s 107us/sample - loss: 0.0431 - accuracy: 0.9870 - val_loss: 0.0269 - val_accuracy: 0.9952\n",
      "Epoch 57/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0458 - accuracy: 0.9863 - val_loss: 0.0244 - val_accuracy: 0.9904\n",
      "Epoch 58/100\n",
      "4158/4158 [==============================] - 0s 114us/sample - loss: 0.0444 - accuracy: 0.9870 - val_loss: 0.0386 - val_accuracy: 0.9894\n",
      "Epoch 59/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0477 - accuracy: 0.9856 - val_loss: 0.0336 - val_accuracy: 0.9894\n",
      "Epoch 60/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0443 - accuracy: 0.9875 - val_loss: 0.0761 - val_accuracy: 0.9788\n",
      "Epoch 61/100\n",
      "4158/4158 [==============================] - 0s 107us/sample - loss: 0.0493 - accuracy: 0.9846 - val_loss: 0.0712 - val_accuracy: 0.9760\n",
      "Epoch 62/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0418 - accuracy: 0.9887 - val_loss: 0.0247 - val_accuracy: 0.9913\n",
      "Epoch 63/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0436 - accuracy: 0.9870 - val_loss: 0.0198 - val_accuracy: 0.9933\n",
      "Epoch 64/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0427 - accuracy: 0.9873 - val_loss: 0.0473 - val_accuracy: 0.9875\n",
      "Epoch 65/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0455 - accuracy: 0.9873 - val_loss: 0.0423 - val_accuracy: 0.9885\n",
      "Epoch 66/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0447 - accuracy: 0.9873 - val_loss: 0.0150 - val_accuracy: 0.9952\n",
      "Epoch 67/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0453 - accuracy: 0.9870 - val_loss: 0.0757 - val_accuracy: 0.9779\n",
      "Epoch 68/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0486 - accuracy: 0.9861 - val_loss: 0.0224 - val_accuracy: 0.9952\n",
      "Epoch 69/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0482 - accuracy: 0.9856 - val_loss: 0.0198 - val_accuracy: 0.9942\n",
      "Epoch 70/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0451 - accuracy: 0.9868 - val_loss: 0.0619 - val_accuracy: 0.9827\n",
      "Epoch 71/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0390 - accuracy: 0.9894 - val_loss: 0.0198 - val_accuracy: 0.9942\n",
      "Epoch 72/100\n",
      "4158/4158 [==============================] - 0s 109us/sample - loss: 0.0458 - accuracy: 0.9873 - val_loss: 0.0274 - val_accuracy: 0.9933\n",
      "Epoch 73/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0433 - accuracy: 0.9875 - val_loss: 0.0472 - val_accuracy: 0.9875\n",
      "Epoch 74/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0419 - accuracy: 0.9882 - val_loss: 0.0213 - val_accuracy: 0.9933\n",
      "Epoch 75/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0445 - accuracy: 0.9865 - val_loss: 0.0218 - val_accuracy: 0.9933\n",
      "Epoch 76/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0466 - accuracy: 0.9873 - val_loss: 0.0240 - val_accuracy: 0.9942\n",
      "Epoch 77/100\n",
      "4158/4158 [==============================] - 0s 107us/sample - loss: 0.0493 - accuracy: 0.9851 - val_loss: 0.0298 - val_accuracy: 0.9933\n",
      "Epoch 78/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0403 - accuracy: 0.9887 - val_loss: 0.0411 - val_accuracy: 0.9894\n",
      "Epoch 79/100\n",
      "4158/4158 [==============================] - 0s 103us/sample - loss: 0.0401 - accuracy: 0.9892 - val_loss: 0.0406 - val_accuracy: 0.9865\n",
      "Epoch 80/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0402 - accuracy: 0.9897 - val_loss: 0.0313 - val_accuracy: 0.9904\n",
      "Epoch 81/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0444 - accuracy: 0.9853 - val_loss: 0.0362 - val_accuracy: 0.9904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0436 - accuracy: 0.9865 - val_loss: 0.0161 - val_accuracy: 0.9933\n",
      "Epoch 83/100\n",
      "4158/4158 [==============================] - 0s 104us/sample - loss: 0.0429 - accuracy: 0.9877 - val_loss: 0.0142 - val_accuracy: 0.9952\n",
      "Epoch 84/100\n",
      "4158/4158 [==============================] - 0s 104us/sample - loss: 0.0387 - accuracy: 0.9894 - val_loss: 0.0147 - val_accuracy: 0.9962\n",
      "Epoch 85/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0409 - accuracy: 0.9887 - val_loss: 0.0183 - val_accuracy: 0.9942\n",
      "Epoch 86/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0442 - accuracy: 0.9868 - val_loss: 0.0138 - val_accuracy: 0.9952\n",
      "Epoch 87/100\n",
      "4158/4158 [==============================] - 0s 103us/sample - loss: 0.0445 - accuracy: 0.9877 - val_loss: 0.0196 - val_accuracy: 0.9923\n",
      "Epoch 88/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0411 - accuracy: 0.9887 - val_loss: 0.0056 - val_accuracy: 0.9990\n",
      "Epoch 89/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0450 - accuracy: 0.9868 - val_loss: 0.0223 - val_accuracy: 0.9952\n",
      "Epoch 90/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0389 - accuracy: 0.9892 - val_loss: 0.0105 - val_accuracy: 0.9962\n",
      "Epoch 91/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0442 - accuracy: 0.9865 - val_loss: 0.0189 - val_accuracy: 0.9952\n",
      "Epoch 92/100\n",
      "4158/4158 [==============================] - 0s 108us/sample - loss: 0.0433 - accuracy: 0.9873 - val_loss: 0.1158 - val_accuracy: 0.9577\n",
      "Epoch 93/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0394 - accuracy: 0.9880 - val_loss: 0.0353 - val_accuracy: 0.9913\n",
      "Epoch 94/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0391 - accuracy: 0.9885 - val_loss: 0.0242 - val_accuracy: 0.9923\n",
      "Epoch 95/100\n",
      "4158/4158 [==============================] - 0s 111us/sample - loss: 0.0426 - accuracy: 0.9875 - val_loss: 0.0505 - val_accuracy: 0.9837\n",
      "Epoch 96/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0390 - accuracy: 0.9889 - val_loss: 0.0224 - val_accuracy: 0.9933\n",
      "Epoch 97/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0430 - accuracy: 0.9870 - val_loss: 0.0284 - val_accuracy: 0.9933\n",
      "Epoch 98/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0426 - accuracy: 0.9873 - val_loss: 0.0542 - val_accuracy: 0.9788\n",
      "Epoch 99/100\n",
      "4158/4158 [==============================] - 0s 104us/sample - loss: 0.0394 - accuracy: 0.9894 - val_loss: 0.0399 - val_accuracy: 0.9875\n",
      "Epoch 100/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0422 - accuracy: 0.9870 - val_loss: 0.0191 - val_accuracy: 0.9942\n",
      "1299/1299 - 0s - loss: 0.0725 - accuracy: 0.9877\n",
      "Train on 4158 samples, validate on 1040 samples\n",
      "Epoch 1/100\n",
      "4158/4158 [==============================] - 1s 258us/sample - loss: 0.4007 - accuracy: 0.8177 - val_loss: 0.1663 - val_accuracy: 0.9519\n",
      "Epoch 2/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.2069 - accuracy: 0.9250 - val_loss: 0.0950 - val_accuracy: 0.9779\n",
      "Epoch 3/100\n",
      "4158/4158 [==============================] - 0s 104us/sample - loss: 0.1808 - accuracy: 0.9329 - val_loss: 0.0818 - val_accuracy: 0.9798\n",
      "Epoch 4/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.1584 - accuracy: 0.9420 - val_loss: 0.0603 - val_accuracy: 0.9875\n",
      "Epoch 5/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.1390 - accuracy: 0.9481 - val_loss: 0.1042 - val_accuracy: 0.9760\n",
      "Epoch 6/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.1236 - accuracy: 0.9555 - val_loss: 0.0539 - val_accuracy: 0.9865\n",
      "Epoch 7/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.1082 - accuracy: 0.9668 - val_loss: 0.0739 - val_accuracy: 0.9788\n",
      "Epoch 8/100\n",
      "4158/4158 [==============================] - 0s 107us/sample - loss: 0.1028 - accuracy: 0.9678 - val_loss: 0.0695 - val_accuracy: 0.9817\n",
      "Epoch 9/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0969 - accuracy: 0.9685 - val_loss: 0.0298 - val_accuracy: 0.9942\n",
      "Epoch 10/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0931 - accuracy: 0.9699 - val_loss: 0.0326 - val_accuracy: 0.9923\n",
      "Epoch 11/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0867 - accuracy: 0.9743 - val_loss: 0.0504 - val_accuracy: 0.9865\n",
      "Epoch 12/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0860 - accuracy: 0.9721 - val_loss: 0.0705 - val_accuracy: 0.9769\n",
      "Epoch 13/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0838 - accuracy: 0.9743 - val_loss: 0.0365 - val_accuracy: 0.9894\n",
      "Epoch 14/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0776 - accuracy: 0.9762 - val_loss: 0.0843 - val_accuracy: 0.9750\n",
      "Epoch 15/100\n",
      "4158/4158 [==============================] - 0s 107us/sample - loss: 0.0763 - accuracy: 0.9776 - val_loss: 0.0236 - val_accuracy: 0.9962\n",
      "Epoch 16/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0750 - accuracy: 0.9757 - val_loss: 0.0223 - val_accuracy: 0.9962\n",
      "Epoch 17/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0747 - accuracy: 0.9755 - val_loss: 0.0355 - val_accuracy: 0.9923\n",
      "Epoch 18/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0718 - accuracy: 0.9762 - val_loss: 0.0202 - val_accuracy: 0.9962\n",
      "Epoch 19/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0725 - accuracy: 0.9776 - val_loss: 0.0290 - val_accuracy: 0.9933\n",
      "Epoch 20/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0683 - accuracy: 0.9781 - val_loss: 0.0406 - val_accuracy: 0.9894\n",
      "Epoch 21/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0693 - accuracy: 0.9776 - val_loss: 0.0963 - val_accuracy: 0.9625\n",
      "Epoch 22/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0684 - accuracy: 0.9791 - val_loss: 0.0332 - val_accuracy: 0.9904\n",
      "Epoch 23/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0668 - accuracy: 0.9781 - val_loss: 0.0977 - val_accuracy: 0.9635\n",
      "Epoch 24/100\n",
      "4158/4158 [==============================] - 0s 107us/sample - loss: 0.0674 - accuracy: 0.9788 - val_loss: 0.0224 - val_accuracy: 0.9952\n",
      "Epoch 25/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0668 - accuracy: 0.9791 - val_loss: 0.0438 - val_accuracy: 0.9865\n",
      "Epoch 26/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0640 - accuracy: 0.9776 - val_loss: 0.0220 - val_accuracy: 0.9913\n",
      "Epoch 27/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0685 - accuracy: 0.9786 - val_loss: 0.0836 - val_accuracy: 0.9692\n",
      "Epoch 28/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0628 - accuracy: 0.9808 - val_loss: 0.0372 - val_accuracy: 0.9865\n",
      "Epoch 29/100\n",
      "4158/4158 [==============================] - 0s 112us/sample - loss: 0.0639 - accuracy: 0.9803 - val_loss: 0.0306 - val_accuracy: 0.9923\n",
      "Epoch 30/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0641 - accuracy: 0.9788 - val_loss: 0.0734 - val_accuracy: 0.9702\n",
      "Epoch 31/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0625 - accuracy: 0.9796 - val_loss: 0.0886 - val_accuracy: 0.9673\n",
      "Epoch 32/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0617 - accuracy: 0.9810 - val_loss: 0.0387 - val_accuracy: 0.9865\n",
      "Epoch 33/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0613 - accuracy: 0.9812 - val_loss: 0.0559 - val_accuracy: 0.9798\n",
      "Epoch 34/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0637 - accuracy: 0.9793 - val_loss: 0.0182 - val_accuracy: 0.9981\n",
      "Epoch 35/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0638 - accuracy: 0.9774 - val_loss: 0.0237 - val_accuracy: 0.9923\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0631 - accuracy: 0.9812 - val_loss: 0.0369 - val_accuracy: 0.9885\n",
      "Epoch 37/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0599 - accuracy: 0.9820 - val_loss: 0.0377 - val_accuracy: 0.9904\n",
      "Epoch 38/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0610 - accuracy: 0.9805 - val_loss: 0.0278 - val_accuracy: 0.9971\n",
      "Epoch 39/100\n",
      "4158/4158 [==============================] - 0s 104us/sample - loss: 0.0620 - accuracy: 0.9810 - val_loss: 0.0530 - val_accuracy: 0.9837\n",
      "Epoch 40/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0611 - accuracy: 0.9808 - val_loss: 0.0793 - val_accuracy: 0.9779\n",
      "Epoch 41/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0619 - accuracy: 0.9815 - val_loss: 0.1041 - val_accuracy: 0.9663\n",
      "Epoch 42/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0590 - accuracy: 0.9805 - val_loss: 0.0341 - val_accuracy: 0.9923\n",
      "Epoch 43/100\n",
      "4158/4158 [==============================] - 0s 103us/sample - loss: 0.0622 - accuracy: 0.9815 - val_loss: 0.0324 - val_accuracy: 0.9904\n",
      "Epoch 44/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0597 - accuracy: 0.9820 - val_loss: 0.0219 - val_accuracy: 0.9981\n",
      "Epoch 45/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0580 - accuracy: 0.9829 - val_loss: 0.0504 - val_accuracy: 0.9817\n",
      "Epoch 46/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0585 - accuracy: 0.9812 - val_loss: 0.0515 - val_accuracy: 0.9856\n",
      "Epoch 47/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0604 - accuracy: 0.9808 - val_loss: 0.0698 - val_accuracy: 0.9769\n",
      "Epoch 48/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0559 - accuracy: 0.9822 - val_loss: 0.0744 - val_accuracy: 0.9769\n",
      "Epoch 49/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0572 - accuracy: 0.9817 - val_loss: 0.1255 - val_accuracy: 0.9615\n",
      "Epoch 50/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0564 - accuracy: 0.9827 - val_loss: 0.0656 - val_accuracy: 0.9769\n",
      "Epoch 51/100\n",
      "4158/4158 [==============================] - 0s 103us/sample - loss: 0.0565 - accuracy: 0.9815 - val_loss: 0.0406 - val_accuracy: 0.9904\n",
      "Epoch 52/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0562 - accuracy: 0.9827 - val_loss: 0.0713 - val_accuracy: 0.9769\n",
      "Epoch 53/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0558 - accuracy: 0.9824 - val_loss: 0.0280 - val_accuracy: 0.9962\n",
      "Epoch 54/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0543 - accuracy: 0.9834 - val_loss: 0.0370 - val_accuracy: 0.9942\n",
      "Epoch 55/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0557 - accuracy: 0.9829 - val_loss: 0.0522 - val_accuracy: 0.9894\n",
      "Epoch 56/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0567 - accuracy: 0.9827 - val_loss: 0.1247 - val_accuracy: 0.9615\n",
      "Epoch 57/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0556 - accuracy: 0.9829 - val_loss: 0.0372 - val_accuracy: 0.9913\n",
      "Epoch 58/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0552 - accuracy: 0.9820 - val_loss: 0.0489 - val_accuracy: 0.9894\n",
      "Epoch 59/100\n",
      "4158/4158 [==============================] - 0s 109us/sample - loss: 0.0560 - accuracy: 0.9815 - val_loss: 0.0416 - val_accuracy: 0.9923\n",
      "Epoch 60/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0549 - accuracy: 0.9829 - val_loss: 0.1082 - val_accuracy: 0.9702\n",
      "Epoch 61/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0542 - accuracy: 0.9841 - val_loss: 0.0380 - val_accuracy: 0.9913\n",
      "Epoch 62/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0534 - accuracy: 0.9829 - val_loss: 0.0776 - val_accuracy: 0.9769\n",
      "Epoch 63/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0505 - accuracy: 0.9861 - val_loss: 0.0406 - val_accuracy: 0.9904\n",
      "Epoch 64/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0534 - accuracy: 0.9841 - val_loss: 0.0482 - val_accuracy: 0.9875\n",
      "Epoch 65/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0551 - accuracy: 0.9832 - val_loss: 0.0979 - val_accuracy: 0.9683\n",
      "Epoch 66/100\n",
      "4158/4158 [==============================] - 0s 112us/sample - loss: 0.0542 - accuracy: 0.9829 - val_loss: 0.0662 - val_accuracy: 0.9827\n",
      "Epoch 67/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0600 - accuracy: 0.9798 - val_loss: 0.0774 - val_accuracy: 0.9788\n",
      "Epoch 68/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0519 - accuracy: 0.9839 - val_loss: 0.0281 - val_accuracy: 0.9942\n",
      "Epoch 69/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0494 - accuracy: 0.9853 - val_loss: 0.0408 - val_accuracy: 0.9913\n",
      "Epoch 70/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0522 - accuracy: 0.9834 - val_loss: 0.0651 - val_accuracy: 0.9837\n",
      "Epoch 71/100\n",
      "4158/4158 [==============================] - 0s 103us/sample - loss: 0.0525 - accuracy: 0.9851 - val_loss: 0.0453 - val_accuracy: 0.9875\n",
      "Epoch 72/100\n",
      "4158/4158 [==============================] - 0s 109us/sample - loss: 0.0526 - accuracy: 0.9846 - val_loss: 0.0647 - val_accuracy: 0.9827\n",
      "Epoch 73/100\n",
      "4158/4158 [==============================] - 0s 104us/sample - loss: 0.0521 - accuracy: 0.9824 - val_loss: 0.0515 - val_accuracy: 0.9885\n",
      "Epoch 74/100\n",
      "4158/4158 [==============================] - 0s 107us/sample - loss: 0.0568 - accuracy: 0.9822 - val_loss: 0.0566 - val_accuracy: 0.9837\n",
      "Epoch 75/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0527 - accuracy: 0.9851 - val_loss: 0.0599 - val_accuracy: 0.9885\n",
      "Epoch 76/100\n",
      "4158/4158 [==============================] - 0s 107us/sample - loss: 0.0506 - accuracy: 0.9844 - val_loss: 0.1391 - val_accuracy: 0.9519\n",
      "Epoch 77/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0528 - accuracy: 0.9834 - val_loss: 0.0713 - val_accuracy: 0.9837\n",
      "Epoch 78/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0514 - accuracy: 0.9848 - val_loss: 0.0504 - val_accuracy: 0.9913\n",
      "Epoch 79/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0549 - accuracy: 0.9836 - val_loss: 0.0388 - val_accuracy: 0.9971\n",
      "Epoch 80/100\n",
      "4158/4158 [==============================] - 0s 107us/sample - loss: 0.0494 - accuracy: 0.9856 - val_loss: 0.0667 - val_accuracy: 0.9827\n",
      "Epoch 81/100\n",
      "4158/4158 [==============================] - 0s 107us/sample - loss: 0.0528 - accuracy: 0.9829 - val_loss: 0.0592 - val_accuracy: 0.9837\n",
      "Epoch 82/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0478 - accuracy: 0.9851 - val_loss: 0.0478 - val_accuracy: 0.9913\n",
      "Epoch 83/100\n",
      "4158/4158 [==============================] - 0s 104us/sample - loss: 0.0566 - accuracy: 0.9820 - val_loss: 0.0446 - val_accuracy: 0.9885\n",
      "Epoch 84/100\n",
      "4158/4158 [==============================] - 0s 107us/sample - loss: 0.0506 - accuracy: 0.9834 - val_loss: 0.1664 - val_accuracy: 0.9413\n",
      "Epoch 85/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0490 - accuracy: 0.9870 - val_loss: 0.0853 - val_accuracy: 0.9808\n",
      "Epoch 86/100\n",
      "4158/4158 [==============================] - 0s 107us/sample - loss: 0.0519 - accuracy: 0.9844 - val_loss: 0.0661 - val_accuracy: 0.9856\n",
      "Epoch 87/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0503 - accuracy: 0.9841 - val_loss: 0.0666 - val_accuracy: 0.9817\n",
      "Epoch 88/100\n",
      "4158/4158 [==============================] - 0s 107us/sample - loss: 0.0485 - accuracy: 0.9863 - val_loss: 0.0348 - val_accuracy: 0.9933\n",
      "Epoch 89/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0522 - accuracy: 0.9827 - val_loss: 0.1012 - val_accuracy: 0.9712\n",
      "Epoch 90/100\n",
      "4158/4158 [==============================] - 0s 107us/sample - loss: 0.0468 - accuracy: 0.9865 - val_loss: 0.0884 - val_accuracy: 0.9788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0532 - accuracy: 0.9836 - val_loss: 0.1193 - val_accuracy: 0.9663\n",
      "Epoch 92/100\n",
      "4158/4158 [==============================] - 0s 107us/sample - loss: 0.0489 - accuracy: 0.9848 - val_loss: 0.0447 - val_accuracy: 0.9913\n",
      "Epoch 93/100\n",
      "4158/4158 [==============================] - 0s 111us/sample - loss: 0.0463 - accuracy: 0.9873 - val_loss: 0.0461 - val_accuracy: 0.9913\n",
      "Epoch 94/100\n",
      "4158/4158 [==============================] - 0s 104us/sample - loss: 0.0482 - accuracy: 0.9846 - val_loss: 0.0755 - val_accuracy: 0.9769\n",
      "Epoch 95/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0507 - accuracy: 0.9839 - val_loss: 0.0750 - val_accuracy: 0.9817\n",
      "Epoch 96/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0494 - accuracy: 0.9861 - val_loss: 0.0665 - val_accuracy: 0.9817\n",
      "Epoch 97/100\n",
      "4158/4158 [==============================] - 0s 106us/sample - loss: 0.0467 - accuracy: 0.9851 - val_loss: 0.0532 - val_accuracy: 0.9904\n",
      "Epoch 98/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0469 - accuracy: 0.9873 - val_loss: 0.0604 - val_accuracy: 0.9913\n",
      "Epoch 99/100\n",
      "4158/4158 [==============================] - 0s 105us/sample - loss: 0.0479 - accuracy: 0.9858 - val_loss: 0.0620 - val_accuracy: 0.9856\n",
      "Epoch 100/100\n",
      "4158/4158 [==============================] - 0s 107us/sample - loss: 0.0479 - accuracy: 0.9848 - val_loss: 0.0444 - val_accuracy: 0.9923\n",
      "1299/1299 - 0s - loss: 0.0604 - accuracy: 0.9800\n"
     ]
    }
   ],
   "source": [
    "for train, test in skf.split(x, y):\n",
    "    model = Sequential([\n",
    "        Dense(30, input_dim=12, activation='relu'),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(8, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(loss ='binary_crossentropy',\n",
    "                 optimizer = 'nadam',\n",
    "                 metrics=['accuracy'])\n",
    "    model.fit(x[train], y[train], epochs=100, batch_size = 10, validation_split=0.2)\n",
    "    acc = model.evaluate(x[test], y[test], verbose=2)[1]\n",
    "    accuracy.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98553133"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.98846155, 0.98538464, 0.9861432, 0.9876828, 0.9799846]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
