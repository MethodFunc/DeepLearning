{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using plaidml.keras.backend backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../dataset/iris.csv', names = [\"sepal_length\",\n",
    "                 \"sepal_width\", \"petal_length\", \"petal_width\", \"species\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = dataset[:, :-1].astype(np.float32)\n",
    "y = dataset[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = LabelEncoder()\n",
    "labels.fit(y)\n",
    "y_data = labels.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = np_utils.to_categorical(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_data2 = tf.one_hot(y_data, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, stratify=y_data, test_size=0.2, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((120, 4), (120,))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(100, input_shape=(4, ), activation='relu'),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(25, activation='relu'),\n",
    "    Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               500       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 78        \n",
      "=================================================================\n",
      "Total params: 6,903\n",
      "Trainable params: 6,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "             optimizer = 'nadam',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 96 samples, validate on 24 samples\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 1s 7ms/sample - loss: 1.2221 - accuracy: 0.3333 - val_loss: 0.9811 - val_accuracy: 0.7083\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 0s 230us/sample - loss: 0.9523 - accuracy: 0.6146 - val_loss: 0.8625 - val_accuracy: 0.8750\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 0s 170us/sample - loss: 0.8365 - accuracy: 0.6875 - val_loss: 0.7617 - val_accuracy: 0.6667\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - 0s 187us/sample - loss: 0.7330 - accuracy: 0.7708 - val_loss: 0.6627 - val_accuracy: 0.6667\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 0s 175us/sample - loss: 0.6453 - accuracy: 0.7083 - val_loss: 0.5747 - val_accuracy: 0.8333\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - 0s 169us/sample - loss: 0.5713 - accuracy: 0.7604 - val_loss: 0.5076 - val_accuracy: 0.8333\n",
      "Epoch 7/100\n",
      "96/96 [==============================] - 0s 177us/sample - loss: 0.5204 - accuracy: 0.8125 - val_loss: 0.4522 - val_accuracy: 0.9167\n",
      "Epoch 8/100\n",
      "96/96 [==============================] - 0s 182us/sample - loss: 0.4449 - accuracy: 0.9062 - val_loss: 0.4068 - val_accuracy: 0.9167\n",
      "Epoch 9/100\n",
      "96/96 [==============================] - 0s 177us/sample - loss: 0.4019 - accuracy: 0.8958 - val_loss: 0.4063 - val_accuracy: 0.7500\n",
      "Epoch 10/100\n",
      "96/96 [==============================] - 0s 173us/sample - loss: 0.3745 - accuracy: 0.8750 - val_loss: 0.3619 - val_accuracy: 0.8750\n",
      "Epoch 11/100\n",
      "96/96 [==============================] - 0s 166us/sample - loss: 0.3375 - accuracy: 0.9167 - val_loss: 0.3108 - val_accuracy: 0.9583\n",
      "Epoch 12/100\n",
      "96/96 [==============================] - 0s 177us/sample - loss: 0.3060 - accuracy: 0.9062 - val_loss: 0.3081 - val_accuracy: 0.9167\n",
      "Epoch 13/100\n",
      "96/96 [==============================] - 0s 178us/sample - loss: 0.3000 - accuracy: 0.8958 - val_loss: 0.2910 - val_accuracy: 0.9167\n",
      "Epoch 14/100\n",
      "96/96 [==============================] - 0s 166us/sample - loss: 0.2573 - accuracy: 0.9583 - val_loss: 0.2852 - val_accuracy: 0.9167\n",
      "Epoch 15/100\n",
      "96/96 [==============================] - 0s 172us/sample - loss: 0.2307 - accuracy: 0.9583 - val_loss: 0.2695 - val_accuracy: 0.9167\n",
      "Epoch 16/100\n",
      "96/96 [==============================] - 0s 177us/sample - loss: 0.2061 - accuracy: 0.9896 - val_loss: 0.3420 - val_accuracy: 0.7917\n",
      "Epoch 17/100\n",
      "96/96 [==============================] - 0s 166us/sample - loss: 0.2032 - accuracy: 0.9375 - val_loss: 0.2576 - val_accuracy: 0.9167\n",
      "Epoch 18/100\n",
      "96/96 [==============================] - 0s 168us/sample - loss: 0.1704 - accuracy: 0.9792 - val_loss: 0.2031 - val_accuracy: 0.9167\n",
      "Epoch 19/100\n",
      "96/96 [==============================] - 0s 177us/sample - loss: 0.1541 - accuracy: 0.9896 - val_loss: 0.2199 - val_accuracy: 0.9167\n",
      "Epoch 20/100\n",
      "96/96 [==============================] - 0s 183us/sample - loss: 0.1349 - accuracy: 0.9792 - val_loss: 0.1706 - val_accuracy: 0.9583\n",
      "Epoch 21/100\n",
      "96/96 [==============================] - 0s 166us/sample - loss: 0.1362 - accuracy: 0.9583 - val_loss: 0.2277 - val_accuracy: 0.9167\n",
      "Epoch 22/100\n",
      "96/96 [==============================] - 0s 174us/sample - loss: 0.1385 - accuracy: 0.9583 - val_loss: 0.1658 - val_accuracy: 0.9167\n",
      "Epoch 23/100\n",
      "96/96 [==============================] - 0s 179us/sample - loss: 0.1299 - accuracy: 0.9583 - val_loss: 0.1542 - val_accuracy: 0.9167\n",
      "Epoch 24/100\n",
      "96/96 [==============================] - 0s 176us/sample - loss: 0.1081 - accuracy: 0.9896 - val_loss: 0.2358 - val_accuracy: 0.9167\n",
      "Epoch 25/100\n",
      "96/96 [==============================] - 0s 169us/sample - loss: 0.0961 - accuracy: 0.9896 - val_loss: 0.2213 - val_accuracy: 0.9167\n",
      "Epoch 26/100\n",
      "96/96 [==============================] - 0s 187us/sample - loss: 0.0941 - accuracy: 0.9688 - val_loss: 0.1894 - val_accuracy: 0.9167\n",
      "Epoch 27/100\n",
      "96/96 [==============================] - 0s 176us/sample - loss: 0.1001 - accuracy: 0.9792 - val_loss: 0.1558 - val_accuracy: 0.9167\n",
      "Epoch 28/100\n",
      "96/96 [==============================] - 0s 177us/sample - loss: 0.0851 - accuracy: 0.9896 - val_loss: 0.1650 - val_accuracy: 0.9167\n",
      "Epoch 29/100\n",
      "96/96 [==============================] - 0s 180us/sample - loss: 0.0848 - accuracy: 0.9688 - val_loss: 0.2435 - val_accuracy: 0.9167\n",
      "Epoch 30/100\n",
      "96/96 [==============================] - 0s 185us/sample - loss: 0.0852 - accuracy: 0.9688 - val_loss: 0.1339 - val_accuracy: 0.9583\n",
      "Epoch 31/100\n",
      "96/96 [==============================] - 0s 177us/sample - loss: 0.0901 - accuracy: 0.9688 - val_loss: 0.1518 - val_accuracy: 0.9167\n",
      "Epoch 32/100\n",
      "96/96 [==============================] - 0s 169us/sample - loss: 0.0689 - accuracy: 0.9896 - val_loss: 0.1914 - val_accuracy: 0.9167\n",
      "Epoch 33/100\n",
      "96/96 [==============================] - 0s 177us/sample - loss: 0.0682 - accuracy: 1.0000 - val_loss: 0.1494 - val_accuracy: 0.9167\n",
      "Epoch 34/100\n",
      "96/96 [==============================] - 0s 176us/sample - loss: 0.0609 - accuracy: 0.9896 - val_loss: 0.1293 - val_accuracy: 0.9583\n",
      "Epoch 35/100\n",
      "96/96 [==============================] - 0s 177us/sample - loss: 0.0617 - accuracy: 0.9792 - val_loss: 0.3087 - val_accuracy: 0.9167\n",
      "Epoch 36/100\n",
      "96/96 [==============================] - 0s 177us/sample - loss: 0.0716 - accuracy: 0.9896 - val_loss: 0.2136 - val_accuracy: 0.9167\n",
      "Epoch 37/100\n",
      "96/96 [==============================] - 0s 187us/sample - loss: 0.0768 - accuracy: 0.9792 - val_loss: 0.2616 - val_accuracy: 0.9167\n",
      "Epoch 38/100\n",
      "96/96 [==============================] - 0s 166us/sample - loss: 0.0549 - accuracy: 0.9792 - val_loss: 0.1304 - val_accuracy: 0.9583\n",
      "Epoch 39/100\n",
      "96/96 [==============================] - 0s 161us/sample - loss: 0.0590 - accuracy: 0.9792 - val_loss: 0.1672 - val_accuracy: 0.9167\n",
      "Epoch 40/100\n",
      "96/96 [==============================] - 0s 165us/sample - loss: 0.0869 - accuracy: 0.9583 - val_loss: 0.2499 - val_accuracy: 0.9167\n",
      "Epoch 41/100\n",
      "96/96 [==============================] - 0s 160us/sample - loss: 0.0483 - accuracy: 1.0000 - val_loss: 0.2562 - val_accuracy: 0.9167\n",
      "Epoch 42/100\n",
      "96/96 [==============================] - 0s 173us/sample - loss: 0.0595 - accuracy: 0.9688 - val_loss: 0.1811 - val_accuracy: 0.9167\n",
      "Epoch 43/100\n",
      "96/96 [==============================] - 0s 166us/sample - loss: 0.0424 - accuracy: 1.0000 - val_loss: 0.1572 - val_accuracy: 0.9167\n",
      "Epoch 44/100\n",
      "96/96 [==============================] - 0s 158us/sample - loss: 0.0554 - accuracy: 0.9792 - val_loss: 0.2905 - val_accuracy: 0.9167\n",
      "Epoch 45/100\n",
      "96/96 [==============================] - 0s 167us/sample - loss: 0.0551 - accuracy: 0.9792 - val_loss: 0.3100 - val_accuracy: 0.9167\n",
      "Epoch 46/100\n",
      "96/96 [==============================] - 0s 171us/sample - loss: 0.0646 - accuracy: 0.9792 - val_loss: 0.2249 - val_accuracy: 0.9167\n",
      "Epoch 47/100\n",
      "96/96 [==============================] - 0s 175us/sample - loss: 0.0521 - accuracy: 0.9792 - val_loss: 0.3462 - val_accuracy: 0.9167\n",
      "Epoch 48/100\n",
      "96/96 [==============================] - 0s 175us/sample - loss: 0.0586 - accuracy: 0.9792 - val_loss: 0.2710 - val_accuracy: 0.9167\n",
      "Epoch 49/100\n",
      "96/96 [==============================] - 0s 175us/sample - loss: 0.0439 - accuracy: 0.9896 - val_loss: 0.2479 - val_accuracy: 0.9167\n",
      "Epoch 50/100\n",
      "96/96 [==============================] - 0s 177us/sample - loss: 0.0388 - accuracy: 0.9896 - val_loss: 0.2120 - val_accuracy: 0.9167\n",
      "Epoch 51/100\n",
      "96/96 [==============================] - 0s 176us/sample - loss: 0.0537 - accuracy: 0.9896 - val_loss: 0.1201 - val_accuracy: 0.9167\n",
      "Epoch 52/100\n",
      "96/96 [==============================] - 0s 177us/sample - loss: 0.0713 - accuracy: 0.9688 - val_loss: 0.1241 - val_accuracy: 0.9583\n",
      "Epoch 53/100\n",
      "96/96 [==============================] - 0s 172us/sample - loss: 0.0519 - accuracy: 0.9792 - val_loss: 0.2196 - val_accuracy: 0.9167\n",
      "Epoch 54/100\n",
      "96/96 [==============================] - 0s 187us/sample - loss: 0.0466 - accuracy: 0.9896 - val_loss: 0.3257 - val_accuracy: 0.9167\n",
      "Epoch 55/100\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0461 - accuracy: 1.00 - 0s 167us/sample - loss: 0.0378 - accuracy: 0.9896 - val_loss: 0.1505 - val_accuracy: 0.9167\n",
      "Epoch 56/100\n",
      "96/96 [==============================] - 0s 177us/sample - loss: 0.0395 - accuracy: 0.9896 - val_loss: 0.3361 - val_accuracy: 0.9167\n",
      "Epoch 57/100\n",
      "96/96 [==============================] - 0s 174us/sample - loss: 0.0481 - accuracy: 0.9792 - val_loss: 0.3106 - val_accuracy: 0.9167\n",
      "Epoch 58/100\n",
      "96/96 [==============================] - 0s 184us/sample - loss: 0.0350 - accuracy: 0.9896 - val_loss: 0.2581 - val_accuracy: 0.9167\n",
      "Epoch 59/100\n",
      "96/96 [==============================] - 0s 177us/sample - loss: 0.0326 - accuracy: 0.9896 - val_loss: 0.1661 - val_accuracy: 0.9167\n",
      "Epoch 60/100\n",
      "96/96 [==============================] - 0s 176us/sample - loss: 0.0387 - accuracy: 0.9792 - val_loss: 0.1571 - val_accuracy: 0.9167\n",
      "Epoch 61/100\n",
      "96/96 [==============================] - 0s 179us/sample - loss: 0.0305 - accuracy: 0.9896 - val_loss: 0.2995 - val_accuracy: 0.9167\n",
      "Epoch 62/100\n",
      "96/96 [==============================] - 0s 181us/sample - loss: 0.0381 - accuracy: 0.9896 - val_loss: 0.4125 - val_accuracy: 0.9167\n",
      "Epoch 63/100\n",
      "96/96 [==============================] - 0s 166us/sample - loss: 0.0401 - accuracy: 0.9792 - val_loss: 0.1972 - val_accuracy: 0.9167\n",
      "Epoch 64/100\n",
      "96/96 [==============================] - 0s 175us/sample - loss: 0.0596 - accuracy: 0.9688 - val_loss: 0.3172 - val_accuracy: 0.9167\n",
      "Epoch 65/100\n",
      "96/96 [==============================] - 0s 186us/sample - loss: 0.0425 - accuracy: 0.9792 - val_loss: 0.2197 - val_accuracy: 0.9167\n",
      "Epoch 66/100\n",
      "96/96 [==============================] - 0s 174us/sample - loss: 0.0333 - accuracy: 0.9896 - val_loss: 0.2810 - val_accuracy: 0.9167\n",
      "Epoch 67/100\n",
      "96/96 [==============================] - 0s 181us/sample - loss: 0.0290 - accuracy: 0.9896 - val_loss: 0.3849 - val_accuracy: 0.9167\n",
      "Epoch 68/100\n",
      "96/96 [==============================] - 0s 177us/sample - loss: 0.0296 - accuracy: 1.0000 - val_loss: 0.2877 - val_accuracy: 0.9167\n",
      "Epoch 69/100\n",
      "96/96 [==============================] - 0s 177us/sample - loss: 0.0323 - accuracy: 0.9896 - val_loss: 0.3024 - val_accuracy: 0.9167\n",
      "Epoch 70/100\n",
      "96/96 [==============================] - 0s 166us/sample - loss: 0.0293 - accuracy: 0.9896 - val_loss: 0.1621 - val_accuracy: 0.9167\n",
      "Epoch 71/100\n",
      "96/96 [==============================] - 0s 176us/sample - loss: 0.0455 - accuracy: 0.9688 - val_loss: 0.3007 - val_accuracy: 0.9167\n",
      "Epoch 72/100\n",
      "96/96 [==============================] - 0s 186us/sample - loss: 0.0342 - accuracy: 0.9792 - val_loss: 0.3352 - val_accuracy: 0.9167\n",
      "Epoch 73/100\n",
      "96/96 [==============================] - 0s 183us/sample - loss: 0.0280 - accuracy: 0.9896 - val_loss: 0.3417 - val_accuracy: 0.9167\n",
      "Epoch 74/100\n",
      "96/96 [==============================] - 0s 166us/sample - loss: 0.0326 - accuracy: 0.9792 - val_loss: 0.3176 - val_accuracy: 0.9167\n",
      "Epoch 75/100\n",
      "96/96 [==============================] - 0s 174us/sample - loss: 0.0271 - accuracy: 0.9896 - val_loss: 0.1603 - val_accuracy: 0.9167\n",
      "Epoch 76/100\n",
      "96/96 [==============================] - 0s 177us/sample - loss: 0.0399 - accuracy: 0.9792 - val_loss: 0.3962 - val_accuracy: 0.9167\n",
      "Epoch 77/100\n",
      "96/96 [==============================] - 0s 165us/sample - loss: 0.0278 - accuracy: 0.9896 - val_loss: 0.2526 - val_accuracy: 0.9167\n",
      "Epoch 78/100\n",
      "96/96 [==============================] - 0s 187us/sample - loss: 0.0379 - accuracy: 0.9792 - val_loss: 0.4045 - val_accuracy: 0.9167\n",
      "Epoch 79/100\n",
      "96/96 [==============================] - 0s 173us/sample - loss: 0.0312 - accuracy: 0.9896 - val_loss: 0.3248 - val_accuracy: 0.9167\n",
      "Epoch 80/100\n",
      "96/96 [==============================] - 0s 184us/sample - loss: 0.0473 - accuracy: 0.9688 - val_loss: 0.2561 - val_accuracy: 0.9167\n",
      "Epoch 81/100\n",
      "96/96 [==============================] - 0s 177us/sample - loss: 0.0284 - accuracy: 0.9896 - val_loss: 0.4678 - val_accuracy: 0.9167\n",
      "Epoch 82/100\n",
      "96/96 [==============================] - 0s 183us/sample - loss: 0.0279 - accuracy: 1.0000 - val_loss: 0.3823 - val_accuracy: 0.9167\n",
      "Epoch 83/100\n",
      "96/96 [==============================] - 0s 184us/sample - loss: 0.0301 - accuracy: 1.0000 - val_loss: 0.4054 - val_accuracy: 0.9167\n",
      "Epoch 84/100\n",
      "96/96 [==============================] - 0s 190us/sample - loss: 0.0303 - accuracy: 0.9896 - val_loss: 0.3905 - val_accuracy: 0.9167\n",
      "Epoch 85/100\n",
      "96/96 [==============================] - 0s 189us/sample - loss: 0.0410 - accuracy: 0.9792 - val_loss: 0.4423 - val_accuracy: 0.9167\n",
      "Epoch 86/100\n",
      "96/96 [==============================] - 0s 178us/sample - loss: 0.0316 - accuracy: 0.9896 - val_loss: 0.3666 - val_accuracy: 0.9167\n",
      "Epoch 87/100\n",
      "96/96 [==============================] - 0s 180us/sample - loss: 0.0265 - accuracy: 0.9896 - val_loss: 0.3307 - val_accuracy: 0.9167\n",
      "Epoch 88/100\n",
      "96/96 [==============================] - 0s 177us/sample - loss: 0.0201 - accuracy: 1.0000 - val_loss: 0.4302 - val_accuracy: 0.9167\n",
      "Epoch 89/100\n",
      "96/96 [==============================] - 0s 187us/sample - loss: 0.0406 - accuracy: 0.9792 - val_loss: 0.4023 - val_accuracy: 0.9167\n",
      "Epoch 90/100\n",
      "96/96 [==============================] - 0s 189us/sample - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.2311 - val_accuracy: 0.9167\n",
      "Epoch 91/100\n",
      "96/96 [==============================] - 0s 177us/sample - loss: 0.0321 - accuracy: 0.9896 - val_loss: 0.2164 - val_accuracy: 0.9167\n",
      "Epoch 92/100\n",
      "96/96 [==============================] - 0s 172us/sample - loss: 0.0788 - accuracy: 0.9583 - val_loss: 0.3367 - val_accuracy: 0.9167\n",
      "Epoch 93/100\n",
      "96/96 [==============================] - 0s 170us/sample - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.4418 - val_accuracy: 0.9167\n",
      "Epoch 94/100\n",
      "96/96 [==============================] - 0s 160us/sample - loss: 0.0281 - accuracy: 0.9792 - val_loss: 0.4054 - val_accuracy: 0.9167\n",
      "Epoch 95/100\n",
      "96/96 [==============================] - 0s 174us/sample - loss: 0.0252 - accuracy: 0.9896 - val_loss: 0.4688 - val_accuracy: 0.9167\n",
      "Epoch 96/100\n",
      "96/96 [==============================] - 0s 176us/sample - loss: 0.0236 - accuracy: 0.9896 - val_loss: 0.1203 - val_accuracy: 0.9167\n",
      "Epoch 97/100\n",
      "96/96 [==============================] - 0s 175us/sample - loss: 0.0928 - accuracy: 0.9688 - val_loss: 0.2578 - val_accuracy: 0.9167\n",
      "Epoch 98/100\n",
      "96/96 [==============================] - 0s 173us/sample - loss: 0.0239 - accuracy: 1.0000 - val_loss: 0.4172 - val_accuracy: 0.9167\n",
      "Epoch 99/100\n",
      "96/96 [==============================] - 0s 186us/sample - loss: 0.0244 - accuracy: 0.9896 - val_loss: 0.4491 - val_accuracy: 0.9167\n",
      "Epoch 100/100\n",
      "96/96 [==============================] - 0s 187us/sample - loss: 0.0167 - accuracy: 0.9896 - val_loss: 0.1770 - val_accuracy: 0.9167\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs = 100 , batch_size=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 57us/sample - loss: 0.0854 - accuracy: 0.9333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.93333334"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.array(dataset[:, :-1]).astype(np.float32)\n",
    "y = dataset[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = LabelEncoder().fit(y)\n",
    "y_data = np.array(labels.transform(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3,), dtype=float32, numpy=array([1., 0., 0.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3,), dtype=float32, numpy=array([0., 1., 0.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3,), dtype=float32, numpy=array([0., 0., 1.], dtype=float32)>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_one_hot = tf.one_hot(y_data, 3)\n",
    "y_one_hot[0], y_one_hot[50], y_one_hot[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(100, input_shape=(4, ), activation='relu'),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(25, activation='relu'),\n",
    "    Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "             optimizer = 'nadam',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 150 samples\n",
      "Epoch 1/50\n",
      "150/150 [==============================] - 1s 3ms/sample - loss: 1.0444 - accuracy: 0.6333\n",
      "Epoch 2/50\n",
      "150/150 [==============================] - 0s 51us/sample - loss: 0.9409 - accuracy: 0.9000\n",
      "Epoch 3/50\n",
      "150/150 [==============================] - 0s 43us/sample - loss: 0.8617 - accuracy: 0.6667\n",
      "Epoch 4/50\n",
      "150/150 [==============================] - 0s 46us/sample - loss: 0.7918 - accuracy: 0.7000\n",
      "Epoch 5/50\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.7251 - accuracy: 0.6667\n",
      "Epoch 6/50\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.6557 - accuracy: 0.7067\n",
      "Epoch 7/50\n",
      "150/150 [==============================] - 0s 33us/sample - loss: 0.5766 - accuracy: 0.7267\n",
      "Epoch 8/50\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.5188 - accuracy: 0.8933\n",
      "Epoch 9/50\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.4664 - accuracy: 0.8467\n",
      "Epoch 10/50\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.4239 - accuracy: 0.9267\n",
      "Epoch 11/50\n",
      "150/150 [==============================] - 0s 46us/sample - loss: 0.3815 - accuracy: 0.9267\n",
      "Epoch 12/50\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.3488 - accuracy: 0.9667\n",
      "Epoch 13/50\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.3172 - accuracy: 0.9600\n",
      "Epoch 14/50\n",
      "150/150 [==============================] - 0s 46us/sample - loss: 0.2878 - accuracy: 0.9800\n",
      "Epoch 15/50\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.2621 - accuracy: 0.9733\n",
      "Epoch 16/50\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.2547 - accuracy: 0.9600\n",
      "Epoch 17/50\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.2289 - accuracy: 0.9667\n",
      "Epoch 18/50\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.2130 - accuracy: 0.9533\n",
      "Epoch 19/50\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.2078 - accuracy: 0.9600\n",
      "Epoch 20/50\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.1922 - accuracy: 0.9467\n",
      "Epoch 21/50\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.1685 - accuracy: 0.9867\n",
      "Epoch 22/50\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.1694 - accuracy: 0.9533\n",
      "Epoch 23/50\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.1573 - accuracy: 0.9400\n",
      "Epoch 24/50\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.1518 - accuracy: 0.9533\n",
      "Epoch 25/50\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.1382 - accuracy: 0.9800\n",
      "Epoch 26/50\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.1388 - accuracy: 0.9667\n",
      "Epoch 27/50\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.1337 - accuracy: 0.9667\n",
      "Epoch 28/50\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.1435 - accuracy: 0.9533\n",
      "Epoch 29/50\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.1153 - accuracy: 0.9800\n",
      "Epoch 30/50\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.1140 - accuracy: 0.9800\n",
      "Epoch 31/50\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.1252 - accuracy: 0.9667\n",
      "Epoch 32/50\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.1082 - accuracy: 0.9733\n",
      "Epoch 33/50\n",
      "150/150 [==============================] - 0s 46us/sample - loss: 0.1113 - accuracy: 0.9800\n",
      "Epoch 34/50\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.1054 - accuracy: 0.9800\n",
      "Epoch 35/50\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.1071 - accuracy: 0.9733\n",
      "Epoch 36/50\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.1089 - accuracy: 0.9600\n",
      "Epoch 37/50\n",
      "150/150 [==============================] - 0s 46us/sample - loss: 0.1068 - accuracy: 0.9733\n",
      "Epoch 38/50\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.0907 - accuracy: 0.9867\n",
      "Epoch 39/50\n",
      "150/150 [==============================] - 0s 33us/sample - loss: 0.0995 - accuracy: 0.9667\n",
      "Epoch 40/50\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.0902 - accuracy: 0.9733\n",
      "Epoch 41/50\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.0905 - accuracy: 0.9667\n",
      "Epoch 42/50\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.0810 - accuracy: 0.9800\n",
      "Epoch 43/50\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.0931 - accuracy: 0.9733\n",
      "Epoch 44/50\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.0874 - accuracy: 0.9733\n",
      "Epoch 45/50\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.0763 - accuracy: 0.9733\n",
      "Epoch 46/50\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.0864 - accuracy: 0.9667\n",
      "Epoch 47/50\n",
      "150/150 [==============================] - 0s 33us/sample - loss: 0.0911 - accuracy: 0.9667\n",
      "Epoch 48/50\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.0753 - accuracy: 0.9867\n",
      "Epoch 49/50\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.0781 - accuracy: 0.9733\n",
      "Epoch 50/50\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.0762 - accuracy: 0.9733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x29cb32f3e88>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_data, y_one_hot, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 - 0s - loss: 0.0728 - accuracy: 0.9800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07279197485496601, 0.98]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_data, y_one_hot, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
